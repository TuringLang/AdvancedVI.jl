var documenterSearchIndex = {"docs":
[{"location":"optimization/#optim","page":"Optimization","title":"Optimization","text":"","category":"section"},{"location":"optimization/#Parameter-Free-Optimization-Rules","page":"Optimization","title":"Parameter-Free Optimization Rules","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"We provide custom optimization rules that are not provided out-of-the-box by Optimisers.jl. The main theme of the provided optimizers is that they are parameter-free. This means that these optimization rules shouldn't require (or barely) any tuning to obtain performance competitive with well-tuned alternatives.","category":"page"},{"location":"optimization/#AdvancedVI.DoG","page":"Optimization","title":"AdvancedVI.DoG","text":"DoG(repsilon)\n\nDistance over gradient (DoG[IHC2023]) optimizer. It's only parameter is the initial guess of the Euclidean distance to the optimum repsilon. The original paper recommends $ 10^{-4} ( 1 + \\lVert \\lambda_0 \\rVert ) $, but the default value is $ 10^{-6} $.\n\nParameters\n\nrepsilon: Initial guess of the Euclidean distance between the initial point and the optimum. (default value: 1e-6)\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.DoWG","page":"Optimization","title":"AdvancedVI.DoWG","text":"DoWG(repsilon)\n\nDistance over weighted gradient (DoWG[KMJ2024]) optimizer. It's only parameter is the initial guess of the Euclidean distance to the optimum repsilon.\n\nParameters\n\nrepsilon: Initial guess of the Euclidean distance between the initial point and           the optimum. (default value: 1e-6)\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.COCOB","page":"Optimization","title":"AdvancedVI.COCOB","text":"COCOB(alpha)\n\nContinuous Coin Betting (COCOB[OT2017]) optimizer. We use the \"COCOB-Backprop\" variant, which is closer to the Adam optimizer. Its only parameter is the maximum change per parameter α, which shouldn't need much tuning.\n\nParameters\n\nalpha: Scaling parameter. (default value: 100)\n\n[OT2017]: Orabona, F., & Tommasi, T. (2017). Training deep networks without learning rates through coin betting. Advances in Neural Information Processing Systems, 30.\n\n\n\n\n\n","category":"type"},{"location":"optimization/#Parameter-Averaging-Strategies","page":"Optimization","title":"Parameter Averaging Strategies","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"In some cases, the best optimization performance is obtained by averaging the sequence of parameters generated by the optimization algorithm. For instance, the DoG[IHC2023] and DoWG[KMJ2024] papers report their best performance through averaging. The benefits of parameter averaging have been specifically confirmed for ELBO maximization[DCAMHV2020].","category":"page"},{"location":"optimization/#AdvancedVI.NoAveraging","page":"Optimization","title":"AdvancedVI.NoAveraging","text":"NoAveraging()\n\nNo averaging. This returns the last-iterate of the optimization rule.\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.PolynomialAveraging","page":"Optimization","title":"AdvancedVI.PolynomialAveraging","text":"PolynomialAveraging(eta)\n\nPolynomial averaging rule proposed Shamir and Zhang[SZ2013]. At iteration t, the parameter average $ \\bar{\\lambda}_t $ according to the polynomial averaging rule is given as\n\n    barlambda_t = (1 - w_t) barlambda_t-1 + w_t lambda_t  \n\nwhere the averaging weight is \n\n    w_t = fraceta + 1t + eta  \n\nHigher eta (eta) down-weights earlier iterations. When eta=0, this is equivalent to uniformly averaging the iterates in an online fashion. The DoG paper[IHC2023] suggests eta=8.\n\nParameters\n\neta: Regularization term. (default: 8)\n\n[SZ2013]: Shamir, O., & Zhang, T. (2013). Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes. In International conference on machine learning (pp. 71-79). PMLR.\n\n\n\n\n\n","category":"type"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[DCAMHV2020]: Dhaka, A. K., Catalina, A., Andersen, M. R., Magnusson, M., Huggins, J., & Vehtari, A. (2020). Robust, accurate stochastic optimization for variational inference. Advances in Neural Information Processing Systems, 33, 10961-10973.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[KMJ2024]: Khaled, A., Mishchenko, K., & Jin, C. (2023). Dowg unleashed: An efficient universal parameter-free gradient descent method. Advances in Neural Information Processing Systems, 36, 6748-6769.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[IHC2023]: Ivgi, M., Hinder, O., & Carmon, Y. (2023). Dog is sgd's best friend: A parameter-free dynamic step size schedule. In International Conference on Machine Learning (pp. 14465-14499). PMLR.","category":"page"},{"location":"optimization/#Operators","page":"Optimization","title":"Operators","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Depending on the variational family, variational objective, and optimization strategy, it might be necessary to modify the variational parameters after performing a gradient-based update. For this, an operator acting on the parameters can be supplied via the  operator keyword argument of AdvancedVI.optimize.","category":"page"},{"location":"optimization/#clipscale","page":"Optimization","title":"ClipScale","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"For the location-scale family, it is often the case that optimization is stable only when the smallest eigenvalue of the scale matrix is strictly positive[D2020]. To ensure this, we provide the following projection operator:","category":"page"},{"location":"optimization/#AdvancedVI.ClipScale","page":"Optimization","title":"AdvancedVI.ClipScale","text":"ClipScale(ϵ = 1e-5)\n\nProjection operator ensuring that an MvLocationScale or MvLocationScaleLowRank has a scale with eigenvalues larger than ϵ. ClipScale also supports by operating on MvLocationScale and MvLocationScaleLowRank wrapped by a Bijectors.TransformedDistribution object. \n\n\n\n\n\n","category":"type"},{"location":"optimization/#proximalocationscaleentropy","page":"Optimization","title":"ProximalLocationScaleEntropy","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"ELBO maximization with the location-scale family tends to be unstable when the scale has small eigenvalues or the stepsize is large. To remedy this, a proximal operator of the entropy[D2020] can be used.","category":"page"},{"location":"optimization/#AdvancedVI.ProximalLocationScaleEntropy","page":"Optimization","title":"AdvancedVI.ProximalLocationScaleEntropy","text":"ProximalLocationScaleEntropy()\n\nProximal operator for the entropy of a location-scale distribution, which is defined as\n\n    mathrmprox(lambda) = argmin_lambda^prime - mathbbH(q_lambda^prime) + frac12 gamma_t leftlVert lambda - lambda^prime rightrVert_2^2 \n\nwhere gamma_t is the stepsize the optimizer used with the proximal operator. This assumes the variational family is <:VILocationScale and the optimizer is one of the following:\n\nDoG\nDoWG\nDescent\n\nFor ELBO maximization, since this proximal operator handles the entropy, the gradient estimator for the ELBO must ignore the entropy term. That is, the entropy keyword argument of RepGradELBO muse be one of the following:\n\nClosedFormEntropyZeroGradient\nStickingTheLandingEntropyZeroGradient\n\n\n\n\n\n","category":"type"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[D2020]: Domke, J. (2020). Provable smoothness guarantees for black-box variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"families/#families","page":"Variational Families","title":"Reparameterizable Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The RepGradELBO objective assumes that the members of the variational family have a differentiable sampling path. We provide multiple pre-packaged variational families that can be readily used.","category":"page"},{"location":"families/#locscale","page":"Variational Families","title":"The LocationScale Family","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The location-scale variational family is a family of probability distributions, where their sampling process can be represented as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= C u + mquad u sim varphi","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where C is the scale, m is the location, and varphi is the base distribution. m and C form the variational parameters lambda = (m C) of q_lambda. The location-scale family encompases many practical variational families, which can be instantiated by setting the base distribution of u and the structure of C.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The probability density is given by","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  q_lambda(z) = C^-1 varphi(C^-1(z - m))","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"the covariance is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathrmVarleft(q_lambdaright) = C mathrmVar(q_lambda) C^top","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"and the entropy is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathbbH(q_lambda) = mathbbH(varphi) + log C","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where mathbbH(varphi) is the entropy of the base distribution. Notice the mathbbH(varphi) does not depend on log C. The derivative of the entropy with respect to lambda is thus independent of the base distribution.","category":"page"},{"location":"families/#API","page":"Variational Families","title":"API","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"note: Note\nFor stable convergence, the initial scale needs to be sufficiently large and well-conditioned. Initializing scale to have small eigenvalues will often result in initial divergences and numerical instabilities.","category":"page"},{"location":"families/#AdvancedVI.MvLocationScale","page":"Variational Families","title":"AdvancedVI.MvLocationScale","text":"MvLocationScale(location, scale, dist)\n\nThe location scale variational family broadly represents various variational families using location and scale variational parameters.\n\nIt generally represents any distribution for which the sampling path can be represented as follows:\n\n  d = length(location)\n  u = rand(dist, d)\n  z = scale*u + location\n\n\n\n\n\n","category":"type"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The following are specialized constructors for convenience:","category":"page"},{"location":"families/#AdvancedVI.FullRankGaussian","page":"Variational Families","title":"AdvancedVI.FullRankGaussian","text":"FullRankGaussian(μ, L)\n\nConstruct a Gaussian variational approximation with a dense covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nL::LinearAlgebra.AbstractTriangular{T}: Cholesky factor of the covariance of the Gaussian.\n\n\n\n\n\n","category":"function"},{"location":"families/#AdvancedVI.MeanFieldGaussian","page":"Variational Families","title":"AdvancedVI.MeanFieldGaussian","text":"MeanFieldGaussian(μ, L)\n\nConstruct a Gaussian variational approximation with a diagonal covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nL::Diagonal{T}: Diagonal Cholesky factor of the covariance of the Gaussian.\n\n\n\n\n\n","category":"function"},{"location":"families/#Gaussian-Variational-Families","page":"Variational Families","title":"Gaussian Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\n\nL = LowerTriangular(diagm(ones(2)));\nq = FullRankGaussian(μ, L)\n\nL = Diagonal(ones(2));\nq = MeanFieldGaussian(μ, L)","category":"page"},{"location":"families/#Student-t-Variational-Families","page":"Variational Families","title":"Student-t Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\nν = 3;\n\n# Full-Rank \nL = LowerTriangular(diagm(ones(2)));\nq = MvLocationScale(μ, L, TDist(ν))\n\n# Mean-Field\nL = Diagonal(ones(2));\nq = MvLocationScale(μ, L, TDist(ν))","category":"page"},{"location":"families/#Laplace-Variational-families","page":"Variational Families","title":"Laplace Variational families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\n\n# Full-Rank \nL = LowerTriangular(diagm(ones(2)));\nq = MvLocationScale(μ, L, Laplace())\n\n# Mean-Field\nL = Diagonal(ones(2));\nq = MvLocationScale(μ, L, Laplace())","category":"page"},{"location":"families/#The-LocationScaleLowRank-Family","page":"Variational Families","title":"The LocationScaleLowRank Family","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"In practice, LocationScale families with full-rank scale matrices are known to converge slowly as they require a small SGD stepsize. Low-rank variational families can be an effective alternative[ONS2018]. LocationScaleLowRank generally represent any d-dimensional distribution which its sampling path can be represented as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= D u_1 + U u_2  + mquad u_1 u_2 sim varphi","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where D in mathbbR^d times d is a diagonal matrix, U in mathbbR^d times r is a dense low-rank matrix for the rank r  0, m in mathbbR^d is the location, and varphi is the base distribution. m, D, and U form the variational parameters lambda = (m D U).","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The covariance of this distribution is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathrmVarleft(q_lambdaright) = D mathrmVar(varphi) D + U mathrmVar(varphi) U^top","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"and the entropy is given by the matrix determinant lemma as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathbbH(q_lambda) \n  = mathbbH(varphi) + log Sigma\n  = mathbbH(varphi) + 2 log D + log I + U^top D^-2 U","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where mathbbH(varphi) is the entropy of the base distribution.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"Consider a 30-dimensional Gaussian with a diagonal plus low-rank covariance structure, where the true rank is 3. Then, we can compare the convergence speed of LowRankGaussian versus FullRankGaussian:","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"(Image: )","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"As we can see, LowRankGaussian converges faster than FullRankGaussian. While FullRankGaussian can converge to the true solution since it is a more expressive variational family, LowRankGaussian gets there faster.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"info: Info\nMvLocationScaleLowRank tend to work better with the Optimisers.Adam optimizer due to non-smoothness. Other optimisers may experience divergences.","category":"page"},{"location":"families/#API-2","page":"Variational Families","title":"API","text":"","category":"section"},{"location":"families/#AdvancedVI.MvLocationScaleLowRank","page":"Variational Families","title":"AdvancedVI.MvLocationScaleLowRank","text":"MvLocationLowRankScale(location, scale_diag, scale_factors, dist)\n\nVariational family with a covariance in the form of a diagonal matrix plus a squared low-rank matrix. The rank is given by size(scale_factors, 2).\n\nIt generally represents any distribution for which the sampling path can be represented as follows:\n\n  d = length(location)\n  r = size(scale_factors, 2)\n  u_diag = rand(dist, d)\n  u_factors = rand(dist, r)\n  z = scale_diag.*u_diag + scale_factors*u_factors + location\n\n\n\n\n\n","category":"type"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The logpdf of  MvLocationScaleLowRank has an optional argument non_differentiable::Bool (default: false). If set as true, a more efficient Oleft(r d^2right) implementation is used to evaluate the density. This, however, is not differentiable under most AD frameworks due to the use of Cholesky lowrankupdate. The default value is false, which uses a Oleft(d^3right) implementation, is differentiable and therefore compatible with the StickingTheLandingEntropy estimator.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The following is a specialized constructor for convenience:","category":"page"},{"location":"families/#AdvancedVI.LowRankGaussian","page":"Variational Families","title":"AdvancedVI.LowRankGaussian","text":"LowRankGaussian(μ, D, U)\n\nConstruct a Gaussian variational approximation with a diagonal plus low-rank covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nD::Vector{T}: Diagonal of the scale.\nU::Matrix{T}: Low-rank factors of the scale, where size(U,2) is the rank.\n\n\n\n\n\n","category":"function"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"[ONS2018]: Ong, V. M. H., Nott, D. J., & Smith, M. S. (2018). Gaussian variational approximation with a factor covariance structure. Journal of Computational and Graphical Statistics, 27(3), 465-478.","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/#klminrepgraddescent","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"","category":"section"},{"location":"paramspacesgd/klminrepgraddescent/","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"This is a convenience constructor for ParamSpaceSGD with the RepGradELBO objective. This is equivalent to the algorithm commonly referred as automatic differentiation variational inference[KTRGB2017]. KLMinRepGradDescent is also an alias of ADVI .","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research, 18(14), 1-45.","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/#AdvancedVI.KLMinRepGradDescent","page":"KLMinRepGradDescent","title":"AdvancedVI.KLMinRepGradDescent","text":"KLMinRepGradDescent(adtype; entropy, optimizer, n_samples, averager, operator)\n\nKL divergence minimization by running stochastic gradient descent with the reparameterization gradient in the Euclidean space of variational parameters.\n\nArguments\n\nadtype::ADTypes.AbstractADType: Automatic differentiation backend. \n\nKeyword Arguments\n\nentropy: Entropy gradient estimator to be used. Must be one of ClosedFormEntropy, StickingTheLandingEntropy, MonteCarloEntropy. (default: ClosedFormEntropy())\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient. (default: 1)\naverager::AbstractAverager: Parameter averaging strategy. \noperator::Union{<:IdentityOperator, <:ClipScale}: Operator to be applied after each gradient descent step. (default: ClipScale())\n\nRequirements\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\nThe variational approximation q_lambda implements rand.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblems.logdensity(prob, x) must be differentiable with respect to x by the selected AD backend.\nAdditonal requirements on q may apply depending on the choice of entropy.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/klminrepgradproxdescent/#klminrepgradproxdescent","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"","category":"section"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"This is a convenience constructor for ParamSpaceSGD with the RepGradELBO objective with a proximal operator of the entropy (see here) of location-scale variational families. It implements the stochastic proximal gradient descent-based algorithm described in: [D2020][KMG2024][DGG2023].","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[D2020]: Domke, J. (2020). Provable smoothness guarantees for black-box variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[KMG2024]: Kim, K., Ma, Y., & Gardner, J. (2024). Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. In International Conference on Artificial Intelligence and Statistics (pp. 235-243). PMLR.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[DGG2023]: Domke, J., Gower, R., & Garrigos, G. (2023). Provable convergence guarantees for black-box variational inference. Advances in neural information processing systems, 36, 66289-66327.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/#AdvancedVI.KLMinRepGradProxDescent","page":"KLMinRepGradProxDescent","title":"AdvancedVI.KLMinRepGradProxDescent","text":"KLMinRepGradProxDescent(adtype; entropy_zerograd, optimizer, n_samples, averager)\n\nKL divergence minimization by running stochastic proximal gradient descent with the reparameterization gradient in the Euclidean space of variational parameters of a location-scale family.\n\nThis algorithm only supports subtypes of MvLocationScale. Also, since the stochastic proximal gradient descent does not use the entropy of the gradient, the entropy estimator to be used must have a zero-mean gradient. Thus, only the entropy estimators with a \"ZeroGradient\" suffix are allowed.\n\nArguments\n\nadtype: Automatic differentiation backend. \n\nKeyword Arguments\n\nentropy_zerograd: Estimator of the entropy with a zero-mean gradient to be used. Must be one of ClosedFormEntropyZeroGrad, StickingTheLandingEntropyZeroGrad. (default: ClosedFormEntropyZeroGrad())\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. Only DoG, DoWG and Optimisers.Descent are supported. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient.\naverager::AbstractAverager: Parameter averaging strategy. (default: PolynomialAveraging())\n\nRequirements\n\nThe variational family is MvLocationScale.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblems.logdensity(prob, x) must be differentiable with respect to x by the selected AD backend.\nAdditonal requirements on q may apply depending on the choice of entropy_zerograd.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/repgradelbo/#repgradelbo","page":"RepGradELBO","title":"Reparameterization Gradient Estimator","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/#Overview","page":"RepGradELBO","title":"Overview","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The RepGradELBO objective implements the reparameterization gradient estimator[HC1983][G1991][R1992][P1996] of the ELBO gradient. The reparameterization gradient, also known as the push-in gradient or the pathwise gradient, was introduced to VI in [TL2014][RMW2014][KW2014]. For the variational family mathcalQ = q_lambda mid lambda in Lambda, suppose the process of sampling from q_lambda can be described by some differentiable reparameterization function T_lambda and a base distribution varphi independent of lambda such that","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[HC1983]: Ho, Y. C., & Cao, X. (1983). Perturbation analysis and optimization of queueing networks. Journal of optimization theory and Applications, 40(4), 559-582.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[G1991]: Glasserman, P. (1991). Gradient estimation via perturbation analysis (Vol. 116). Springer Science & Business Media.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[R1992]: Rubinstein, R. Y. (1992). Sensitivity analysis of discrete event systems by the “push out” method. Annals of Operations Research, 39(1), 229-250.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[P1996]: Pflug, G. C. (1996). Optimization of stochastic models: the interface between simulation and optimization (Vol. 373). Springer Science & Business Media.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[TL2014]: Titsias, M., & Lázaro-Gredilla, M. (2014). Doubly stochastic variational Bayes for non-conjugate inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[RMW2014]: Rezende, D. J., Mohamed, S., & Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KW2014]: Kingma, D. P., & Welling, M. (2014). Auto-encoding variational bayes. In International Conference on Learning Representations.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= T_lambdaleft(epsilonright)quad epsilon sim varphi  ","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"In these cases, denoting the target log denstiy as log pi, we can effectively estimate the gradient of the ELBO by directly differentiating the stochastic estimate of the ELBO objective","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"  widehatmathrmELBOleft(lambdaright) = frac1Msum^M_m=1 log pileft(T_lambdaleft(epsilon_mright)right) + mathbbHleft(q_lambdaright)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"where epsilon_m sim varphi are Monte Carlo samples. The resulting gradient estimate is called the reparameterization gradient estimator.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"In addition to the reparameterization gradient, AdvancedVI provides the following features:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Posteriors with constrained supports are handled through Bijectors, which is known as the automatic differentiation VI (ADVI; [KTRGB2017]) formulation. (See this section.)\nThe gradient of the entropy can be estimated through various strategies depending on the capabilities of the variational family. (See this section.)","category":"page"},{"location":"paramspacesgd/repgradelbo/#RepGradELBO","page":"RepGradELBO","title":"RepGradELBO","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"To use the reparameterization gradient, AdvancedVI provides the following variational objective:","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.RepGradELBO","page":"RepGradELBO","title":"AdvancedVI.RepGradELBO","text":"RepGradELBO(n_samples; kwargs...)\n\nEvidence lower-bound objective with the reparameterization gradient formulation[TL2014][RMW2014][KW2014].\n\nArguments\n\nn_samples::Int: Number of Monte Carlo samples used to estimate the ELBO.\n\nKeyword Arguments\n\nentropy: The estimator for the entropy term. (Type <: AbstractEntropyEstimator; Default: ClosedFormEntropy())\n\nRequirements\n\nThe variational approximation q_lambda implements rand.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblem must have a capability at least LogDensityProblems.LogDensityOrder{1}().\nOnly the AD backend ReverseDiff, Zygote, Mooncake are supported.\nThe sampling process rand(q) must be differentiable by the selected AD backend.\n\nDepending on the options, additional requirements on q_lambda may apply.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/repgradelbo/#bijectors","page":"RepGradELBO","title":"Handling Constraints with Bijectors","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"As mentioned in the docstring, the RepGradELBO objective assumes that the variational approximation q_lambda and the target distribution pi have the same support for all lambda in Lambda.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"However, in general, it is most convenient to use variational families that have the whole Euclidean space mathbbR^d as their support. This is the case for the location-scale distributions provided by AdvancedVI. For target distributions which the support is not the full mathbbR^d, we can apply some transformation b to q_lambda to match its support such that","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"z sim  q_blambda qquadLeftrightarrowqquad\nz stackreld= b^-1left(etaright)quad eta sim q_lambda","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"where b is often called a bijector, since it is often chosen among bijective transformations. This idea is known as automatic differentiation VI[KTRGB2017] and has subsequently been improved by Tensorflow Probability[DLTBV2017]. In Julia, Bijectors.jl[FXTYG2020] provides a comprehensive collection of bijections.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"One caveat of ADVI is that, after applying the bijection, a Jacobian adjustment needs to be applied. That is, the objective is now","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"mathrmADVIleft(lambdaright)\ntriangleq\nmathbbE_eta sim q_lambdaleft\n  log pileft( b^-1left( eta right) right)\n  + log lvert J_b^-1left(etaright) rvert\nright\n+ mathbbHleft(q_lambdaright)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"This is automatically handled by AdvancedVI through TransformedDistribution provided by Bijectors.jl. See the following example:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"using Bijectors\nq = MeanFieldGaussian(μ, L)\nb = Bijectors.bijector(dist)\nbinv = inverse(b)\nq_transformed = Bijectors.TransformedDistribution(q, binv)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"By passing q_transformed to optimize, the Jacobian adjustment for the bijector b is automatically applied. (See Examples for a fully working example.)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[DLTBV2017]: Dillon, J. V., Langmore, I., Tran, D., Brevdo, E., Vasudevan, S., Moore, D., ... & Saurous, R. A. (2017). Tensorflow distributions. arXiv.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[FXTYG2020]: Fjelde, T. E., Xu, K., Tarek, M., Yalburgi, S., & Ge, H. (2020,. Bijectors. jl: Flexible transformations for probability distributions. In Symposium on Advances in Approximate Bayesian Inference.","category":"page"},{"location":"paramspacesgd/repgradelbo/#entropygrad","page":"RepGradELBO","title":"Entropy Estimators","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"For the gradient of the entropy term, we provide three choices with varying requirements. The user can select the entropy estimator by passing it as a keyword argument when constructing the RepGradELBO objective.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Estimator entropy(q) logpdf(q) Type\nClosedFormEntropy required  Deterministic\nMonteCarloEntropy  required Monte Carlo\nStickingTheLandingEntropy  required Monte Carlo with control variate","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The requirements mean that either Distributions.entropy or Distributions.logpdf need to be implemented for the choice of variational family. In general, the use of ClosedFormEntropy is recommended whenever possible. If entropy is not available, then StickingTheLandingEntropy is recommended. See the following section for more details.","category":"page"},{"location":"paramspacesgd/repgradelbo/#The-StickingTheLandingEntropy-Estimator","page":"RepGradELBO","title":"The StickingTheLandingEntropy Estimator","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The StickingTheLandingEntropy, or STL estimator, is a control variate approach [RWD2017].","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.StickingTheLandingEntropy","page":"RepGradELBO","title":"AdvancedVI.StickingTheLandingEntropy","text":"StickingTheLandingEntropy()\n\nThe \"sticking the landing\" entropy estimator[RWD2017].\n\nRequirements\n\nThe variational approximation q implements logpdf.\nlogpdf(q, η) must be differentiable by the selected AD framework.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"It occasionally results in lower variance when pi approx q_lambda, and higher variance when pi notapprox q_lambda. The conditions for which the STL estimator results in lower variance is still an active subject for research.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The main downside of the STL estimator is that it needs to evaluate and differentiate the log density of q_lambda, logpdf(q), in every iteration. Depending on the variational family, this might be computationally inefficient or even numerically unstable. For example, if q_lambda is a Gaussian with a full-rank covariance, a back-substitution must be performed at every step, making the per-iteration complexity mathcalO(d^3) and reducing numerical stability.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Let us come back to the example in Examples, where a LogDensityProblem is given as model. In this example, the true posterior is contained within the variational family. This setting is known as \"perfect variational family specification.\" In this case, the RepGradELBO estimator with StickingTheLandingEntropy is the only estimator known to converge exponentially fast (\"linear convergence\") to the true solution.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Recall that the original ADVI objective with a closed-form entropy (CFE) is given as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"n_montecarlo = 16;\nb = Bijectors.bijector(model);\nbinv = inverse(b)\n\nq0_trans = Bijectors.TransformedDistribution(q0, binv)\n\ncfe = KLMinRepGradDescent(\n    AutoReverseDiff(); entropy=ClosedFormEntropy(), optimizer=Adam(1e-2)\n)\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The repgradelbo estimator can instead be created as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"stl = KLMinRepGradDescent(\n    AutoReverseDiff(); entropy=StickingTheLandingEntropy(), optimizer=Adam(1e-2)\n)\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"We can see that the noise of the repgradelbo estimator becomes smaller as VI converges. However, the speed of convergence may not always be significantly different. Also, due to noise, just looking at the ELBO may not be sufficient to judge which algorithm is better. This can be made apparent if we measure convergence through the distance to the optimum:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"We can see that STL kicks-in at later stages of optimization. Therefore, when STL \"works\", it yields a higher accuracy solution even on large stepsizes. However, whether STL works or not highly depends on the problem[KMG2024]. Furthermore, in a lot of cases, a low-accuracy solution may be sufficient.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[RWD2017]: Roeder, G., Wu, Y., & Duvenaud, D. K. (2017). Sticking the landing: Simple, lower-variance gradient estimators for variational inference. Advances in Neural Information Processing Systems, 30.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KMG2024]: Kim, K., Ma, Y., & Gardner, J. (2024). Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. In International Conference on Artificial Intelligence and Statistics (pp. 235-243). PMLR.","category":"page"},{"location":"paramspacesgd/repgradelbo/#Advanced-Usage","page":"RepGradELBO","title":"Advanced Usage","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"There are two major ways to customize the behavior of RepGradELBO","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Customize the Distributions functions: rand(q), entropy(q), logpdf(q).\nCustomize AdvancedVI.reparam_with_entropy.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"It is generally recommended to customize rand(q), entropy(q), logpdf(q), since it will easily compose with other functionalities provided by AdvancedVI.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The most advanced way is to customize AdvancedVI.reparam_with_entropy. In particular, reparam_with_entropy is the function that invokes rand(q), entropy(q), logpdf(q). Thus, it is the most general way to override the behavior of RepGradELBO.","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.reparam_with_entropy","page":"RepGradELBO","title":"AdvancedVI.reparam_with_entropy","text":"reparam_with_entropy(rng, q, q_stop, n_samples, ent_est)\n\nDraw n_samples from q and compute its entropy.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nq: Variational approximation.\nq_stop: Same as q, but held constant during differentiation. Should only be used for computing the entropy.\nn_samples::Int: Number of Monte Carlo samples \nent_est: The entropy estimation strategy. (See estimate_entropy.)\n\nReturns\n\nsamples: Monte Carlo samples generated through reparameterization. Their support matches that of the target distribution.\nentropy: An estimate (or exact value) of the differential entropy of q.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"To illustrate how we can customize the rand(q) function, we will implement quasi-Monte-Carlo variational inference[BWM2018]. Consider the case where we use the MeanFieldGaussian variational family. In this case, it suffices to override its rand specialization as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"using QuasiMonteCarlo\nusing StatsFuns\n\nqmcrng = SobolSample(; R=OwenScramble(; base=2, pad=32))\n\nfunction Distributions.rand(\n    rng::AbstractRNG, q::MvLocationScale{<:Diagonal,D,L}, num_samples::Int\n) where {L,D}\n    (; location, scale, dist) = q\n    n_dims = length(location)\n    scale_diag = diag(scale)\n    unif_samples = QuasiMonteCarlo.sample(num_samples, length(q), qmcrng)\n    std_samples = norminvcdf.(unif_samples)\n    return scale_diag .* std_samples .+ location\nend\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Note that this is a quick-and-dirty example, and there are more sophisticated ways to implement this.)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"By plotting the ELBO, we can see the effect of quasi-Monte Carlo. (Image: ) We can see that quasi-Monte Carlo results in much lower variance than naive Monte Carlo. However, similarly to the STL example, just looking at the ELBO is often insufficient to really judge performance. Instead, let's look at the distance to the global optimum:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"QMC yields an additional order of magnitude in accuracy. Also, unlike STL, it ever-so slightly accelerates convergence. This is because quasi-Monte Carlo uniformly reduces variance, unlike STL, which reduces variance only near the optimum.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[BWM2018]: Buchholz, A., Wenzel, F., & Mandt, S. (2018). Quasi-monte carlo variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/general/#paramspacesgd","page":"General","title":"General","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"ParamSpaceSGD SGD is a general algorithm for leveraging automatic differentiation and SGD. Furthermore, it operates in the space of variational parameters. Consider the case where each member q_lambda in mathcalQ of the variational family mathcalQ is uniquely represented through a collection of parameters lambda in Lambda subseteq mathbbR^p.  That is,","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"mathcalQ = q_lambda mid lambda in Lambda ","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Then, as implied by the name, ParamSpaceSGD runs SGD on Lambda, the (Euclidean) space of parameters.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Any algorithm that operates by iterating the following steps can easily be implemented via  ParamSpaceSGD:","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Obtain an unbiased estimate of the target objective.\nObtain an estimate of the gradient of the objective by differentiating the objective estimate with respect to the parameters.\nPerform gradient descent with the stochastic gradient estimate.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"After some simplifications, each step of ParamSpaceSGD can be described as follows:","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"function step(rng, alg::ParamSpaceSGD, state, callback, objargs...; kwargs...)\n    (; adtype, problem, objective, operator, averager) = alg\n    (; q, iteration, grad_buf, opt_st, obj_st, avg_st) = state\n    iteration += 1\n\n    # Extract variational parameters of `q`\n    params, re = Optimisers.destructure(q)\n\n    # Estimate gradient and update the `DiffResults` buffer `grad_buf`.\n    grad_buf, obj_st, info = estimate_gradient!(...)\n\n    # Gradient descent step.\n    grad = DiffResults.gradient(grad_buf)\n    opt_st, params = Optimisers.update!(opt_st, params, grad)\n\n    # Apply operator\n    params = apply(operator, typeof(q), opt_st, params, re)\n\n    # Apply parameter averaging\n    avg_st = apply(averager, avg_st, params)\n\n    # Updated state\n    state = ParamSpaceSGDState(re(params), iteration, grad_buf, opt_st, obj_st, avg_st)\n    state, false, info\nend","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"The output of ParamSpaceSGD is the final state of averager. Furthermore, operator can be anything from an identity mapping, a projection operator, a proximal operator, and so on.","category":"page"},{"location":"paramspacesgd/general/#ParamSpaceSGD","page":"General","title":"ParamSpaceSGD","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"The constructor for ParamSpaceSGD is as follows:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.ParamSpaceSGD","page":"General","title":"AdvancedVI.ParamSpaceSGD","text":"ParamSpaceSGD(\n    objective::AbstractVariationalObjective,\n    adtype::ADTypes.AbstractADType,\n    optimizer::Optimisers.AbstractRule,\n    averager::AbstractAverager,\n    operator::AbstractOperator,\n)\n\nThis algorithm applies stochastic gradient descent (SGD) to the variational objective over the (Euclidean) space of variational parameters.\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\n\nnote: Note\nDifferent objective may impose different requirements on adtype, variational family, optimizer, and operator. It is therefore important to check the documentation corresponding to each specific objective. Essentially, each objective should be thought as forming its own unique algorithm.\n\nArguments\n\nobjective: Variational Objective.\nadtype: Automatic differentiation backend. \noptimizer: Optimizer used for inference.\naverager : Parameter averaging strategy.\noperator : Operator applied to the parameters after each optimization step.\n\nOutput\n\nq_averaged: The variational approximation formed from the averaged SGD iterates.\n\nCallback\n\nThe callback function callback has a signature of\n\ncallback(; rng, iteration, restructure, params, averaged_params, restructure, gradient)\n\nThe arguments are as follows:\n\nrng: Random number generator internally used by the algorithm.\niteration: The index of the current iteration.\nrestructure: Function that restructures the variational approximation from the variational parameters. Calling restructure(params) reconstructs the current variational approximation. \nparams: Current variational parameters.\naveraged_params: Variational parameters averaged according to the averaging strategy.\ngradient: The estimated (possibly stochastic) gradient.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/general/#Objective-Interface","page":"General","title":"Objective Interface","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"To define an instance of a ParamSpaceSGD algorithm, it suffices to implement the AbstractVariationalObjective interface. First, we need to define a subtype of AbstractVariationalObjective:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.AbstractVariationalObjective","page":"General","title":"AdvancedVI.AbstractVariationalObjective","text":"AbstractVariationalObjective\n\nAbstract type for the VI algorithms supported by AdvancedVI.\n\nImplementations\n\nTo be supported by AdvancedVI, a VI algorithm must implement AbstractVariationalObjective and estimate_objective. Also, it should provide gradients by implementing the function estimate_gradient. If the estimator is stateful, it can implement init to initialize the state.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"In addition, we need to implement some methods associated with the objective. First, each objective may maintain a state such as buffers, online estimates of control variates, batch iterators for subsampling, and so on. Such things should be initialized by implementing the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.init-Tuple{AbstractRNG, AdvancedVI.AbstractVariationalObjective, AbstractADType, Any, Any, Any}","page":"General","title":"AdvancedVI.init","text":"init(rng, obj, adtype, prob, params, restructure)\n\nInitialize a state of the variational objective obj given the initial variational parameters λ. This function needs to be implemented only if obj is stateful.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\n\nadtype::ADTypes.AbstractADType`: Automatic differentiation backend.\n\nparams: Initial variational parameters.\nrestructure: Function that reconstructs the variational approximation from λ.\n\n\n\n\n\n","category":"method"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"If this method is not implemented, the state will be automatically be nothing.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Next, the key functionality of estimating stochastic gradients should be implemented through the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.estimate_gradient!","page":"General","title":"AdvancedVI.estimate_gradient!","text":"estimate_gradient!(rng, obj, adtype, out, params, restructure, obj_state)\n\nEstimate (possibly stochastic) gradients of the variational objective obj targeting prob with respect to the variational parameters λ\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\nadtype::ADTypes.AbstractADType: Automatic differentiation backend. \nout::DiffResults.MutableDiffResult: Buffer containing the objective value and gradient estimates. \nparams: Variational parameters to evaluate the gradient on.\nrestructure: Function that reconstructs the variational approximation from params.\nobj_state: Previous state of the objective.\n\nReturns\n\nout::MutableDiffResult: Buffer containing the objective value and gradient estimates.\nobj_state: The updated state of the objective.\nstat::NamedTuple: Statistics and logs generated during estimation.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"AdvancedVI only interacts with each variational objective by querying gradient estimates. In a lot of cases, however, it is convinient to be able to estimate the current value of the objective. For example, for monitoring convergence. This should be done through the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.estimate_objective","page":"General","title":"AdvancedVI.estimate_objective","text":"estimate_objective([rng,] obj, q, prob; kwargs...)\n\nEstimate the variational objective obj targeting prob with respect to the variational approximation q.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\nprob: The target log-joint likelihood implementing the LogDensityProblem interface.\nq: Variational approximation.\n\nKeyword Arguments\n\nDepending on the objective, additional keyword arguments may apply. Please refer to the respective documentation of each variational objective for more info.\n\nReturns\n\nobj_est: Estimate of the objective value.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/klminscoregraddescent/#klminscoregraddescent","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"","category":"section"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"This is a convenience constructor for ParamSpaceSGD with the ScoreGradELBO objective. This is similar to the algorithm that was originally referred to as black-box variational inference (BBVI; [RGB2014][WW2013]). (The term BBVI has also recently been used to refer to the more general setup of maximizing the ELBO in parameter space. We are using the more narrow definition, which restricts to the use of the score gradient.) However, instead of using the vanilla score gradient estimator, we differentiate the \"VarGrad\" objective[RBNRA2020], which results in the score gradient variance-reduced by the leave-one-out control variate[SK2014][KvHW2019].","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[RGB2014]: Ranganath, R., Gerrish, S., & Blei, D. (2014, April). Black box variational inference. In Artificial Intelligence and Statistics (pp. 814-822). PMLR.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[WW2013]: Wingate, D., & Weber, T. (2013). Automated variational inference in probabilistic programming. arXiv preprint arXiv:1301.1299.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[RBNRA2020]: Richter, L., Boustati, A., Nüsken, N., Ruiz, F., & Akyildiz, O. D. (2020). Vargrad: a low-variance gradient estimator for variational inference. Advances in Neural Information Processing Systems, 33, 13481-13492.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[SK2014]: Salimans, T., & Knowles, D. A. (2014). On using control variates with stochastic approximation for variational bayes and its connection to stochastic linear regression. arXiv preprint arXiv:1401.1022.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[KvHW2019]: Kool, W., van Hoof, H., & Welling, M. (2019). Buy 4 reinforce samples, get a baseline for free!.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/#AdvancedVI.KLMinScoreGradDescent","page":"KLMinScoreGradDescent","title":"AdvancedVI.KLMinScoreGradDescent","text":"KLMinScoreGradDescent(adtype; optimizer, n_samples, averager, operator)\n\nKL divergence minimization by running stochastic gradient descent with the score gradient in the Euclidean space of variational parameters.\n\nArguments\n\nadtype: Automatic differentiation backend. \n\nKeyword Arguments\n\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. Only DoG, DoWG and Optimisers.Descent are supported. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient.\naverager::AbstractAverager: Parameter averaging strategy. (default: PolynomialAveraging())\noperator::Union{<:IdentityOperator, <:ClipScale}: Operator to be applied after each gradient descent step. (default: IdentityOperator())\n\nRequirements\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\nThe variational approximation q_lambda implements rand.\nThe variational approximation q_lambda implements logpdf(q, x), which should also be differentiable with respect to x.\nThe target distribution and the variational approximation have the same support.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/objectives/#Overview-of-Algorithms","page":"Overview","title":"Overview of Algorithms","text":"","category":"section"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"This section will provide an overview of the algorithm form by each objectives provided by AdvancedVI.","category":"page"},{"location":"paramspacesgd/objectives/#Evidence-Lower-Bound-Maximization","page":"Overview","title":"Evidence Lower Bound Maximization","text":"","category":"section"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"Evidence lower bound (ELBO) maximization[JGJS1999] is a general family of algorithms that minimize the exclusive (or reverse) Kullback-Leibler (KL) divergence between the target distribution pi and a variational approximation q_lambda. More generally, it aims to solve the problem","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmminimize_q in mathcalQquad mathrmKLleft(q piright)  ","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"where mathcalQ is some family of distributions, often called the variational family. Since we usually only have access to the unnormalized densities of the target distribution pi, we don't have direct access to the KL divergence. Instead, the ELBO maximization strategy maximizes a surrogate objective, the ELBO:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmELBOleft(qright) triangleq mathbbE_theta sim q log pileft(thetaright) + mathbbHleft(qright)","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"which is equivalent to the KL up to an additive constant (the evidence). The ELBO and its gradient can be readily estimated through various strategies. Overall, ELBO maximization algorithms aim to solve the problem:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmminimize_q in mathcalQquad -mathrmELBOleft(qright)","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"Multiple ways to solve this problem exist, each leading to a different variational inference algorithm. AdvancedVI provides the following objectives:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"RepGradELBO: Implements the reparameterization gradient estimator of the ELBO gradient.\nScoreGradELBO: Implements the score gradient estimator of the ELBO gradient.","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"[JGJS1999]: Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., & Saul, L. K. (1999). An introduction to variational methods for graphical models. Machine learning, 37, 183-233.","category":"page"},{"location":"paramspacesgd/scoregradelbo/#scoregradelbo","page":"ScoreGradELBO","title":"Score Gradient Estimator","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/#Overview","page":"ScoreGradELBO","title":"Overview","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"The ScoreGradELBO implements the score gradient estimator[G1990][KR1996][RSU1996][W1992] of the ELBO gradient, also known as the score function method and the REINFORCE gradient. For variational inference, the use of the score gradient was proposed in [WW2013][RGB2014]. Unlike the reparameterization gradient, the score gradient does not require the target log density to be differentiable, and does not differentiate through the sampling process of the variational approximation q. Instead, it only requires gradients of the log density log q. For this reason, the score gradient is the standard method to deal with discrete variables and targets with discrete support.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[G1990]: Glynn, P. W. (1990). Likelihood ratio gradient estimation for stochastic systems. Communications of the ACM, 33(10), 75-84.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[KR1996]: Kleijnen, J. P., & Rubinstein, R. Y. (1996). Optimization and sensitivity analysis of computer simulation models by the score function method. European Journal of Operational Research, 88(3), 413-427.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RSU1996]: Rubinstein, R. Y., Shapiro, A., & Uryasev, S. (1996). The score function method. Encyclopedia of Management Sciences, 1363-1366.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[W1992]: Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8, 229-256.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[WW2013]: Wingate, D., & Weber, T. (2013). Automated variational inference in probabilistic programming. arXiv preprint arXiv:1301.1299.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RGB2014]: Ranganath, R., Gerrish, S., & Blei, D. (2014). Black box variational inference. In Artificial intelligence and statistics (pp. 814-822). PMLR. In more detail, the score gradient uses the Fisher log-derivative identity: For any regular f,","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"nabla_lambda mathbbE_z sim q_lambda f\n=\nmathbbE_z sim q_lambdaleft f(z) log q_lambda(z) right  ","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"The ELBO corresponds to the case where f = log pi  log q, where log pi is the target log density.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"Instead of implementing the canonical score gradient, ScoreGradELBO uses the \"VarGrad\" objective[RBNRA2020]:","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"widehatmathrmVarGrad(lambda) \n=\nmathrmVarleft( log q_lambda(z_i) - log pileft(z_iright) right)  ","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"where the variance is computed over the samples z_1 ldots z_m sim q_lambda. Differentiating the VarGrad objective corresponds to the canonical score gradient combined with the \"leave-one-out\" control variate[SK2014][KvHW2019].","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RBNRA2020]: Richter, L., Boustati, A., Nüsken, N., Ruiz, F., & Akyildiz, O. D. (2020). Vargrad: a low-variance gradient estimator for variational inference. Advances in Neural Information Processing Systems, 33, 13481-13492.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[SK2014]: Salimans, T., & Knowles, D. A. (2014). On using control variates with stochastic approximation for variational bayes and its connection to stochastic linear regression. arXiv preprint arXiv:1401.1022.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[KvHW2019]: Kool, W., van Hoof, H., & Welling, M. (2019). Buy 4 reinforce samples, get a baseline for free!. Since the expectation of the VarGrad objective (not its gradient) is not exactly the ELBO, we separately obtain an unbiased estimate of the ELBO to be returned by estimate_objective.","category":"page"},{"location":"paramspacesgd/scoregradelbo/#ScoreGradELBO","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/#AdvancedVI.ScoreGradELBO","page":"ScoreGradELBO","title":"AdvancedVI.ScoreGradELBO","text":"ScoreGradELBO(n_samples; kwargs...)\n\nEvidence lower-bound objective computed with score function gradient with the VarGrad objective, also known as the leave-one-out control variate.\n\nArguments\n\nn_samples::Int: Number of Monte Carlo samples used to estimate the VarGrad objective.\n\nRequirements\n\nThe variational approximation q_lambda implements rand and logpdf.\nlogpdf(q, x) must be differentiable with respect to q by the selected AD backend.\nThe target distribution and the variational approximation have the same support.\n\n\n\n\n\n","category":"type"},{"location":"examples/#examples","page":"Examples","title":"Evidence Lower Bound Maximization","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In this tutorial, we will work with a normal-log-normal model.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"beginaligned\nx sim mathrmLogNormalleft(mu_x sigma_x^2right) \ny sim mathcalNleft(mu_y sigma_y^2right)\nendaligned","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"BBVI with Bijectors.Exp bijectors is able to infer this model exactly.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Using the LogDensityProblems interface, we the model can be defined as follows:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using LogDensityProblems\n\nstruct NormalLogNormal{MX,SX,MY,SY}\n    μ_x::MX\n    σ_x::SX\n    μ_y::MY\n    Σ_y::SY\nend\n\nfunction LogDensityProblems.logdensity(model::NormalLogNormal, θ)\n    (; μ_x, σ_x, μ_y, Σ_y) = model\n    return logpdf(LogNormal(μ_x, σ_x), θ[1]) + logpdf(MvNormal(μ_y, Σ_y), θ[2:end])\nend\n\nfunction LogDensityProblems.dimension(model::NormalLogNormal)\n    return length(model.μ_y) + 1\nend\n\nfunction LogDensityProblems.capabilities(::Type{<:NormalLogNormal})\n    return LogDensityProblems.LogDensityOrder{0}()\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's now instantiate the model","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using LinearAlgebra\n\nn_dims = 10\nμ_x = randn()\nσ_x = exp.(randn())\nμ_y = randn(n_dims)\nσ_y = exp.(randn(n_dims))\nmodel = NormalLogNormal(μ_x, σ_x, μ_y, Diagonal(σ_y .^ 2));\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Some of the VI algorithms require gradients of the target log-density. In this example, we will use KLMinRepGradDescent, which requires first-order differentiation capability. For this, we can rely on LogDensityProblemsAD:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using LogDensityProblemsAD\nusing ADTypes, ReverseDiff\n\nmodel_ad = ADgradient(AutoReverseDiff(), model)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's now load AdvancedVI. In addition to gradients of the target log-density, KLMinRepGradDescent internally uses automatic differentiation. Therefore, we have to select an AD framework to be used within KLMinRepGradDescent. (This does not need to be the same as the backend used by model_ad.) The selected AD framework needs to be communicated to AdvancedVI using the ADTypes interface. Here, we will use ForwardDiff, which can be selected by later passing ADTypes.AutoForwardDiff().","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Optimisers\nusing AdvancedVI\n\nalg = KLMinRepGradDescent(AutoReverseDiff());\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now, KLMinRepGradDescent requires the variational approximation and the target log-density to have the same support. Since y follows a log-normal prior, its support is bounded to be the positive half-space mathbbR_+. Thus, we will use Bijectors to match the support of our target posterior and the variational approximation.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Bijectors\n\nfunction Bijectors.bijector(model::NormalLogNormal)\n    (; μ_x, σ_x, μ_y, Σ_y) = model\n    return Bijectors.Stacked(\n        Bijectors.bijector.([LogNormal(μ_x, σ_x), MvNormal(μ_y, Σ_y)]),\n        [1:1, 2:(1 + length(μ_y))],\n    )\nend\n\nb = Bijectors.bijector(model);\nbinv = inverse(b)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For the variational family, we will use the classic mean-field Gaussian family.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"d = LogDensityProblems.dimension(model);\nμ = randn(d);\nL = Diagonal(ones(d));\nq0 = AdvancedVI.MeanFieldGaussian(μ, L)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"And then, we now apply the bijector to the variational family.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"q0_trans = Bijectors.TransformedDistribution(q0, binv)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Passing objective and the initial variational approximation q to optimize performs inference.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"n_max_iter = 10^4\nq_out, info, _ = AdvancedVI.optimize(\n    alg, n_max_iter, model_ad, q0_trans; show_progress=false\n);\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"ClipScale is a projection operator, which ensures that the variational approximation stays within a stable region of the variational family. For more information see this section.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"q_out is the final output of the optimization procedure. If a parameter averaging strategy is used through the keyword argument averager, q_out is be the output of the averaging strategy.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The selected inference procedure stores per-iteration statistics into stats. For instance, the ELBO can be ploted as follows:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Plots\n\nt = [i.iteration for i in info]\ny = [i.elbo for i in info]\nplot(t, y; label=\"BBVI\", xlabel=\"Iteration\", ylabel=\"ELBO\")\nsavefig(\"bbvi_example_elbo.svg\")\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Further information can be gathered by defining your own callback!.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The final ELBO can be estimated by calling the objective directly with a different number of Monte Carlo samples as follows:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"estimate_objective(RepGradELBO(10^4), q_out, model)","category":"page"},{"location":"general/#general","page":"General Usage","title":"General Usage","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"AdvancedVI provides multiple variational inference (VI) algorithms. Each algorithm defines its subtype of AdvancedVI.AbstractAlgorithm with some corresponding methods (see this section). Then the algorithm can be executed by invoking optimize. (See this section).","category":"page"},{"location":"general/#optimize","page":"General Usage","title":"Optimize","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Given a subtype of AbstractAlgorithm associated with each algorithm, it suffices to call the function optimize:","category":"page"},{"location":"general/#AdvancedVI.optimize","page":"General Usage","title":"AdvancedVI.optimize","text":"optimize(\n    [rng::Random.AbstractRNG = Random.default_rng(),]\n    algorithm::AbstractAlgorithm,\n    max_iter::Int,\n    prob,\n    q_init,\n    args...;\n    kwargs...\n)\n\nRun variational inference algorithm on the problem implementing the LogDensityProblems interface. For more details on the usage, refer to the documentation corresponding to algorithm.\n\nArguments\n\nrng: Random number generator.\nalgorithm: Variational inference algorithm.\nmax_iter::Int: Maximum number of iterations.\nprob: Target LogDensityProblem \nq_init: Initial variational distribution.\nargs...: Arguments to be passed to algorithm.\n\nKeyword Arguments\n\nshow_progress::Bool: Whether to show the progress bar. (Default: true.)\nstate::Union{<:Any,Nothing}: Initial value for the internal state of optimization. Used to warm-start from the state of a previous run. (See the returned values below.)\ncallback: Callback function called after every iteration. See further information below. (Default: nothing.)\nprogress::ProgressMeter.AbstractProgress: Progress bar configuration. (Default: ProgressMeter.Progress(n_max_iter; desc=\"Optimizing\", barlen=31, showspeed=true, enabled=prog).)\nkwargs...: Keyword arguments to be passed to algorithm.\n\nReturns\n\noutput: The output of the variational inference algorithm.\ninfo: Array of NamedTuples, where each NamedTuple contains information generated at each iteration.\nstate: Collection of the final internal states of optimization. This can used later to warm-start from the last iteration of the corresponding run.\n\nCallback\n\nThe signature of the callback function depends on the algorithm in use. Thus, see the documentation for each algorithm. However, a callback should return either a nothing or a NamedTuple containing information generated during the current iteration. The content of the NamedTuple will be concatenated into the corresponding entry in the info array returns in the end of the call to optimize and will be displayed on the progress meter.\n\n\n\n\n\n","category":"function"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Each algorithm may interact differently with the arguments of optimize. Therefore, please refer to the documentation of each different algorithm for a detailed description on their behavior and their requirements.","category":"page"},{"location":"general/#algorithm","page":"General Usage","title":"Algorithm Interface","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"A variational inference algorithm supported by AdvancedVI should define its own subtype of AbstractAlgorithm:","category":"page"},{"location":"general/#AdvancedVI.AbstractAlgorithm","page":"General Usage","title":"AdvancedVI.AbstractAlgorithm","text":"AbstractAlgorithm\n\nAbstract type for a variational inference algorithm.\n\n\n\n\n\n","category":"type"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The functionality of each algorithm is then implemented through the following methods:","category":"page"},{"location":"general/#AdvancedVI.init-Tuple{AbstractRNG, AdvancedVI.AbstractAlgorithm, Any, Any}","page":"General Usage","title":"AdvancedVI.init","text":"init(rng, alg, prob, q_init)\n\nInitialize alg given the initial variational approximation q_init and the target prob.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nalg::AbstractAlgorithm: Variational inference algorithm.\nprob: Target problem.\n\nq_init`: Initial variational approximation.\n\n\n\n\n\n","category":"method"},{"location":"general/#AdvancedVI.step","page":"General Usage","title":"AdvancedVI.step","text":"step(rng, alg, state, callback, objargs...; kwargs...)\n\nPerform a single step of alg given the previous stat.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nalg::AbstractAlgorithm: Variational inference algorithm.\nstate: Previous state of the algorithm.\ncallback: Callback function to be called during the step.\n\nReturns\n\nstate: New state generated by performing the step.\nterminate::Bool: Whether to terminate the algorithm after the step.\ninfo::NamedTuple: Information generated during the step. \n\n\n\n\n\n","category":"function"},{"location":"general/#AdvancedVI.output","page":"General Usage","title":"AdvancedVI.output","text":"output(alg, state)\n\nGenerate an output variational approximation using the last state of alg.\n\nArguments\n\nalg::AbstractAlgorithm: Variational inference algorithm used to compute the state.\nstate: The last state generated by the algorithm.\n\nReturns\n\nout: The output of the algorithm. \n\n\n\n\n\n","category":"function"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The role of each method should be self-explanatory and should be clear once we take a look at how optimize interacts with each algorithm. The operation of optimize can be simplified as follows:","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"function optimize([rng,] algorithm, max_iter, q_init, objargs; kwargs...)\n    info_total = NamedTuple[]\n    state = init(rng, algorithm, q_init)\n    for t in 1:max_iter\n        info = (iteration=t,)\n        state, terminate, info′ = step(\n            rng, algorithm, state, callback, objargs...; kwargs...\n        )\n        info = merge(info′, info)\n\n        if terminate\n            break\n        end\n\n        push!(info_total, info)\n    end\n    out = output(algorithm, state)\n    return out, info_total, state\nend","category":"page"},{"location":"#AdvancedVI","page":"AdvancedVI","title":"AdvancedVI","text":"","category":"section"},{"location":"","page":"AdvancedVI","title":"AdvancedVI","text":"AdvancedVI provides implementations of variational Bayesian inference (VI) algorithms. VI algorithms perform scalable and computationally efficient Bayesian inference at the cost of asymptotic exactness. AdvancedVI is part of the Turing probabilistic programming ecosystem.","category":"page"},{"location":"#List-of-Algorithms","page":"AdvancedVI","title":"List of Algorithms","text":"","category":"section"},{"location":"","page":"AdvancedVI","title":"AdvancedVI","text":"ParamSpaceSGD\nKLMinRepGradDescent (alias of ADVI)\nKLMinRepGradProxDescent\nKLMinScoreGradDescent  (alias of BBVI)","category":"page"}]
}
