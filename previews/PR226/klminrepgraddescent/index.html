<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>KLMinRepGradDescent · AdvancedVI.jl</title><meta name="title" content="KLMinRepGradDescent · AdvancedVI.jl"/><meta property="og:title" content="KLMinRepGradDescent · AdvancedVI.jl"/><meta property="twitter:title" content="KLMinRepGradDescent · AdvancedVI.jl"/><meta name="description" content="Documentation for AdvancedVI.jl."/><meta property="og:description" content="Documentation for AdvancedVI.jl."/><meta property="twitter:description" content="Documentation for AdvancedVI.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body>
<!-- NAVBAR START -->
<style>
    @import url('https://fonts.googleapis.com/css2?family=Source+Sans+Pro&display=swap');

    /* Documenter.jl CSS Overrides */
    html {
        scroll-padding-top: calc(var(--navbar-height) + 1rem);
    }
    .docs-sidebar, #documenter {
        margin-top: var(--navbar-height);
    }
    .docs-version-selector {
        margin-bottom: 60px !important;
    }
    @media screen and (max-width: 1056px) {
        .docs-version-selector {
            margin-bottom: 60px !important;
        }
        .docs-sidebar {
            margin-top: 0 !important;
        }
    }
    /* End of Documenter.jl Tweaks */

    /* Color and Font Variables */
    :root {
        --heading-color: #6c757d;
        --item-color: rgb(165, 165, 165);
        --primary-bg: white;
        --hover-color: #8faad2;
        --deprecated-bg: #ff4d4d;
        --deprecated-text: white;
        --icon-color: #6c757d;
        --shadow-color: rgba(0, 0, 0, 0.1);
        --dropdown-hover-bg: #e9ecef;
        
        /* Typography */
        --font-family: "Source Sans Pro", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
        --nav-link-font-size: 1.0625rem;
        --turing-title-font-size: 21.25px;
        --icon-font-size: 1.25rem;
        --dropdown-arrow-font-size: 0.6875rem;
        --badge-font-size: 0.75rem;

        /* Sizing and Spacing */
        --navbar-height: 3.75rem;
        --logo-height: 31px;
        --logo-width: auto;
        --logo-padding-top: 7px;
        --logo-margin-left: 0.8rem;
        --title-margin-left: 0.4px;
        --title-nav-spacing: 1.1rem;
        --nav-item-margin-left: 1.3rem;
        --icon-margin-left: 1rem;
        --dropdown-padding: 1.875rem;
        --dropdown-item-width: 12.5rem;
        --dropdown-subitem-width: 15.625rem;
        --dropdown-subitem-padding: 0.125rem 0.625rem;
    }

    /* Dark Theme Variable Overrides */
    html.theme--documenter-dark {
        --heading-color: #e0e0e0;
        --item-color: #bdbdbd;
        --primary-bg: #1f2424;
        --hover-color: #ffffff;
        --icon-color: #e0e0e0;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #424242;
    }

    /* Catppuccin Theme Overrides */
    html.theme--catppuccin-latte {
        --heading-color: #4c4f69;
        --primary-bg: #eff1f5;
        --icon-color: #4c4f69;
        --shadow-color: rgba(0, 0, 0, 0.1);
        --dropdown-hover-bg: #e6e9ef;
    }
    html.theme--catppuccin-frappe {
        --heading-color: #c6d0f5;
        --primary-bg: #303446;
        --icon-color: #c6d0f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #51576d;
    }
    html.theme--catppuccin-macchiato {
        --heading-color: #cad3f5;
        --primary-bg: #24273a;
        --icon-color: #cad3f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #494d64;
    }
    html.theme--catppuccin-mocha {
        --heading-color: #cad3f5;
        --primary-bg: #1e1e2e;
        --icon-color: #cad3f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #45475a;
    }


    /* Main Navigation Bar */
    .ext-navigation {
        font-family: var(--font-family);
        position: fixed;
        height: var(--navbar-height);
        top: 0;
        width: 100%;
        background-color: var(--primary-bg);
        z-index: 1000;
        box-shadow: 0 2px 4px var(--shadow-color);
        display: flex;
        align-items: center;
        padding: 0 1.0625rem;
        transition: transform 0.3s, background-color 0.3s;
    }

    nav.ext-navigation .ext-navbar-logo {
        margin-left: var(--logo-margin-left);
        height: auto;
        max-height: var(--logo-height);
        width: auto;
        padding-top: var(--logo-padding-top);
    }
    
    /* Theme-aware logo text color */
    .ext-navbar-logo .logo-text {
        fill: var(--heading-color);
    }
    
    .ext-navbar-title {
        color: var(--heading-color) !important;
        font-size: var(--turing-title-font-size) !important;
        margin-left: var(--title-margin-left);
        text-decoration: none;
        transition: color 0.2s ease;
    }
    
    .ext-navbar-title:hover {
        color: var(--hover-color) !important;
    }

    .ext-nav-links {
        display: flex;
        align-items: center;
        list-style-type: none;
        margin: 0;
        padding: 0;
        flex-grow: 1;
        margin-left: var(--title-nav-spacing);
    }

    .ext-nav-links li:first-child {
        margin-left: 0 !important;
    }

    .ext-nav-links li {
        margin-left: var(--nav-item-margin-left) !important;
    }

    .ext-nav-link {
        color: var(--heading-color) !important;
        text-decoration: none;
        font-size: var(--nav-link-font-size) !important;
        transition: color 0.2s ease;
        cursor: pointer;
    }

    .ext-nav-link:hover,
    .ext-navbar-item-single a:hover,
    .ext-navbar-icons a:hover {
        color: var(--hover-color) !important;
    }

    .ext-navbar-item-single a {
        color: var(--heading-color) !important;
    }
    
    .ext-navbar-icons {
        display: flex;
        align-items: center;
    }

    .ext-navbar-icons a {
        color: var(--icon-color) !important;
        font-size: var(--icon-font-size) !important;
        transition: color 0.2s ease;
        margin-left: var(--icon-margin-left);
    }

    .ext-menu-toggle {
        display: none;
        font-size: 1.5rem;
        color: var(--heading-color);
        cursor: pointer;
    }

    .ext-dropdown {
        display: none;
        grid-template-columns: 1fr 1fr 1fr 1fr;
        padding: var(--dropdown-padding);
        position: absolute;
        top: var(--navbar-height);
        width: 100%;
        left: 0;
        background-color: var(--primary-bg);
        line-height: 1.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out, background-color 0.3s;
        transform: translateY(-0.625rem);
        box-shadow: 0 4px 6px var(--shadow-color);
    }

    #library-handler::after {
        content: "▼";
        font-size: var(--dropdown-arrow-font-size);
        margin-left: 0.3125rem;
        transition: transform 0.3s ease-in-out;
    }

    #library-handler.open::after {
        content: "▲";
    }

    .ext-dropdown.show {
        display: grid;
        opacity: 1;
        transform: translateY(0);
    }

    .ext-dropdown ul {
        width: var(--dropdown-item-width);
        margin-bottom: 1.25rem;
    }

    .ext-dropdown ul li {
        text-align: left;
        display: flex;
        align-items: center;
    }

    .ext-dropdown ul a li {
        color: var(--item-color);
        width: var(--dropdown-subitem-width);
        border-radius: 3px;
        padding: var(--dropdown-subitem-padding);
        transition: background-color 0.2s ease;
    }

    .ext-dropdown ul a li:hover {
        background-color: var(--dropdown-hover-bg);
    }

    .ext-dropdown-item-heading {
        color: var(--heading-color);
        text-align: center;
    }

    .deprecated-badge {
        background-color: var(--deprecated-bg);
        color: var(--deprecated-text);
        font-size: var(--badge-font-size);
        padding: .1rem;
        border-radius: 3px;
        margin-left: 0.5rem;
        line-height: 1;
    }

    @media (max-width: 966px) {
        .ext-dropdown {
            grid-template-columns: 1fr 1fr 1fr;
        }
    }

    @media (max-width: 768px) {
        .ext-nav-links {
            display: none;
            flex-direction: column;
            align-items: center;
            width: 100%;
            background-color: var(--primary-bg);
            position: absolute;
            top: var(--navbar-height);
            left: 0;
            padding: 0.625rem 0;
            height: auto;
            overflow-y: auto;
            box-shadow: 0 4px 6px var(--shadow-color);
            margin-left: 0;
        }

        .ext-nav-links.show {
            display: flex;
        }

        .ext-nav-links li {
            margin: 0.625rem 0 !important;
            text-align: center;
        }
        
        .ext-menu-toggle {
            display: block;
            margin-left: auto;
        }

        .ext-navigation.hide {
            transform: translateY(calc(-1 * var(--navbar-height)));
        }

        .ext-dropdown {
            position: static;
            display: block;
            opacity: 1;
            transform: none;
            box-shadow: none;
            grid-template-columns: 1fr;
            padding: 0.625rem;
            text-align: center;
        }

        .ext-dropdown ul {
            width: auto;
            display: inline-block;
            margin: 0 auto 0.3125rem;
            text-align: left;
        }
    }
</style>
<nav class="ext-navigation">
    <a href="https://turinglang.org/">
        <svg width="4333" height="1145" viewBox="0 0 4333 1145" fill="none" xmlns="http://www.w3.org/2000/svg" class="ext-navbar-logo">
            <path class="logo-text" d="M0.44603 193.181V66.9868H663.471V193.181H406.62V898H257.297V193.181H0.44603ZM1097.24 635.874V274.74H1244.13V898H1101.7V787.225H1095.21C1081.14 822.121 1058.01 850.66 1025.82 872.842C993.902 895.024 954.542 906.115 907.744 906.115C866.896 906.115 830.783 897.053 799.403 878.929C768.295 860.534 743.948 833.889 726.365 798.993C708.782 763.826 699.99 721.356 699.99 671.581V274.74H846.878V648.858C846.878 688.353 857.699 719.733 879.34 742.997C900.981 766.261 929.385 777.893 964.551 777.893C986.192 777.893 1007.16 772.618 1027.45 762.068C1047.73 751.518 1064.37 735.828 1077.35 714.999C1090.61 693.899 1097.24 667.524 1097.24 635.874ZM1395.17 898V274.74H1537.6V378.617H1544.09C1555.45 342.639 1574.93 314.911 1602.52 295.434C1630.38 275.687 1662.17 265.813 1697.88 265.813C1705.99 265.813 1715.05 266.219 1725.06 267.031C1735.34 267.572 1743.86 268.518 1750.63 269.871V404.992C1744.4 402.828 1734.53 400.934 1721 399.311C1707.75 397.417 1694.9 396.471 1682.46 396.471C1655.68 396.471 1631.6 402.287 1610.23 413.919C1589.13 425.28 1572.49 441.105 1560.32 461.393C1548.15 481.682 1542.06 505.081 1542.06 531.591V898H1395.17ZM1848.21 898V274.74H1995.1V898H1848.21ZM1922.06 186.283C1898.8 186.283 1878.78 178.573 1862.01 163.154C1845.24 147.464 1836.85 128.664 1836.85 106.752C1836.85 84.5701 1845.24 65.7695 1862.01 50.3503C1878.78 34.6606 1898.8 26.8158 1922.06 26.8158C1945.6 26.8158 1965.61 34.6606 1982.12 50.3503C1998.89 65.7695 2007.27 84.5701 2007.27 106.752C2007.27 128.664 1998.89 147.464 1982.12 163.154C1965.61 178.573 1945.6 186.283 1922.06 186.283ZM2293.04 532.809V898H2146.15V274.74H2286.54V380.646H2293.85C2308.18 345.75 2331.04 318.022 2362.42 297.463C2394.07 276.904 2433.16 266.625 2479.69 266.625C2522.7 266.625 2560.17 275.822 2592.09 294.217C2624.28 312.612 2649.17 339.257 2666.75 374.153C2684.6 409.049 2693.39 451.385 2693.12 501.159V898H2546.24V523.882C2546.24 482.223 2535.41 449.626 2513.77 426.092C2492.4 402.557 2462.78 390.79 2424.91 390.79C2399.21 390.79 2376.35 396.471 2356.34 407.832C2336.59 418.923 2321.03 435.019 2309.67 456.119C2298.58 477.218 2293.04 502.782 2293.04 532.809ZM3113.5 1144.71C3060.75 1144.71 3015.44 1137.54 2977.57 1123.2C2939.7 1109.13 2909.26 1090.2 2886.27 1066.39C2863.28 1042.59 2847.32 1016.21 2838.39 987.269L2970.67 955.213C2976.62 967.386 2985.28 979.424 2996.64 991.327C3008 1003.5 3023.28 1013.51 3042.49 1021.35C3061.97 1029.47 3086.45 1033.53 3115.93 1033.53C3157.59 1033.53 3192.08 1023.38 3219.4 1003.09C3246.73 983.076 3260.39 950.074 3260.39 904.087V786.008H3253.08C3245.51 801.157 3234.42 816.711 3219.81 832.671C3205.47 848.632 3186.4 862.022 3162.6 872.842C3139.06 883.663 3109.44 889.073 3073.73 889.073C3025.85 889.073 2982.44 877.847 2943.48 855.394C2904.8 832.671 2873.96 798.857 2850.97 753.952C2828.24 708.777 2816.88 652.24 2816.88 584.341C2816.88 515.902 2828.24 458.147 2850.97 411.078C2873.96 363.739 2904.93 327.896 2943.89 303.55C2982.84 278.933 3026.26 266.625 3074.14 266.625C3110.66 266.625 3140.69 272.847 3164.22 285.29C3188.03 297.463 3206.96 312.206 3221.03 329.519C3235.09 346.561 3245.78 362.657 3253.08 377.805H3261.2V274.74H3406.06V908.144C3406.06 961.435 3393.34 1005.53 3367.92 1040.42C3342.49 1075.32 3307.73 1101.43 3263.63 1118.74C3219.54 1136.05 3169.5 1144.71 3113.5 1144.71ZM3114.72 773.835C3145.83 773.835 3172.34 766.261 3194.25 751.112C3216.16 735.963 3232.79 714.187 3244.16 685.783C3255.52 657.379 3261.2 623.295 3261.2 583.53C3261.2 544.305 3255.52 509.95 3244.16 480.465C3233.07 450.979 3216.56 428.12 3194.65 411.89C3173.01 395.389 3146.37 387.138 3114.72 387.138C3081.98 387.138 3054.66 395.659 3032.75 412.701C3010.84 429.744 2994.34 453.143 2983.25 482.899C2972.16 512.385 2966.61 545.929 2966.61 583.53C2966.61 621.672 2972.16 655.08 2983.25 683.754C2994.61 712.158 3011.25 734.34 3033.16 750.3C3055.34 765.99 3082.53 773.835 3114.72 773.835ZM3647.08 906.927C3622.47 906.927 3601.37 898.271 3583.78 880.958C3566.2 863.645 3557.54 842.545 3557.82 817.658C3557.54 793.312 3566.2 772.482 3583.78 755.17C3601.37 737.857 3622.47 729.2 3647.08 729.2C3670.89 729.2 3691.58 737.857 3709.17 755.17C3727.02 772.482 3736.08 793.312 3736.35 817.658C3736.08 834.159 3731.75 849.173 3723.37 862.698C3715.25 876.224 3704.43 887.044 3690.91 895.16C3677.65 903.004 3663.04 906.927 3647.08 906.927ZM3888.01 274.74H4034.9V933.708C4034.9 978.613 4026.38 1015.67 4009.33 1044.89C3992.29 1074.1 3967.67 1095.88 3935.48 1110.22C3903.29 1124.55 3864.2 1131.72 3818.22 1131.72C3812.81 1131.72 3807.8 1131.59 3803.2 1131.32C3798.6 1131.32 3793.6 1131.18 3788.19 1130.91V1011.21C3792.25 1011.48 3795.9 1011.62 3799.15 1011.62C3802.39 1011.89 3805.77 1012.02 3809.29 1012.02C3837.42 1012.02 3857.58 1005.12 3869.75 991.327C3881.92 977.801 3888.01 957.918 3888.01 931.679V274.74ZM3961.05 186.283C3937.51 186.283 3917.36 178.573 3900.59 163.154C3884.09 147.464 3875.84 128.664 3875.84 106.752C3875.84 84.5701 3884.09 65.7695 3900.59 50.3503C3917.36 34.6606 3937.51 26.8158 3961.05 26.8158C3984.31 26.8158 4004.19 34.6606 4020.7 50.3503C4037.47 65.7695 4045.85 84.5701 4045.85 106.752C4045.85 128.664 4037.47 147.464 4020.7 163.154C4004.19 178.573 3984.31 186.283 3961.05 186.283ZM4332.83 66.9868V898H4185.94V66.9868H4332.83Z" fill="currentColor"/>
            <path d="M4076 108.5C4076 168.424 4027.42 217 3967.5 217C3907.58 217 3859 168.424 3859 108.5C3859 48.5762 3907.58 0 3967.5 0C4027.42 0 4076 48.5762 4076 108.5Z" fill="#389725"/>
            <path d="M3755 814.5C3755 874.424 3706.42 923 3646.5 923C3586.58 923 3538 874.424 3538 814.5C3538 754.576 3586.58 706 3646.5 706C3706.42 706 3755 754.576 3755 814.5Z" fill="#9457B1"/>
            <path d="M2030 108.5C2030 168.424 1981.42 217 1921.5 217C1861.58 217 1813 168.424 1813 108.5C1813 48.5762 1861.58 0 1921.5 0C1981.42 0 2030 48.5762 2030 108.5Z" fill="#CA3B33"/>
        </svg>
    </a>
    <!-- <a class="ext-navbar-title" href="https://turinglang.org/">Turing.jl</a> -->
    
    <ul class="ext-nav-links">
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/getting-started/">Get Started</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/tutorials/">Tutorials</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/faq/">FAQ</a></li>
        <li>
            <p class="ext-nav-link" id="library-handler">Libraries</p>
            <div class="ext-dropdown" id="ext-dropdown-items">
                <ul>
                    <li class="ext-dropdown-item-heading">Modelling Languages</li>
                    <a href="https://turinglang.org/DynamicPPL.jl/"><li>DynamicPPL</li></a>
                    <a href="https://turinglang.org/JuliaBUGS.jl/"><li>JuliaBUGS</li></a>
                    <a href="https://turinglang.org/TuringGLM.jl/"><li>TuringGLM</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">MCMC</li>
                    <a href="https://turinglang.org/AdvancedHMC.jl/"><li>AdvancedHMC</li></a>
                    <a href="https://turinglang.org/AbstractMCMC.jl/"><li>AbstractMCMC</li></a>
                    <a href="https://github.com/theogf/ThermodynamicIntegration.jl"><li>ThermodynamicIntegration</li></a>
                    <a href="https://turinglang.org/AdvancedPS.jl/"><li>AdvancedPS</li></a>
                    <a href="https://turinglang.org/SliceSampling.jl/"><li>SliceSampling</li></a>
                    <a href="https://turinglang.org/EllipticalSliceSampling.jl/"><li>EllipticalSliceSampling</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Diagnostics</li>
                    <a href="https://turinglang.org/MCMCChains.jl/"><li>MCMCChains</li></a>
                    <a href="https://turinglang.org/MCMCDiagnosticTools.jl/"><li>MCMCDiagnosticTools</li></a>
                    <a href="https://turinglang.org/ParetoSmooth.jl/"><li>ParetoSmooth</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Gaussian Processes</li>
                    <a href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/"><li>AbstractGPs</li></a>
                    <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/"><li>KernelFunctions</li></a>
                    <a href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/"><li>ApproximateGPs</li></a>
                </ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/Bijectors.jl/">Bijectors</a></li></ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/TuringCallbacks.jl/">TuringCallbacks</a></li></ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/Deprecated/TuringBenchmarking/">TuringBenchmarking</a><span class="deprecated-badge">Deprecated</span></li></ul>
            </div>
        </li>
        <li><a class="ext-nav-link" href="https://turinglang.org/news/">News</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/team/">Team</a></li>
    </ul>

    <div class="ext-navbar-icons">
        <a href="https://x.com/TuringLang" aria-label="Turing on X"><i class="fa-brands fa-x-twitter"></i></a>
        <a href="https://discourse.julialang.org/c/domain/probprog/48" aria-label="Turing on Discourse"><i class="fa-brands fa-discourse"></i></a>
        <a href="https://julialang.slack.com/archives/CCYDC34A0" aria-label="Turing on Slack"><i class="fa-brands fa-slack"></i></a>
        <a href="https://github.com/TuringLang/" aria-label="Turing.jl on GitHub"><i class="fa-brands fa-github"></i></a>
    </div>

    <span class="ext-menu-toggle"><i class="fa-solid fa-bars"></i></span>
</nav>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        const menuToggle = document.querySelector(".ext-menu-toggle");
        const navLinks = document.querySelector(".ext-nav-links");
        const nav = document.querySelector(".ext-navigation");
        const libraryHandler = document.getElementById("library-handler");
        const dropdownContainer = document.getElementById("ext-dropdown-items");
        let lastScrollY = window.scrollY;

        function closeDropdown() {
            if (dropdownContainer.classList.contains("show")) {
                libraryHandler.classList.remove("open");
                dropdownContainer.classList.remove("show");
                setTimeout(() => {
                    if (!dropdownContainer.classList.contains("show")) {
                        dropdownContainer.style.display = "none";
                    }
                }, 300);
            }
        }

        function openDropdown() {
            dropdownContainer.style.display = "grid";
            libraryHandler.classList.add("open");
            setTimeout(() => {
                dropdownContainer.classList.add("show");
            }, 10);
        }

        function setAppropriateHeight() {
            if (window.innerWidth <= 768) {
                const viewportHeight = window.innerHeight;
                const navHeight = nav.offsetHeight;
                navLinks.style.maxHeight = `${viewportHeight - navHeight}px`;
                navLinks.style.overflowY = "auto";
            } else {
                navLinks.style.maxHeight = "";
                navLinks.style.overflowY = "";
            }
        }

        menuToggle.addEventListener("click", (event) => {
            event.stopPropagation();
            navLinks.classList.toggle("show");
            if (navLinks.classList.contains("show")) {
                setAppropriateHeight();
                closeDropdown();
                dropdownContainer.style.display = "none";
            }
        });

        libraryHandler.addEventListener("click", (event) => {
            event.stopPropagation();
            event.preventDefault();
            if (dropdownContainer.classList.contains("show")) {
                closeDropdown();
            } else {
                openDropdown();
            }
            setAppropriateHeight();
        });

        // Close all menus if a click is registered outside the navigation bar.
        document.addEventListener("click", (event) => {
            if (!nav.contains(event.target)) {
                navLinks.classList.remove("show");
                closeDropdown();
            }
        });

        // Hide navigation bar on scroll down in mobile view.
        window.addEventListener("scroll", () => {
            if (window.innerWidth <= 768) {
                if (window.scrollY > lastScrollY && window.scrollY > nav.offsetHeight){
                    nav.classList.add("hide");
                } else {
                    nav.classList.remove("hide");
                }
                lastScrollY = window.scrollY;
            }
        });

        window.addEventListener("resize", setAppropriateHeight);
    });
</script>
<!-- NAVBAR END -->


<div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AdvancedVI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">AdvancedVI</a></li><li><a class="tocitem" href="../general/">General Usage</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/basic/">Basic Example</a></li><li><a class="tocitem" href="../tutorials/subsampling/">Scaling to Large Datasets</a></li><li><a class="tocitem" href="../tutorials/stan/">Stan Models</a></li><li><a class="tocitem" href="../tutorials/flows/">Normalizing Flows</a></li><li><a class="tocitem" href="../tutorials/constrained/">Dealing with Constrained Posteriors</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li class="is-active"><a class="tocitem" href><code>KLMinRepGradDescent</code></a><ul class="internal"><li><a class="tocitem" href="#klminrepgraddescent_method"><span>Methodology</span></a></li><li><a class="tocitem" href="#entropygrad"><span>Entropy Gradient Estimators</span></a></li><li><a class="tocitem" href="#Advanced-Usage"><span>Advanced Usage</span></a></li></ul></li><li><a class="tocitem" href="../klminrepgradproxdescent/"><code>KLMinRepGradProxDescent</code></a></li><li><a class="tocitem" href="../klminscoregraddescent/"><code>KLMinScoreGradDescent</code></a></li><li><a class="tocitem" href="../klminwassfwdbwd/"><code>KLMinWassFwdBwd</code></a></li><li><a class="tocitem" href="../klminnaturalgraddescent/"><code>KLMinNaturalGradDescent</code></a></li><li><a class="tocitem" href="../klminsqrtnaturalgraddescent/"><code>KLMinSqrtNaturalGradDescent</code></a></li><li><a class="tocitem" href="../fisherminbatchmatch/"><code>FisherMinBatchMatch</code></a></li></ul></li><li><a class="tocitem" href="../families/">Variational Families</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Algorithms</a></li><li class="is-active"><a href><code>KLMinRepGradDescent</code></a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href><code>KLMinRepGradDescent</code></a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TuringLang/AdvancedVI.jl/blob/main/docs/src/klminrepgraddescent.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="klminrepgraddescent"><a class="docs-heading-anchor" href="#klminrepgraddescent"><code>KLMinRepGradDescent</code></a><a id="klminrepgraddescent-1"></a><a class="docs-heading-anchor-permalink" href="#klminrepgraddescent" title="Permalink"></a></h1><p>This algorithms aim to minimize the exclusive (or reverse) Kullback-Leibler (KL) divergence via stochastic gradient descent in the space of parameters. Specifically, it uses the the <em>reparameterization gradient</em> estimator. As a result, this algorithm is best applicable when the target log-density is differentiable and the sampling process of the variational family is differentiable. (See the <a href="#klminrepgraddescent_method">methodology section</a> for more details.) This algorithm is also commonly referred to as automatic differentiation variational inference, black-box variational inference with the reparameterization gradient, and stochastic gradient variational inference. <code>KLMinRepGradDescent</code> is also an alias of <code>ADVI</code> .</p><article><details class="docstring" open="true"><summary id="AdvancedVI.KLMinRepGradDescent"><a class="docstring-binding" href="#AdvancedVI.KLMinRepGradDescent"><code>AdvancedVI.KLMinRepGradDescent</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">KLMinRepGradDescent(adtype; entropy, optimizer, n_samples, averager, operator)</code></pre><p>KL divergence minimization by running stochastic gradient descent with the reparameterization gradient in the Euclidean space of variational parameters.</p><div class="admonition is-info" id="Note-9cc8aaadb34cd555"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-9cc8aaadb34cd555" title="Permalink"></a></header><div class="admonition-body"><p>For a <code>&lt;:MvLocationScale</code> variational family, <code>IdentityOperator</code> should be avoided for <code>operator</code> since optimization can result in a singular scale matrix. Instead, consider using <a href="../optimization/#AdvancedVI.ClipScale"><code>ClipScale</code></a>.</p></div></div><p><strong>Arguments</strong></p><ul><li><code>adtype::ADTypes.AbstractADType</code>: Automatic differentiation backend. </li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>entropy</code>: Entropy gradient estimator to be used. Must be one of <code>ClosedFormEntropy</code>, <code>StickingTheLandingEntropy</code>, <code>MonteCarloEntropy</code>. (default: <code>ClosedFormEntropy()</code>)</li><li><code>optimizer::Optimisers.AbstractRule</code>: Optimization algorithm to be used. (default: <code>DoWG()</code>)</li><li><code>n_samples::Int</code>: Number of Monte Carlo samples to be used for estimating each gradient. (default: <code>1</code>)</li><li><code>averager::AbstractAverager</code>: Parameter averaging strategy. </li><li><code>operator::AbstractOperator</code>: Operator to be applied after each gradient descent step. (default: <code>IdentityOperator()</code>)</li><li><code>subsampling::Union{&lt;:Nothing,&lt;:AbstractSubsampling}</code>: Data point subsampling strategy. If <code>nothing</code>, subsampling is not used. (default: <code>nothing</code>)</li></ul><p><strong>Output</strong></p><ul><li><code>q_averaged</code>: The variational approximation formed by the averaged SGD iterates.</li></ul><p><strong>Callback Signature</strong></p><p>The <code>callback</code> function supplied to <code>optimize</code> needs to have the following signature:</p><pre><code class="nohighlight hljs">callback(; rng, iteration, restructure, params, averaged_params, restructure, gradient)</code></pre><p>The keyword arguments are as follows:</p><ul><li><code>rng</code>: Random number generator internally used by the algorithm.</li><li><code>iteration</code>: The index of the current iteration.</li><li><code>restructure</code>: Function that restructures the variational approximation from the variational parameters. Calling <code>restructure(params)</code> reconstructs the current variational approximation. </li><li><code>params</code>: Current variational parameters.</li><li><code>averaged_params</code>: Variational parameters averaged according to the averaging strategy.</li><li><code>gradient</code>: The estimated (possibly stochastic) gradient.</li></ul><p><strong>Requirements</strong></p><ul><li>The trainable parameters in the variational approximation are expected to be extractable through <code>Optimisers.destructure</code>. This requires the variational approximation to be marked as a functor through <code>Functors.@functor</code>.</li><li>The variational approximation <span>$q_{\lambda}$</span> implements <code>rand</code>.</li><li>The target distribution and the variational approximation have the same support.</li><li>The target <code>LogDensityProblems.logdensity(prob, x)</code> must be differentiable with respect to <code>x</code> by the selected AD backend.</li><li>Additonal requirements on <code>q</code> may apply depending on the choice of <code>entropy</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/c439cd673aa5ef9faccea98ae20c04f188066861/src/algorithms/constructors.jl#L2-L43">source</a></section></details></article><h2 id="klminrepgraddescent_method"><a class="docs-heading-anchor" href="#klminrepgraddescent_method">Methodology</a><a id="klminrepgraddescent_method-1"></a><a class="docs-heading-anchor-permalink" href="#klminrepgraddescent_method" title="Permalink"></a></h2><p>This algorithms aim to solve the problem</p><p class="math-container">\[  \mathrm{minimize}_{q \in \mathcal{Q}}\quad \mathrm{KL}\left(q, \pi\right)\]</p><p>where <span>$\mathcal{Q}$</span> is some family of distributions, often called the variational family, by running stochastic gradient descent in the (Euclidean) space of parameters. Since we usually only have access to the unnormalized densities of the target distribution <span>$\pi$</span>, we don&#39;t have direct access to the KL divergence. Instead, the ELBO maximization strategy maximizes a surrogate objective, the <em>evidence lower bound</em> (ELBO; <sup class="footnote-reference"><a id="citeref-JGJS1999" href="#footnote-JGJS1999" class="footnote-ref">[JGJS1999]</a><span class="footnote-preview" id="fn-JGJS1999"></span></sup>)</p><p class="math-container">\[  \mathrm{ELBO}\left(q\right) \triangleq \mathbb{E}_{\theta \sim q} \log \pi\left(\theta\right) + \mathbb{H}\left(q\right),\]</p><p>which is equivalent to the KL up to an additive constant (the evidence).</p><p>Algorithmically, <code>KLMinRepGradDescent</code> iterates the step</p><p class="math-container">\[  \lambda_{t+1} = \mathrm{operator}\big(
      \lambda_{t} + \gamma_t \widehat{\nabla_{\lambda} \mathrm{ELBO}} (q_{\lambda_t}) 
  \big) , \]</p><p>where <span>$\widehat{\nabla \mathrm{ELBO}}(q_{\lambda})$</span> is the reparameterization gradient estimate<sup class="footnote-reference"><a id="citeref-HC1983" href="#footnote-HC1983" class="footnote-ref">[HC1983]</a><span class="footnote-preview" id="fn-HC1983"></span></sup><sup class="footnote-reference"><a id="citeref-G1991" href="#footnote-G1991" class="footnote-ref">[G1991]</a><span class="footnote-preview" id="fn-G1991"></span></sup><sup class="footnote-reference"><a id="citeref-R1992" href="#footnote-R1992" class="footnote-ref">[R1992]</a><span class="footnote-preview" id="fn-R1992"></span></sup><sup class="footnote-reference"><a id="citeref-P1996" href="#footnote-P1996" class="footnote-ref">[P1996]</a><span class="footnote-preview" id="fn-P1996"></span></sup> of the ELBO gradient and <span>$\mathrm{operator}$</span> is an optional operator (<em>e.g.</em> projections, identity mapping).</p><p>The reparameterization gradient, also known as the push-in gradient or the pathwise gradient, was introduced to VI in <sup class="footnote-reference"><a id="citeref-TL2014" href="#footnote-TL2014" class="footnote-ref">[TL2014]</a><span class="footnote-preview" id="fn-TL2014"></span></sup><sup class="footnote-reference"><a id="citeref-RMW2014" href="#footnote-RMW2014" class="footnote-ref">[RMW2014]</a><span class="footnote-preview" id="fn-RMW2014"></span></sup><sup class="footnote-reference"><a id="citeref-KW2014" href="#footnote-KW2014" class="footnote-ref">[KW2014]</a><span class="footnote-preview" id="fn-KW2014"></span></sup>. For the variational family <span>$\mathcal{Q} = \{q_{\lambda} \mid \lambda \in \Lambda\}$</span>, suppose the process of sampling from <span>$q_{\lambda}$</span> can be described by some differentiable reparameterization function <span>$T_{\lambda}$</span> and a <em>base distribution</em> <span>$\varphi$</span> independent of <span>$\lambda$</span> such that</p><p class="math-container">\[z \sim  q_{\lambda} \qquad\Leftrightarrow\qquad
z \stackrel{d}{=} T_{\lambda}\left(\epsilon\right);\quad \epsilon \sim \varphi \; .\]</p><p>In these cases, denoting the target log denstiy as <span>$\log \pi$</span>, we can effectively estimate the gradient of the ELBO by directly differentiating the stochastic estimate of the ELBO objective</p><p class="math-container">\[  \widehat{\mathrm{ELBO}}\left(q_{\lambda}\right) = \frac{1}{M}\sum^M_{m=1} \log \pi\left(T_{\lambda}\left(\epsilon_m\right)\right) + \mathbb{H}\left(q_{\lambda}\right),\]</p><p>where <span>$\epsilon_m \sim \varphi$</span> are Monte Carlo samples.</p><h2 id="entropygrad"><a class="docs-heading-anchor" href="#entropygrad">Entropy Gradient Estimators</a><a id="entropygrad-1"></a><a class="docs-heading-anchor-permalink" href="#entropygrad" title="Permalink"></a></h2><p>For the gradient of the entropy term, we provide three choices with varying requirements. The user can select the entropy estimator by passing it as a keyword argument when constructing the algorithm object.</p><table><tr><th style="text-align: left">Estimator</th><th style="text-align: center"><code>entropy(q)</code></th><th style="text-align: center"><code>logpdf(q)</code></th><th style="text-align: left">Type</th></tr><tr><td style="text-align: left"><code>ClosedFormEntropy</code></td><td style="text-align: center">required</td><td style="text-align: center"></td><td style="text-align: left">Deterministic</td></tr><tr><td style="text-align: left"><code>MonteCarloEntropy</code></td><td style="text-align: center"></td><td style="text-align: center">required</td><td style="text-align: left">Monte Carlo</td></tr><tr><td style="text-align: left"><code>StickingTheLandingEntropy</code></td><td style="text-align: center"></td><td style="text-align: center">required</td><td style="text-align: left">Monte Carlo with control variate</td></tr></table><p>The requirements mean that either <code>Distributions.entropy</code> or <code>Distributions.logpdf</code> need to be implemented for the choice of variational family. In general, the use of <code>ClosedFormEntropy</code> is recommended whenever possible. If <code>entropy</code> is not available, then <code>StickingTheLandingEntropy</code> is recommended. See the following section for more details.</p><h3 id="The-StickingTheLandingEntropy-Estimator"><a class="docs-heading-anchor" href="#The-StickingTheLandingEntropy-Estimator">The <code>StickingTheLandingEntropy</code> Estimator</a><a id="The-StickingTheLandingEntropy-Estimator-1"></a><a class="docs-heading-anchor-permalink" href="#The-StickingTheLandingEntropy-Estimator" title="Permalink"></a></h3><p>The <code>StickingTheLandingEntropy</code>, or STL estimator, is a control variate approach <sup class="footnote-reference"><a id="citeref-RWD2017" href="#footnote-RWD2017" class="footnote-ref">[RWD2017]</a><span class="footnote-preview" id="fn-RWD2017"></span></sup>.</p><article><details class="docstring" open="true"><summary id="AdvancedVI.StickingTheLandingEntropy"><a class="docstring-binding" href="#AdvancedVI.StickingTheLandingEntropy"><code>AdvancedVI.StickingTheLandingEntropy</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">StickingTheLandingEntropy()</code></pre><p>The &quot;sticking the landing&quot; entropy estimator<sup class="footnote-reference"><a id="citeref-RWD2017" href="#footnote-RWD2017" class="footnote-ref">[RWD2017]</a><span class="footnote-preview" id="fn-RWD2017"></span></sup>.</p><p><strong>Requirements</strong></p><ul><li>The variational approximation <code>q</code> implements <code>logpdf</code>.</li><li><code>logpdf(q, η)</code> must be differentiable by the selected AD framework.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/c439cd673aa5ef9faccea98ae20c04f188066861/src/algorithms/entropy.jl#L48-L56">source</a></section></details></article><p>It occasionally results in lower variance when <span>$\pi \approx q_{\lambda}$</span>, and higher variance when <span>$\pi \not\approx q_{\lambda}$</span>. The conditions for which the STL estimator results in lower variance is still an active subject for research.</p><p>The main downside of the STL estimator is that it needs to evaluate and differentiate the log density of <span>$q_{\lambda}$</span>, <code>logpdf(q)</code>, in every iteration. Depending on the variational family, this might be computationally inefficient or even numerically unstable. For example, if <span>$q_{\lambda}$</span> is a Gaussian with a full-rank covariance, a back-substitution must be performed at every step, making the per-iteration complexity <span>$\mathcal{O}(d^3)$</span> and reducing numerical stability.</p><p>In this example, the true posterior is contained within the variational family. This setting is known as &quot;perfect variational family specification.&quot; In this case, <code>KLMinRepGradDescent</code> with <code>StickingTheLandingEntropy</code> is the only estimator known to converge exponentially fast (&quot;linear convergence&quot;) to the true solution.</p><p>Recall that the original ADVI objective with a closed-form entropy (CFE) is given as follows:</p><pre><code class="language-julia hljs">n_montecarlo = 16;

cfe = KLMinRepGradDescent(
    AutoReverseDiff();
    entropy=ClosedFormEntropy(),
    optimizer=Adam(1e-2),
    operator=ClipScale(),
)
nothing</code></pre><p>The repgradelbo estimator can instead be created as follows:</p><pre><code class="language-julia hljs">stl = KLMinRepGradDescent(
    AutoReverseDiff();
    entropy=StickingTheLandingEntropy(),
    optimizer=Adam(1e-2),
    operator=ClipScale(),
)
nothing</code></pre><p><img src="../advi_stl_elbo.svg" alt/></p><p>We can see that the noise of the repgradelbo estimator becomes smaller as VI converges. However, the speed of convergence may not always be significantly different. Also, due to noise, just looking at the ELBO may not be sufficient to judge which algorithm is better. This can be made apparent if we measure convergence through the distance to the optimum:</p><p><img src="../advi_stl_dist.svg" alt/></p><p>We can see that STL kicks-in at later stages of optimization. Therefore, when STL &quot;works&quot;, it yields a higher accuracy solution even on large stepsizes. However, whether STL works or not highly depends on the problem<sup class="footnote-reference"><a id="citeref-KMG2024" href="#footnote-KMG2024" class="footnote-ref">[KMG2024]</a><span class="footnote-preview" id="fn-KMG2024"></span></sup>. Furthermore, in a lot of cases, a low-accuracy solution may be sufficient.</p><h2 id="Advanced-Usage"><a class="docs-heading-anchor" href="#Advanced-Usage">Advanced Usage</a><a id="Advanced-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Usage" title="Permalink"></a></h2><p>There are two major ways to customize the behavior of <code>KLMinRepGradDescent</code></p><ul><li>Customize the <code>Distributions</code> functions: <code>rand(q)</code>, <code>entropy(q)</code>, <code>logpdf(q)</code>.</li><li>Customize <code>AdvancedVI.reparam_with_entropy</code>.</li></ul><p>It is generally recommended to customize <code>rand(q)</code>, <code>entropy(q)</code>, <code>logpdf(q)</code>, since it will easily compose with other functionalities provided by <code>AdvancedVI</code>.</p><p>The most advanced way is to customize <code>AdvancedVI.reparam_with_entropy</code>. In particular, <code>reparam_with_entropy</code> is the function that invokes <code>rand(q)</code>, <code>entropy(q)</code>, <code>logpdf(q)</code>. Thus, it is the most general way to override the behavior of <code>RepGradELBO</code>.</p><article><details class="docstring" open="true"><summary id="AdvancedVI.reparam_with_entropy"><a class="docstring-binding" href="#AdvancedVI.reparam_with_entropy"><code>AdvancedVI.reparam_with_entropy</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">reparam_with_entropy(rng, q, q_stop, n_samples, ent_est)</code></pre><p>Draw <code>n_samples</code> from <code>q</code> and compute its entropy.</p><p><strong>Arguments</strong></p><ul><li><code>rng::Random.AbstractRNG</code>: Random number generator.</li><li><code>q</code>: Variational approximation.</li><li><code>q_stop</code>: Same as <code>q</code>, but held constant during differentiation. Should only be used for computing the entropy.</li><li><code>n_samples::Int</code>: Number of Monte Carlo samples </li><li><code>ent_est</code>: The entropy estimation strategy. (See <code>estimate_entropy</code>.)</li></ul><p><strong>Returns</strong></p><ul><li><code>samples</code>: Monte Carlo samples generated through reparameterization. Their support matches that of the target distribution.</li><li><code>entropy</code>: An estimate (or exact value) of the differential entropy of <code>q</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/c439cd673aa5ef9faccea98ae20c04f188066861/src/algorithms/repgradelbo.jl#L88-L103">source</a></section></details></article><p>To illustrate how we can customize the <code>rand(q)</code> function, we will implement quasi-Monte-Carlo variational inference<sup class="footnote-reference"><a id="citeref-BWM2018" href="#footnote-BWM2018" class="footnote-ref">[BWM2018]</a><span class="footnote-preview" id="fn-BWM2018"></span></sup>. Consider the case where we use the <code>MeanFieldGaussian</code> variational family. In this case, it suffices to override its <code>rand</code> specialization as follows:</p><pre><code class="language-julia hljs">using QuasiMonteCarlo
using StatsFuns

qmcrng = SobolSample(; R=OwenScramble(; base=2, pad=32))

function Distributions.rand(
    rng::AbstractRNG, q::MvLocationScale{&lt;:Diagonal,D,L}, num_samples::Int
) where {L,D}
    (; location, scale, dist) = q
    n_dims = length(location)
    scale_diag = diag(scale)
    unif_samples = QuasiMonteCarlo.sample(num_samples, length(q), qmcrng)
    std_samples = norminvcdf.(unif_samples)
    return scale_diag .* std_samples .+ location
end
nothing</code></pre><p>(Note that this is a quick-and-dirty example, and there are more sophisticated ways to implement this.)</p><p>By plotting the ELBO, we can see the effect of quasi-Monte Carlo. <img src="../advi_qmc_elbo.svg" alt/> We can see that quasi-Monte Carlo results in much lower variance than naive Monte Carlo. However, similarly to the STL example, just looking at the ELBO is often insufficient to really judge performance. Instead, let&#39;s look at the distance to the global optimum:</p><p><img src="../advi_qmc_dist.svg" alt/></p><p>QMC yields an additional order of magnitude in accuracy. Also, unlike STL, it ever-so slightly accelerates convergence. This is because quasi-Monte Carlo uniformly reduces variance, unlike STL, which reduces variance only near the optimum.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-JGJS1999"><a class="tag is-link" href="#citeref-JGJS1999">JGJS1999</a>Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., &amp; Saul, L. K. (1999). An introduction to variational methods for graphical models. Machine learning, 37, 183-233.</li><li class="footnote" id="footnote-HC1983"><a class="tag is-link" href="#citeref-HC1983">HC1983</a>Ho, Y. C., &amp; Cao, X. (1983). Perturbation analysis and optimization of queueing networks. Journal of optimization theory and Applications, 40(4), 559-582.</li><li class="footnote" id="footnote-G1991"><a class="tag is-link" href="#citeref-G1991">G1991</a>Glasserman, P. (1991). Gradient estimation via perturbation analysis (Vol. 116). Springer Science &amp; Business Media.</li><li class="footnote" id="footnote-R1992"><a class="tag is-link" href="#citeref-R1992">R1992</a>Rubinstein, R. Y. (1992). Sensitivity analysis of discrete event systems by the “push out” method. Annals of Operations Research, 39(1), 229-250.</li><li class="footnote" id="footnote-P1996"><a class="tag is-link" href="#citeref-P1996">P1996</a>Pflug, G. C. (1996). Optimization of stochastic models: the interface between simulation and optimization (Vol. 373). Springer Science &amp; Business Media.</li><li class="footnote" id="footnote-TL2014"><a class="tag is-link" href="#citeref-TL2014">TL2014</a>Titsias, M., &amp; Lázaro-Gredilla, M. (2014). Doubly stochastic variational Bayes for non-conjugate inference. In <em>International Conference on Machine Learning</em>.</li><li class="footnote" id="footnote-RMW2014"><a class="tag is-link" href="#citeref-RMW2014">RMW2014</a>Rezende, D. J., Mohamed, S., &amp; Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. In <em>International Conference on Machine Learning</em>.</li><li class="footnote" id="footnote-KW2014"><a class="tag is-link" href="#citeref-KW2014">KW2014</a>Kingma, D. P., &amp; Welling, M. (2014). Auto-encoding variational bayes. In <em>International Conference on Learning Representations</em>.</li><li class="footnote" id="footnote-RWD2017"><a class="tag is-link" href="#citeref-RWD2017">RWD2017</a>Roeder, G., Wu, Y., &amp; Duvenaud, D. K. (2017). Sticking the landing: Simple, lower-variance gradient estimators for variational inference. Advances in Neural Information Processing Systems, 30.</li><li class="footnote" id="footnote-KMG2024"><a class="tag is-link" href="#citeref-KMG2024">KMG2024</a>Kim, K., Ma, Y., &amp; Gardner, J. (2024). Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. In International Conference on Artificial Intelligence and Statistics (pp. 235-243). PMLR.</li><li class="footnote" id="footnote-BWM2018"><a class="tag is-link" href="#citeref-BWM2018">BWM2018</a>Buchholz, A., Wenzel, F., &amp; Mandt, S. (2018). Quasi-monte carlo variational inference. In <em>International Conference on Machine Learning</em>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorials/constrained/">« Dealing with Constrained Posteriors</a><a class="docs-footer-nextpage" href="../klminrepgradproxdescent/"><code>KLMinRepGradProxDescent</code> »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 11 December 2025 00:33">Thursday 11 December 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
