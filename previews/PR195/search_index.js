var documenterSearchIndex = {"docs":
[{"location":"optimization/#optim","page":"Optimization","title":"Optimization","text":"","category":"section"},{"location":"optimization/#Parameter-Free-Optimization-Rules","page":"Optimization","title":"Parameter-Free Optimization Rules","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"We provide custom optimization rules that are not provided out-of-the-box by Optimisers.jl. The main theme of the provided optimizers is that they are parameter-free. This means that these optimization rules shouldn't require (or barely) any tuning to obtain performance competitive with well-tuned alternatives.","category":"page"},{"location":"optimization/#AdvancedVI.DoG","page":"Optimization","title":"AdvancedVI.DoG","text":"DoG(alpha)\n\nDistance over gradient (DoG[IHC2023]) optimizer. Its only parameter is the guess for the distance between the optimum and the initialization alpha, which shouldn't need much tuning.\n\nDoG works by starting from a AdaGrad-like update rule with a small step size, but then automatically increases the step size (\"warming up\") to be as large as possible. If alpha is too large, the optimzier can initially diverge, while if it is too small, the warm up period can be too long.\n\nParameters\n\nalpha: Scaling factor for initial guess (repsilon in the original paper) of the Euclidean distance between the initial point and the optimum. For the initial parameter lambda0, repsilon is calculated as repsilon = alpha*(1 + norm(lambda0)). (default value: 1e-6)\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.DoWG","page":"Optimization","title":"AdvancedVI.DoWG","text":"DoWG(alpha)\n\nDistance over weighted gradient (DoWG[KMJ2024]) optimizer. Its only parameter is the guess for the distance between the optimum and the initialization alpha, which shouldn't need much tuning.\n\nDoWG is a minor modification to DoG so that the step sizes are always provably larger than DoG. Similarly to DoG, it works by starting from a AdaGrad-like update rule with a small step size, but then automatically increases the step size (\"warming up\") to be as large as possible. If alpha is too large, the optimzier can initially diverge, while if it is too small, the warm up period can be too long. Depending on the problem, DoWG can be too aggressive and result in unstable behavior. If this is suspected, try using DoG instead.\n\nParameters\n\nalpha: Scaling factor for initial guess (repsilon in the original paper) of the Euclidean distance between the initial point and the optimum. For the initial parameter lambda0, repsilon is calculated as repsilon = alpha*(1 + norm(lambda0)). (default value: 1e-6)\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.COCOB","page":"Optimization","title":"AdvancedVI.COCOB","text":"COCOB(alpha)\n\nContinuous Coin Betting (COCOB[OT2017]) optimizer. We use the \"COCOB-Backprop\" variant, which is closer to the Adam optimizer. Its only parameter is the maximum change per parameter alpha, which shouldn't need much tuning.\n\nParameters\n\nalpha: Scaling parameter. (default value: 100)\n\n[OT2017]: Orabona, F., & Tommasi, T. (2017). Training deep networks without learning rates through coin betting. Advances in Neural Information Processing Systems, 30.\n\n\n\n\n\n","category":"type"},{"location":"optimization/#Parameter-Averaging-Strategies","page":"Optimization","title":"Parameter Averaging Strategies","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"In some cases, the best optimization performance is obtained by averaging the sequence of parameters generated by the optimization algorithm. For instance, the DoG[IHC2023] and DoWG[KMJ2024] papers report their best performance through averaging. The benefits of parameter averaging have been specifically confirmed for ELBO maximization[DCAMHV2020].","category":"page"},{"location":"optimization/#AdvancedVI.NoAveraging","page":"Optimization","title":"AdvancedVI.NoAveraging","text":"NoAveraging()\n\nNo averaging. This returns the last-iterate of the optimization rule.\n\n\n\n\n\n","category":"type"},{"location":"optimization/#AdvancedVI.PolynomialAveraging","page":"Optimization","title":"AdvancedVI.PolynomialAveraging","text":"PolynomialAveraging(eta)\n\nPolynomial averaging rule proposed Shamir and Zhang[SZ2013]. At iteration t, the parameter average $ \\bar{\\lambda}_t $ according to the polynomial averaging rule is given as\n\n    barlambda_t = (1 - w_t) barlambda_t-1 + w_t lambda_t  \n\nwhere the averaging weight is \n\n    w_t = fraceta + 1t + eta  \n\nHigher eta (eta) down-weights earlier iterations. When eta=0, this is equivalent to uniformly averaging the iterates in an online fashion. The DoG paper[IHC2023] suggests eta=8.\n\nParameters\n\neta: Regularization term. (default: 8)\n\n[SZ2013]: Shamir, O., & Zhang, T. (2013). Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes. In International conference on machine learning (pp. 71-79). PMLR.\n\n\n\n\n\n","category":"type"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[DCAMHV2020]: Dhaka, A. K., Catalina, A., Andersen, M. R., Magnusson, M., Huggins, J., & Vehtari, A. (2020). Robust, accurate stochastic optimization for variational inference. Advances in Neural Information Processing Systems, 33, 10961-10973.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[KMJ2024]: Khaled, A., Mishchenko, K., & Jin, C. (2023). Dowg unleashed: An efficient universal parameter-free gradient descent method. Advances in Neural Information Processing Systems, 36, 6748-6769.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[IHC2023]: Ivgi, M., Hinder, O., & Carmon, Y. (2023). Dog is sgd's best friend: A parameter-free dynamic step size schedule. In International Conference on Machine Learning (pp. 14465-14499). PMLR.","category":"page"},{"location":"optimization/#Operators","page":"Optimization","title":"Operators","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Depending on the variational family, variational objective, and optimization strategy, it might be necessary to modify the variational parameters after performing a gradient-based update. For this, an operator acting on the parameters can be supplied via the  operator keyword argument of AdvancedVI.optimize.","category":"page"},{"location":"optimization/#clipscale","page":"Optimization","title":"ClipScale","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"For the location-scale family, it is often the case that optimization is stable only when the smallest eigenvalue of the scale matrix is strictly positive[D2020]. To ensure this, we provide the following projection operator:","category":"page"},{"location":"optimization/#AdvancedVI.ClipScale","page":"Optimization","title":"AdvancedVI.ClipScale","text":"ClipScale(ϵ = 1e-5)\n\nProjection operator ensuring that an MvLocationScale or MvLocationScaleLowRank has a scale with eigenvalues larger than ϵ. ClipScale also supports by operating on MvLocationScale and MvLocationScaleLowRank wrapped by a Bijectors.TransformedDistribution object. \n\n\n\n\n\n","category":"type"},{"location":"optimization/#proximalocationscaleentropy","page":"Optimization","title":"ProximalLocationScaleEntropy","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"ELBO maximization with the location-scale family tends to be unstable when the scale has small eigenvalues or the stepsize is large. To remedy this, a proximal operator of the entropy[D2020] can be used.","category":"page"},{"location":"optimization/#AdvancedVI.ProximalLocationScaleEntropy","page":"Optimization","title":"AdvancedVI.ProximalLocationScaleEntropy","text":"ProximalLocationScaleEntropy()\n\nProximal operator for the entropy of a location-scale distribution, which is defined as\n\n    mathrmprox(lambda) = argmin_lambda^prime - mathbbH(q_lambda^prime) + frac12 gamma_t leftlVert lambda - lambda^prime rightrVert_2^2 \n\nwhere gamma_t is the stepsize the optimizer used with the proximal operator. This assumes the variational family is <:VILocationScale and the optimizer is one of the following:\n\nDoG\nDoWG\nDescent\n\nFor ELBO maximization, since this proximal operator handles the entropy, the gradient estimator for the ELBO must ignore the entropy term. That is, the entropy keyword argument of RepGradELBO muse be one of the following:\n\nClosedFormEntropyZeroGradient\nStickingTheLandingEntropyZeroGradient\n\n\n\n\n\n","category":"type"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"[D2020]: Domke, J. (2020). Provable smoothness guarantees for black-box variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"families/#families","page":"Variational Families","title":"Reparameterizable Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The RepGradELBO objective assumes that the members of the variational family have a differentiable sampling path. We provide multiple pre-packaged variational families that can be readily used.","category":"page"},{"location":"families/#locscale","page":"Variational Families","title":"The LocationScale Family","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The location-scale variational family is a family of probability distributions, where their sampling process can be represented as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= C u + mquad u sim varphi","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where C is the scale, m is the location, and varphi is the base distribution. m and C form the variational parameters lambda = (m C) of q_lambda. The location-scale family encompasses many practical variational families, which can be instantiated by setting the base distribution of u and the structure of C.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The probability density is given by","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  q_lambda(z) = C^-1 varphi(C^-1(z - m))","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"the covariance is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathrmVarleft(q_lambdaright) = C mathrmVar(varphi) C^top","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"and the entropy is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathbbH(q_lambda) = mathbbH(varphi) + log C","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where mathbbH(varphi) is the entropy of the base distribution. Notice that mathbbH(varphi) does not depend on the variational parameters lambda. The derivative of the entropy with respect to lambda is thus independent of the base distribution.","category":"page"},{"location":"families/#API","page":"Variational Families","title":"API","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"note: Note\nFor stable convergence, the initial scale needs to be sufficiently large and well-conditioned. Initializing scale to have small eigenvalues will often result in initial divergences and numerical instabilities.","category":"page"},{"location":"families/#AdvancedVI.MvLocationScale","page":"Variational Families","title":"AdvancedVI.MvLocationScale","text":"MvLocationScale(location, scale, dist)\n\nThe location scale variational family broadly represents various variational families using location and scale variational parameters.\n\nIt generally represents any distribution for which the sampling path can be represented as follows:\n\n  d = length(location)\n  u = rand(dist, d)\n  z = scale*u + location\n\n\n\n\n\n","category":"type"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The following are specialized constructors for convenience:","category":"page"},{"location":"families/#AdvancedVI.FullRankGaussian","page":"Variational Families","title":"AdvancedVI.FullRankGaussian","text":"FullRankGaussian(μ, L)\n\nConstruct a Gaussian variational approximation with a dense covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nL::LinearAlgebra.AbstractTriangular{T}: Cholesky factor of the covariance of the Gaussian.\n\n\n\n\n\n","category":"function"},{"location":"families/#AdvancedVI.MeanFieldGaussian","page":"Variational Families","title":"AdvancedVI.MeanFieldGaussian","text":"MeanFieldGaussian(μ, L)\n\nConstruct a Gaussian variational approximation with a diagonal covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nL::Diagonal{T}: Diagonal Cholesky factor of the covariance of the Gaussian.\n\n\n\n\n\n","category":"function"},{"location":"families/#Gaussian-Variational-Families","page":"Variational Families","title":"Gaussian Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\n\nL = LowerTriangular(diagm(ones(2)));\nq = FullRankGaussian(μ, L)\n\nL = Diagonal(ones(2));\nq = MeanFieldGaussian(μ, L)","category":"page"},{"location":"families/#Student-t-Variational-Families","page":"Variational Families","title":"Student-t Variational Families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\nν = 3;\n\n# Full-Rank \nL = LowerTriangular(diagm(ones(2)));\nq = MvLocationScale(μ, L, TDist(ν))\n\n# Mean-Field\nL = Diagonal(ones(2));\nq = MvLocationScale(μ, L, TDist(ν))","category":"page"},{"location":"families/#Laplace-Variational-families","page":"Variational Families","title":"Laplace Variational families","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"using AdvancedVI, LinearAlgebra, Distributions;\nμ = zeros(2);\n\n# Full-Rank \nL = LowerTriangular(diagm(ones(2)));\nq = MvLocationScale(μ, L, Laplace())\n\n# Mean-Field\nL = Diagonal(ones(2));\nq = MvLocationScale(μ, L, Laplace())","category":"page"},{"location":"families/#The-LocationScaleLowRank-Family","page":"Variational Families","title":"The LocationScaleLowRank Family","text":"","category":"section"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"In practice, LocationScale families with full-rank scale matrices are known to converge slowly as they require a small SGD stepsize. Low-rank variational families can be an effective alternative[ONS2018]. LocationScaleLowRank generally represent any d-dimensional distribution which its sampling path can be represented as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= D u_1 + U u_2  + mquad u_1 u_2 sim varphi","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where D in mathbbR^d times d is a diagonal matrix, U in mathbbR^d times r is a dense low-rank matrix for the rank r  0, m in mathbbR^d is the location, and varphi is the base distribution. m, D, and U form the variational parameters lambda = (m D U).","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The covariance of this distribution is given as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathrmVarleft(q_lambdaright) = D mathrmVar(varphi) D + U mathrmVar(varphi) U^top","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"and the entropy is given by the matrix determinant lemma as","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"  mathbbH(q_lambda) \n  = mathbbH(varphi) + log Sigma\n  = mathbbH(varphi) + 2 log D + log I + U^top D^-2 U","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"where mathbbH(varphi) is the entropy of the base distribution.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"Consider a 30-dimensional Gaussian with a diagonal plus low-rank covariance structure, where the true rank is 3. Then, we can compare the convergence speed of LowRankGaussian versus FullRankGaussian:","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"(Image: )","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"As we can see, LowRankGaussian converges faster than FullRankGaussian. While FullRankGaussian can converge to the true solution since it is a more expressive variational family, LowRankGaussian gets there faster.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"info: Info\nMvLocationScaleLowRank tend to work better with the Optimisers.Adam optimizer due to non-smoothness. Other optimisers may experience divergences.","category":"page"},{"location":"families/#API-2","page":"Variational Families","title":"API","text":"","category":"section"},{"location":"families/#AdvancedVI.MvLocationScaleLowRank","page":"Variational Families","title":"AdvancedVI.MvLocationScaleLowRank","text":"MvLocationLowRankScale(location, scale_diag, scale_factors, dist)\n\nVariational family with a covariance in the form of a diagonal matrix plus a squared low-rank matrix. The rank is given by size(scale_factors, 2).\n\nIt generally represents any distribution for which the sampling path can be represented as follows:\n\n  d = length(location)\n  r = size(scale_factors, 2)\n  u_diag = rand(dist, d)\n  u_factors = rand(dist, r)\n  z = scale_diag.*u_diag + scale_factors*u_factors + location\n\n\n\n\n\n","category":"type"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The logpdf of  MvLocationScaleLowRank has an optional argument non_differentiable::Bool (default: false). If set as true, a more efficient Oleft(r d^2right) implementation is used to evaluate the density. This, however, is not differentiable under most AD frameworks due to the use of Cholesky lowrankupdate. The default value is false, which uses a Oleft(d^3right) implementation, is differentiable and therefore compatible with the StickingTheLandingEntropy estimator.","category":"page"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"The following is a specialized constructor for convenience:","category":"page"},{"location":"families/#AdvancedVI.LowRankGaussian","page":"Variational Families","title":"AdvancedVI.LowRankGaussian","text":"LowRankGaussian(μ, D, U)\n\nConstruct a Gaussian variational approximation with a diagonal plus low-rank covariance matrix.\n\nArguments\n\nμ::AbstractVector{T}: Mean of the Gaussian.\nD::Vector{T}: Diagonal of the scale.\nU::Matrix{T}: Low-rank factors of the scale, where size(U,2) is the rank.\n\n\n\n\n\n","category":"function"},{"location":"families/","page":"Variational Families","title":"Variational Families","text":"[ONS2018]: Ong, V. M. H., Nott, D. J., & Smith, M. S. (2018). Gaussian variational approximation with a factor covariance structure. Journal of Computational and Graphical Statistics, 27(3), 465-478.","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/#klminrepgraddescent","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"","category":"section"},{"location":"paramspacesgd/klminrepgraddescent/","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"This is a convenience constructor for ParamSpaceSGD with the RepGradELBO objective. This is equivalent to the algorithm commonly referred as automatic differentiation variational inference[KTRGB2017]. KLMinRepGradDescent is also an alias of ADVI .","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/","page":"KLMinRepGradDescent","title":"KLMinRepGradDescent","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research, 18(14), 1-45.","category":"page"},{"location":"paramspacesgd/klminrepgraddescent/#AdvancedVI.KLMinRepGradDescent","page":"KLMinRepGradDescent","title":"AdvancedVI.KLMinRepGradDescent","text":"KLMinRepGradDescent(adtype; entropy, optimizer, n_samples, averager, operator)\n\nKL divergence minimization by running stochastic gradient descent with the reparameterization gradient in the Euclidean space of variational parameters.\n\nArguments\n\nadtype::ADTypes.AbstractADType: Automatic differentiation backend. \n\nKeyword Arguments\n\nentropy: Entropy gradient estimator to be used. Must be one of ClosedFormEntropy, StickingTheLandingEntropy, MonteCarloEntropy. (default: ClosedFormEntropy())\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient. (default: 1)\naverager::AbstractAverager: Parameter averaging strategy. \noperator::Union{<:IdentityOperator, <:ClipScale}: Operator to be applied after each gradient descent step. (default: ClipScale())\nsubsampling::Union{<:Nothing,<:AbstractSubsampling}: Data point subsampling strategy. If nothing, subsampling is not used. (default: nothing)\n\nRequirements\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\nThe variational approximation q_lambda implements rand.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblems.logdensity(prob, x) must be differentiable with respect to x by the selected AD backend.\nAdditonal requirements on q may apply depending on the choice of entropy.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/stan/#Stan-Models","page":"Stan Models","title":"Stan Models","text":"","category":"section"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"Since AdvancedVI supports the LogDensityProblem interface, it can also be used with Stan models through StanLogDensityProblems interface. Specifically, StanLogDensityProblems wraps any Stan model into a LogDensityProblem using BridgeStan.","category":"page"},{"location":"tutorials/stan/#Problem-Setup","page":"Stan Models","title":"Problem Setup","text":"","category":"section"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"Recall the hierarchical logistic regression example in the Basic Example. Here, we will define the same model in Stan.","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"model_src = \"\"\"\ndata {\n  int<lower=0> N;\n  int<lower=0> D;\n  matrix[N,D] X;\n  array[N] int<lower=0, upper=1> y;\n}\nparameters {\n  vector[D] beta;\n  real<lower=1e-4> sigma;\n}\nmodel {\n  sigma ~ lognormal(0, 1);\n  beta ~ normal(0, sigma);\n  y ~ bernoulli_logit(X * beta);\n}\n\"\"\"\nnothing","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"We also need to prepare the data.","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"using DataFrames: DataFrames\nusing OpenML: OpenML\nusing Statistics\n\ndata = Array(DataFrames.DataFrame(OpenML.load(40)))\n\nX = Matrix{Float64}(data[:, 1:(end - 1)])\nX = (X .- mean(X; dims=2)) ./ std(X; dims=2)\nX = hcat(X, ones(size(X, 1)))\ny = Vector{Int}(data[:, end] .== \"Mine\")\n\nstan_data = (X=transpose(X), y=y, N=size(X, 1), D=size(X, 2))\nnothing","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"Since StanLogDensityProblems expects files for both the model and the data, we need to store both on the file system.","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"using JSON: JSON\n\nopen(\"logistic_model.stan\", \"w\") do io\n    println(io, model_src)\nend\nopen(\"logistic_data.json\", \"w\") do io\n    println(io, JSON.json(stan_data))\nend\nnothing","category":"page"},{"location":"tutorials/stan/#Inference-via-AdvancedVI","page":"Stan Models","title":"Inference via AdvancedVI","text":"","category":"section"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"We can now call StanLogDensityProblems to recieve a LogDensityProblem.","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"using StanLogDensityProblems: StanLogDensityProblems\n\nmodel = StanLogDensityProblems.StanProblem(\"logistic_model.stan\", \"logistic_data.json\")\nnothing","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"The rest is the same as all LogDensityProblem with the exception of how to deal with constrainted variables: Since StanLogDensityProblems automatically transforms the support of the target problem to be unconstrained, we do not need to involve Bijectors.","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"using ADTypes, ReverseDiff\nusing AdvancedVI\nusing LinearAlgebra\nusing LogDensityProblems\nusing Plots\n\nalg = KLMinRepGradDescent(ADTypes.AutoReverseDiff())\n\nd = LogDensityProblems.dimension(model)\nq = FullRankGaussian(zeros(d), LowerTriangular(Matrix{Float64}(0.3*I, d, d)))\n\nmax_iter = 10^4\nq_out, info, _ = AdvancedVI.optimize(alg, max_iter, model, q; show_progress=false)\n\nplot(\n    [i.iteration for i in info],\n    [i.elbo for i in info];\n    xlabel=\"Iteration\",\n    ylabel=\"ELBO\",\n    label=nothing,\n    ylims=(-2000, Inf),\n)\nsavefig(\"stan_example_elbo.svg\")","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"(Image: )","category":"page"},{"location":"tutorials/stan/","page":"Stan Models","title":"Stan Models","text":"From variational posterior q_out we can draw samples from the unconstrained support of the model. To convert the samples back to the original (constrained) support of the model, it suffices to call BridgeStan.param_constrain.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/#klminrepgradproxdescent","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"","category":"section"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"This is a convenience constructor for ParamSpaceSGD with the RepGradELBO objective with a proximal operator of the entropy (see here) of location-scale variational families. It implements the stochastic proximal gradient descent-based algorithm described in: [D2020][KMG2024][DGG2023].","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[D2020]: Domke, J. (2020). Provable smoothness guarantees for black-box variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[KMG2024]: Kim, K., Ma, Y., & Gardner, J. (2024). Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. In International Conference on Artificial Intelligence and Statistics (pp. 235-243). PMLR.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/","page":"KLMinRepGradProxDescent","title":"KLMinRepGradProxDescent","text":"[DGG2023]: Domke, J., Gower, R., & Garrigos, G. (2023). Provable convergence guarantees for black-box variational inference. Advances in neural information processing systems, 36, 66289-66327.","category":"page"},{"location":"paramspacesgd/klminrepgradproxdescent/#AdvancedVI.KLMinRepGradProxDescent","page":"KLMinRepGradProxDescent","title":"AdvancedVI.KLMinRepGradProxDescent","text":"KLMinRepGradProxDescent(adtype; entropy_zerograd, optimizer, n_samples, averager)\n\nKL divergence minimization by running stochastic proximal gradient descent with the reparameterization gradient in the Euclidean space of variational parameters of a location-scale family.\n\nThis algorithm only supports subtypes of MvLocationScale. Also, since the stochastic proximal gradient descent does not use the entropy of the gradient, the entropy estimator to be used must have a zero-mean gradient. Thus, only the entropy estimators with a \"ZeroGradient\" suffix are allowed.\n\nArguments\n\nadtype: Automatic differentiation backend. \n\nKeyword Arguments\n\nentropy_zerograd: Estimator of the entropy with a zero-mean gradient to be used. Must be one of ClosedFormEntropyZeroGrad, StickingTheLandingEntropyZeroGrad. (default: ClosedFormEntropyZeroGrad())\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. Only DoG, DoWG and Optimisers.Descent are supported. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient.\naverager::AbstractAverager: Parameter averaging strategy. (default: PolynomialAveraging())\nsubsampling::Union{<:Nothing,<:AbstractSubsampling}: Data point subsampling strategy. If nothing, subsampling is not used. (default: nothing)\n\nRequirements\n\nThe variational family is MvLocationScale.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblems.logdensity(prob, x) must be differentiable with respect to x by the selected AD backend.\nAdditonal requirements on q may apply depending on the choice of entropy_zerograd.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/repgradelbo/#repgradelbo","page":"RepGradELBO","title":"Reparameterization Gradient Estimator","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/#Overview","page":"RepGradELBO","title":"Overview","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The RepGradELBO objective implements the reparameterization gradient estimator[HC1983][G1991][R1992][P1996] of the ELBO gradient. The reparameterization gradient, also known as the push-in gradient or the pathwise gradient, was introduced to VI in [TL2014][RMW2014][KW2014]. For the variational family mathcalQ = q_lambda mid lambda in Lambda, suppose the process of sampling from q_lambda can be described by some differentiable reparameterization function T_lambda and a base distribution varphi independent of lambda such that","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[HC1983]: Ho, Y. C., & Cao, X. (1983). Perturbation analysis and optimization of queueing networks. Journal of optimization theory and Applications, 40(4), 559-582.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[G1991]: Glasserman, P. (1991). Gradient estimation via perturbation analysis (Vol. 116). Springer Science & Business Media.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[R1992]: Rubinstein, R. Y. (1992). Sensitivity analysis of discrete event systems by the “push out” method. Annals of Operations Research, 39(1), 229-250.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[P1996]: Pflug, G. C. (1996). Optimization of stochastic models: the interface between simulation and optimization (Vol. 373). Springer Science & Business Media.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[TL2014]: Titsias, M., & Lázaro-Gredilla, M. (2014). Doubly stochastic variational Bayes for non-conjugate inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[RMW2014]: Rezende, D. J., Mohamed, S., & Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KW2014]: Kingma, D. P., & Welling, M. (2014). Auto-encoding variational bayes. In International Conference on Learning Representations.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"z sim  q_lambda qquadLeftrightarrowqquad\nz stackreld= T_lambdaleft(epsilonright)quad epsilon sim varphi  ","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"In these cases, denoting the target log denstiy as log pi, we can effectively estimate the gradient of the ELBO by directly differentiating the stochastic estimate of the ELBO objective","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"  widehatmathrmELBOleft(lambdaright) = frac1Msum^M_m=1 log pileft(T_lambdaleft(epsilon_mright)right) + mathbbHleft(q_lambdaright)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"where epsilon_m sim varphi are Monte Carlo samples. The resulting gradient estimate is called the reparameterization gradient estimator.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"In addition to the reparameterization gradient, AdvancedVI provides the following features:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Posteriors with constrained supports are handled through Bijectors, which is known as the automatic differentiation VI (ADVI; [KTRGB2017]) formulation. (See this section.)\nThe gradient of the entropy can be estimated through various strategies depending on the capabilities of the variational family. (See this section.)","category":"page"},{"location":"paramspacesgd/repgradelbo/#RepGradELBO","page":"RepGradELBO","title":"RepGradELBO","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"To use the reparameterization gradient, AdvancedVI provides the following variational objective:","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.RepGradELBO","page":"RepGradELBO","title":"AdvancedVI.RepGradELBO","text":"RepGradELBO(n_samples; kwargs...)\n\nEvidence lower-bound objective with the reparameterization gradient formulation[TL2014][RMW2014][KW2014].\n\nArguments\n\nn_samples::Int: Number of Monte Carlo samples used to estimate the ELBO.\n\nKeyword Arguments\n\nentropy: The estimator for the entropy term. (Type <: AbstractEntropyEstimator; Default: ClosedFormEntropy())\n\nRequirements\n\nThe variational approximation q_lambda implements rand.\nThe target distribution and the variational approximation have the same support.\nThe target LogDensityProblem should satisfy either of the following: The target has a capability of at least LogDensityProblems.LogDensityOrder{1}() and the AD backend is one of ReverseDiff, Zygote, Mooncake, and AutoEnzyme in reverse mode so that ADTypes.mode(adtype) == ADTypes.ReverseMode is true. (In this case, AdvancedVI will take advantage of the existing LogDensityProblems.logdensity_and_gradient.) Otherwise, LogDensityProblems.logdensity should be differentiable under the selected AD backend.\nThe sampling process rand(q) must be differentiable by the selected AD backend.\n\nDepending on the options, additional requirements on q_lambda may apply.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/repgradelbo/#bijectors","page":"RepGradELBO","title":"Handling Constraints with Bijectors","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"As mentioned in the docstring, the RepGradELBO objective assumes that the variational approximation q_lambda and the target distribution pi have the same support for all lambda in Lambda.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"However, in general, it is most convenient to use variational families that have the whole Euclidean space mathbbR^d as their support. This is the case for the location-scale distributions provided by AdvancedVI. For target distributions which the support is not the full mathbbR^d, we can apply some transformation b to q_lambda to match its support such that","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"z sim  q_blambda qquadLeftrightarrowqquad\nz stackreld= b^-1left(etaright)quad eta sim q_lambda","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"where b is often called a bijector, since it is often chosen among bijective transformations. This idea is known as automatic differentiation VI[KTRGB2017] and has subsequently been improved by Tensorflow Probability[DLTBV2017]. In Julia, Bijectors.jl[FXTYG2020] provides a comprehensive collection of bijections.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"One caveat of ADVI is that, after applying the bijection, a Jacobian adjustment needs to be applied. That is, the objective is now","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"mathrmADVIleft(lambdaright)\ntriangleq\nmathbbE_eta sim q_lambdaleft\n  log pileft( b^-1left( eta right) right)\n  + log lvert J_b^-1left(etaright) rvert\nright\n+ mathbbHleft(q_lambdaright)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"This is automatically handled by AdvancedVI through TransformedDistribution provided by Bijectors.jl. See the following example:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"using Bijectors\nq = MeanFieldGaussian(μ, L)\nb = Bijectors.bijector(dist)\nbinv = inverse(b)\nq_transformed = Bijectors.TransformedDistribution(q, binv)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"By passing q_transformed to optimize, the Jacobian adjustment for the bijector b is automatically applied. (See the Basic Example for a fully working example.)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[DLTBV2017]: Dillon, J. V., Langmore, I., Tran, D., Brevdo, E., Vasudevan, S., Moore, D., ... & Saurous, R. A. (2017). Tensorflow distributions. arXiv.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[FXTYG2020]: Fjelde, T. E., Xu, K., Tarek, M., Yalburgi, S., & Ge, H. (2020,. Bijectors. jl: Flexible transformations for probability distributions. In Symposium on Advances in Approximate Bayesian Inference.","category":"page"},{"location":"paramspacesgd/repgradelbo/#entropygrad","page":"RepGradELBO","title":"Entropy Estimators","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"For the gradient of the entropy term, we provide three choices with varying requirements. The user can select the entropy estimator by passing it as a keyword argument when constructing the RepGradELBO objective.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Estimator entropy(q) logpdf(q) Type\nClosedFormEntropy required  Deterministic\nMonteCarloEntropy  required Monte Carlo\nStickingTheLandingEntropy  required Monte Carlo with control variate","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The requirements mean that either Distributions.entropy or Distributions.logpdf need to be implemented for the choice of variational family. In general, the use of ClosedFormEntropy is recommended whenever possible. If entropy is not available, then StickingTheLandingEntropy is recommended. See the following section for more details.","category":"page"},{"location":"paramspacesgd/repgradelbo/#The-StickingTheLandingEntropy-Estimator","page":"RepGradELBO","title":"The StickingTheLandingEntropy Estimator","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The StickingTheLandingEntropy, or STL estimator, is a control variate approach [RWD2017].","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.StickingTheLandingEntropy","page":"RepGradELBO","title":"AdvancedVI.StickingTheLandingEntropy","text":"StickingTheLandingEntropy()\n\nThe \"sticking the landing\" entropy estimator[RWD2017].\n\nRequirements\n\nThe variational approximation q implements logpdf.\nlogpdf(q, η) must be differentiable by the selected AD framework.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"It occasionally results in lower variance when pi approx q_lambda, and higher variance when pi notapprox q_lambda. The conditions for which the STL estimator results in lower variance is still an active subject for research.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The main downside of the STL estimator is that it needs to evaluate and differentiate the log density of q_lambda, logpdf(q), in every iteration. Depending on the variational family, this might be computationally inefficient or even numerically unstable. For example, if q_lambda is a Gaussian with a full-rank covariance, a back-substitution must be performed at every step, making the per-iteration complexity mathcalO(d^3) and reducing numerical stability.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"In this example, the true posterior is contained within the variational family. This setting is known as \"perfect variational family specification.\" In this case, the RepGradELBO estimator with StickingTheLandingEntropy is the only estimator known to converge exponentially fast (\"linear convergence\") to the true solution.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Recall that the original ADVI objective with a closed-form entropy (CFE) is given as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"n_montecarlo = 16;\nb = Bijectors.bijector(model);\nbinv = inverse(b)\n\nq0_trans = Bijectors.TransformedDistribution(q0, binv)\n\ncfe = KLMinRepGradDescent(\n    AutoReverseDiff(); entropy=ClosedFormEntropy(), optimizer=Adam(1e-2)\n)\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The repgradelbo estimator can instead be created as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"stl = KLMinRepGradDescent(\n    AutoReverseDiff(); entropy=StickingTheLandingEntropy(), optimizer=Adam(1e-2)\n)\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"We can see that the noise of the repgradelbo estimator becomes smaller as VI converges. However, the speed of convergence may not always be significantly different. Also, due to noise, just looking at the ELBO may not be sufficient to judge which algorithm is better. This can be made apparent if we measure convergence through the distance to the optimum:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"We can see that STL kicks-in at later stages of optimization. Therefore, when STL \"works\", it yields a higher accuracy solution even on large stepsizes. However, whether STL works or not highly depends on the problem[KMG2024]. Furthermore, in a lot of cases, a low-accuracy solution may be sufficient.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[RWD2017]: Roeder, G., Wu, Y., & Duvenaud, D. K. (2017). Sticking the landing: Simple, lower-variance gradient estimators for variational inference. Advances in Neural Information Processing Systems, 30.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[KMG2024]: Kim, K., Ma, Y., & Gardner, J. (2024). Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. In International Conference on Artificial Intelligence and Statistics (pp. 235-243). PMLR.","category":"page"},{"location":"paramspacesgd/repgradelbo/#Advanced-Usage","page":"RepGradELBO","title":"Advanced Usage","text":"","category":"section"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"There are two major ways to customize the behavior of RepGradELBO","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"Customize the Distributions functions: rand(q), entropy(q), logpdf(q).\nCustomize AdvancedVI.reparam_with_entropy.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"It is generally recommended to customize rand(q), entropy(q), logpdf(q), since it will easily compose with other functionalities provided by AdvancedVI.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"The most advanced way is to customize AdvancedVI.reparam_with_entropy. In particular, reparam_with_entropy is the function that invokes rand(q), entropy(q), logpdf(q). Thus, it is the most general way to override the behavior of RepGradELBO.","category":"page"},{"location":"paramspacesgd/repgradelbo/#AdvancedVI.reparam_with_entropy","page":"RepGradELBO","title":"AdvancedVI.reparam_with_entropy","text":"reparam_with_entropy(rng, q, q_stop, n_samples, ent_est)\n\nDraw n_samples from q and compute its entropy.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nq: Variational approximation.\nq_stop: Same as q, but held constant during differentiation. Should only be used for computing the entropy.\nn_samples::Int: Number of Monte Carlo samples \nent_est: The entropy estimation strategy. (See estimate_entropy.)\n\nReturns\n\nsamples: Monte Carlo samples generated through reparameterization. Their support matches that of the target distribution.\nentropy: An estimate (or exact value) of the differential entropy of q.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"To illustrate how we can customize the rand(q) function, we will implement quasi-Monte-Carlo variational inference[BWM2018]. Consider the case where we use the MeanFieldGaussian variational family. In this case, it suffices to override its rand specialization as follows:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"using QuasiMonteCarlo\nusing StatsFuns\n\nqmcrng = SobolSample(; R=OwenScramble(; base=2, pad=32))\n\nfunction Distributions.rand(\n    rng::AbstractRNG, q::MvLocationScale{<:Diagonal,D,L}, num_samples::Int\n) where {L,D}\n    (; location, scale, dist) = q\n    n_dims = length(location)\n    scale_diag = diag(scale)\n    unif_samples = QuasiMonteCarlo.sample(num_samples, length(q), qmcrng)\n    std_samples = norminvcdf.(unif_samples)\n    return scale_diag .* std_samples .+ location\nend\nnothing","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Note that this is a quick-and-dirty example, and there are more sophisticated ways to implement this.)","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"By plotting the ELBO, we can see the effect of quasi-Monte Carlo. (Image: ) We can see that quasi-Monte Carlo results in much lower variance than naive Monte Carlo. However, similarly to the STL example, just looking at the ELBO is often insufficient to really judge performance. Instead, let's look at the distance to the global optimum:","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"(Image: )","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"QMC yields an additional order of magnitude in accuracy. Also, unlike STL, it ever-so slightly accelerates convergence. This is because quasi-Monte Carlo uniformly reduces variance, unlike STL, which reduces variance only near the optimum.","category":"page"},{"location":"paramspacesgd/repgradelbo/","page":"RepGradELBO","title":"RepGradELBO","text":"[BWM2018]: Buchholz, A., Wenzel, F., & Mandt, S. (2018). Quasi-monte carlo variational inference. In International Conference on Machine Learning.","category":"page"},{"location":"paramspacesgd/general/#paramspacesgd","page":"General","title":"General","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"ParamSpaceSGD SGD is a general algorithm for leveraging automatic differentiation and SGD. Furthermore, it operates in the space of variational parameters. Consider the case where each member q_lambda in mathcalQ of the variational family mathcalQ is uniquely represented through a collection of parameters lambda in Lambda subseteq mathbbR^p.  That is,","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"mathcalQ = q_lambda mid lambda in Lambda ","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Then, as implied by the name, ParamSpaceSGD runs SGD on Lambda, the (Euclidean) space of parameters.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Any algorithm that operates by iterating the following steps can easily be implemented via  ParamSpaceSGD:","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Obtain an unbiased estimate of the target objective.\nObtain an estimate of the gradient of the objective by differentiating the objective estimate with respect to the parameters.\nPerform gradient descent with the stochastic gradient estimate.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"After some simplifications, each step of ParamSpaceSGD can be described as follows:","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"function step(rng, alg::ParamSpaceSGD, state, callback, objargs...; kwargs...)\n    (; adtype, problem, objective, operator, averager) = alg\n    (; q, iteration, grad_buf, opt_st, obj_st, avg_st) = state\n    iteration += 1\n\n    # Extract variational parameters of `q`\n    params, re = Optimisers.destructure(q)\n\n    # Estimate gradient and update the `DiffResults` buffer `grad_buf`.\n    grad_buf, obj_st, info = estimate_gradient!(...)\n\n    # Gradient descent step.\n    grad = DiffResults.gradient(grad_buf)\n    opt_st, params = Optimisers.update!(opt_st, params, grad)\n\n    # Apply operator\n    params = apply(operator, typeof(q), opt_st, params, re)\n\n    # Apply parameter averaging\n    avg_st = apply(averager, avg_st, params)\n\n    # Updated state\n    state = ParamSpaceSGDState(re(params), iteration, grad_buf, opt_st, obj_st, avg_st)\n    state, false, info\nend","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"The output of ParamSpaceSGD is the final state of averager. Furthermore, operator can be anything from an identity mapping, a projection operator, a proximal operator, and so on.","category":"page"},{"location":"paramspacesgd/general/#ParamSpaceSGD","page":"General","title":"ParamSpaceSGD","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"The constructor for ParamSpaceSGD is as follows:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.ParamSpaceSGD","page":"General","title":"AdvancedVI.ParamSpaceSGD","text":"ParamSpaceSGD(\n    objective::AbstractVariationalObjective,\n    adtype::ADTypes.AbstractADType,\n    optimizer::Optimisers.AbstractRule,\n    averager::AbstractAverager,\n    operator::AbstractOperator,\n)\n\nThis algorithm applies stochastic gradient descent (SGD) to the variational objective over the (Euclidean) space of variational parameters.\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\n\nnote: Note\nDifferent objective may impose different requirements on adtype, variational family, optimizer, and operator. It is therefore important to check the documentation corresponding to each specific objective. Essentially, each objective should be thought as forming its own unique algorithm.\n\nArguments\n\nobjective: Variational Objective.\nadtype: Automatic differentiation backend. \noptimizer: Optimizer used for inference.\naverager : Parameter averaging strategy.\noperator : Operator applied to the parameters after each optimization step.\n\nOutput\n\nq_averaged: The variational approximation formed from the averaged SGD iterates.\n\nCallback\n\nThe callback function callback has a signature of\n\ncallback(; rng, iteration, restructure, params, averaged_params, restructure, gradient)\n\nThe arguments are as follows:\n\nrng: Random number generator internally used by the algorithm.\niteration: The index of the current iteration.\nrestructure: Function that restructures the variational approximation from the variational parameters. Calling restructure(params) reconstructs the current variational approximation. \nparams: Current variational parameters.\naveraged_params: Variational parameters averaged according to the averaging strategy.\ngradient: The estimated (possibly stochastic) gradient.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/general/#Objective-Interface","page":"General","title":"Objective Interface","text":"","category":"section"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"To define an instance of a ParamSpaceSGD algorithm, it suffices to implement the AbstractVariationalObjective interface. First, we need to define a subtype of AbstractVariationalObjective:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.AbstractVariationalObjective","page":"General","title":"AdvancedVI.AbstractVariationalObjective","text":"AbstractVariationalObjective\n\nAbstract type for the VI algorithms supported by AdvancedVI.\n\nImplementations\n\nTo be supported by AdvancedVI, a VI algorithm must implement AbstractVariationalObjective and estimate_objective. Also, it should provide gradients by implementing the function estimate_gradient. If the estimator is stateful, it can implement init to initialize the state.\n\n\n\n\n\n","category":"type"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"In addition, we need to implement some methods associated with the objective. First, each objective may maintain a state such as buffers, online estimates of control variates, batch iterators for subsampling, and so on. Such things should be initialized by implementing the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.init-Tuple{AbstractRNG, AdvancedVI.AbstractVariationalObjective, AbstractADType, Vararg{Any, 4}}","page":"General","title":"AdvancedVI.init","text":"init(rng, obj, adtype, q_init, prob, params, restructure)\n\nInitialize a state of the variational objective obj given the initial variational approximation q_init and its parameters params. This function needs to be implemented only if obj is stateful.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\n\nadtype::ADTypes.AbstractADType`: Automatic differentiation backend.\n\nq_init: Initial variational approximation.\nprob: The target log-joint likelihood implementing the LogDensityProblem interface.\nparams: Initial variational parameters.\nrestructure: Function that reconstructs the variational approximation from params.\n\n\n\n\n\n","category":"method"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"If this method is not implemented, the state will be automatically be nothing.","category":"page"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"Next, the key functionality of estimating stochastic gradients should be implemented through the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.estimate_gradient!","page":"General","title":"AdvancedVI.estimate_gradient!","text":"estimate_gradient!(rng, obj, adtype, out, obj_state, params, restructure)\n\nEstimate (possibly stochastic) gradients of the variational objective obj with respect to the variational parameters params\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\nadtype::ADTypes.AbstractADType: Automatic differentiation backend. \nout::DiffResults.MutableDiffResult: Buffer containing the objective value and gradient estimates. \nobj_state: Previous state of the objective.\nparams: Variational parameters to evaluate the gradient on.\nrestructure: Function that reconstructs the variational approximation from params.\n\nReturns\n\nout::MutableDiffResult: Buffer containing the objective value and gradient estimates.\nobj_state: The updated state of the objective.\nstat::NamedTuple: Statistics and logs generated during estimation.\n\n\n\n\n\n","category":"function"},{"location":"paramspacesgd/general/","page":"General","title":"General","text":"AdvancedVI only interacts with each variational objective by querying gradient estimates. In a lot of cases, however, it is convinient to be able to estimate the current value of the objective. For example, for monitoring convergence. This should be done through the following:","category":"page"},{"location":"paramspacesgd/general/#AdvancedVI.estimate_objective","page":"General","title":"AdvancedVI.estimate_objective","text":"estimate_objective([rng,] obj, q, prob; kwargs...)\n\nEstimate the variational objective obj targeting prob with respect to the variational approximation q.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nobj::AbstractVariationalObjective: Variational objective.\nprob: The target log-joint likelihood implementing the LogDensityProblem interface.\nq: Variational approximation.\n\nKeyword Arguments\n\nDepending on the objective, additional keyword arguments may apply. Please refer to the respective documentation of each variational objective for more info.\n\nReturns\n\nobj_est: Estimate of the objective value.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/subsampling/#Scaling-to-Large-Datasets-with-Subsampling","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets with Subsampling","text":"","category":"section"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"In this tutorial, we will show how to use AdvancedVI on problems with large datasets. Variational inference (VI) has a long and successful history[HBWP2013][TL2014][HBB2010] in large scale inference using (minibatch) subsampling. In this tutorial, we will see how to perform subsampling with KLMinRepGradProxDescent, which was originally described in the paper by Titsias and Lázaro-Gredilla[TL2014]; Kucukelbir et al[KTRGB2017].","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[HBB2010]: Hoffman, M., Bach, F., & Blei, D. (2010). Online learning for latent Dirichlet allocation. In Advances in Neural Information Processing Systems, 23.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[HBWP2013]: Hoffman, M. D., Blei, D. M., Wang, C., & Paisley, J. (2013). Stochastic variational inference. Journal of Machine Learning Research, 14(1), 1303-1347.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[TL2014]: Titsias, M., & Lázaro-Gredilla, M. (2014, June). Doubly stochastic variational Bayes for non-conjugate inference. In Proceedings of the International Conference on Machine Learning (pp. 1971-1979). PMLR.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research, 18(14), 1-45.","category":"page"},{"location":"tutorials/subsampling/#Setting-Up-a-LogDensityProblem-for-Subsampling","page":"Scaling to Large Datasets","title":"Setting Up a LogDensityProblem for Subsampling","text":"","category":"section"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"We will consider the same hierarchical logistic regression example used in the Basic Example.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using LogDensityProblems: LogDensityProblems\nusing Distributions\nusing FillArrays\n\nstruct LogReg{XType,YType}\n    X::XType\n    y::YType\n    n_data::Int\nend\n\nfunction LogDensityProblems.logdensity(model::LogReg, θ)\n    (; X, y, n_data) = model\n    n, d = size(X)\n    β, σ = θ[1:size(X, 2)], θ[end]\n\n    logprior_β = logpdf(MvNormal(Zeros(d), σ), β)\n    logprior_σ = logpdf(LogNormal(0, 3), σ)\n\n    logit = X*β\n    loglike_y = mapreduce((li, yi) -> logpdf(BernoulliLogit(li), yi), +, logit, y)\n    return n_data/n*loglike_y + logprior_β + logprior_σ\nend\n\nfunction LogDensityProblems.dimension(model::LogReg)\n    return size(model.X, 2) + 1\nend\n\nfunction LogDensityProblems.capabilities(::Type{<:LogReg})\n    return LogDensityProblems.LogDensityOrder{0}()\nend\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"Notice that, to use subsampling, we need be able to rescale the likelihood strength. That is, for the gradient of the log-density with a batch of data points of size n to be an unbiased estimate of the gradient using the full dataset of size n_data, we need to scale the likelihood by n_data/n. This part is critical to ensure that the algorithm correctly approximates the posterior with the full dataset.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"As usual, we will set up a bijector:","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using Bijectors: Bijectors\n\nfunction Bijectors.bijector(model::LogReg)\n    d = size(model.X, 2)\n    return Bijectors.Stacked(\n        Bijectors.bijector.([MvNormal(Zeros(d), 1.0), LogNormal(0, 3)]),\n        [1:d, (d + 1):(d + 1)],\n    )\nend\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"For the dataset, we will use one that is larger than that used in the Basic Example. This is to properly assess the advantage of subsampling. In particular, we will utilize the \"Phishing\" dataset[Tan2018], which consists of 10000 data points, each with 48 features. The goal is to predict whether the features of a specific website indicate whether it is a phishing website or a legitimate one. The dataset id on the OpenML repository is 46722.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[Tan2018]: Tan, Choon Lin (2018), \"Phishing Dataset for Machine Learning: Feature Evaluation\", Mendeley Data, V1, doi: 10.17632/h3cgnj8hft.1]","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using OpenML: OpenML\nusing DataFrames: DataFrames\n\ndata = Array(DataFrames.DataFrame(OpenML.load(46722)))\nX = Matrix{Float64}(data[:, 2:end])\ny = Vector{Bool}(data[:, end])\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"The features start from the seoncd column, while the last column are the class labels.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"Let's also apply some basic pre-processing.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"X = (X .- mean(X; dims=2)) ./ std(X; dims=2)\nX = hcat(X, ones(size(X, 1)))\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"Let's now istantiate the model and set up automatic differentiation using LogDensityProblemsAD.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using ADTypes, ReverseDiff\nusing LogDensityProblemsAD\n\nmodel = LogReg(X, y, size(X, 1))\nmodel_ad = LogDensityProblemsAD.ADgradient(ADTypes.AutoReverseDiff(), model)\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"To enable subsampling, LogReg has to implement the method AdvancedVI.subsample. For our model, this is fairly simple: We only need to select the rows of X and the elements of y corresponding to the batch of data points. As subtle point here is that we wrapped model with LogDensityProblemsAD.ADgradient into model_ad. Therefore, AdvancedVI sees model_ad and not model. This means we have to specialize AdvancedVI.subsample to typeof(model_ad) and not LogReg.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using Accessors\nusing AdvancedVI\n\nfunction AdvancedVI.subsample(model::typeof(model_ad), idx)\n    (; X, y, n_data) = parent(model)\n    model′ = @set model.ℓ.X = X[idx, :]\n    model′′ = @set model′.ℓ.y = y[idx]\n    return model′′\nend\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"info: Info\nThe default implementation of AdvancedVI.subsample is AdvancedVI.subsample(model, idx) = model. Therefore, if the specialization of AdvancedVI.subsample is not set up properly, AdvancedVI will silently use full-batch gradients instead of subsampling. It is thus useful to check whether the right specialization of AdvancedVI.subsample is being called.","category":"page"},{"location":"tutorials/subsampling/#Scalable-Inference-via-AdvancedVI","page":"Scaling to Large Datasets","title":"Scalable Inference via AdvancedVI","text":"","category":"section"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"In this example, we will compare the convergence speed of KLMinRepGradProxDescent with and without subsampling. Subsampling can be turned on by supplying a subsampling strategy. Here, we will use ReshufflingBatchSubsampling, which implements random reshuffling. We will us a batch size of 32, which results in 313 = length(subsampling) = ceil(Int, size(X,2)/32) steps per epoch.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"dataset = 1:size(model.X, 1)\nbatchsize = 32\nsubsampling = ReshufflingBatchSubsampling(dataset, batchsize)\nalg_sub = KLMinRepGradProxDescent(ADTypes.AutoReverseDiff(; compile=true); subsampling)\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"Recall that each epoch is 313 steps. When using ReshufflingBatchSubsampling, it is best to choose the number of iterations to be a multiple of the number of steps length(subsampling) in an epoch. This is due to a peculiar property of ReshufflingBatchSubsampling: the objective value tends to increase during an epoch, and come down nearing the end. (Theoretically, this is due to conditionally biased nature of random reshuffling[MKR2020].) Therefore, the objective value is minimized exactly after the last step of each epoch.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"[MKR2020]: Mishchenko, K., Khaled, A., & Richtárik, P. (2020). Random reshuffling: Simple analysis with vast improvements. Advances in Neural Information Processing Systems, 33, 17309-17320.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"num_epochs = 10\nmax_iter = num_epochs * length(subsampling)\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"If we don't supply a subsampling strategy to KLMinRepGradProxDescent, subsampling will not be used.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"alg_full = KLMinRepGradProxDescent(ADTypes.AutoReverseDiff(; compile=true))\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"The variational family will be set up as follows:","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using LinearAlgebra\n\nd = LogDensityProblems.dimension(model_ad)\nq = FullRankGaussian(zeros(d), LowerTriangular(Matrix{Float64}(I, d, d)))\nb = Bijectors.bijector(model)\nbinv = Bijectors.inverse(b)\nq_transformed = Bijectors.TransformedDistribution(q, binv)\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"It now remains to run VI. For comparison, we will record both the ELBO (with a large number of Monte Carlo samples) and the prediction accuracy.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using StatsFuns: StatsFuns\n\nlogging_interval = 100\ntime_begin = nothing\n\n\"\"\"\n    logistic_prediction(X, μ_β, Σ_β)\n    \nApproximate the posterior predictive probability for a logistic link function using Mackay's approximation (Bishop p. 220).\n\"\"\"\nfunction logistic_prediction(X, μ_β, Σ_β)\n    xtΣx = sum((model.X*Σ_β) .* model.X; dims=2)[:, 1]\n    κ = @. 1/sqrt(1 + π/8*xtΣx)\n    return StatsFuns.logistic.(κ .* X*μ_β)\nend\n\nfunction callback(; iteration, averaged_params, restructure, kwargs...)\n    if mod(iteration, logging_interval) == 1\n\n        # Use the averaged parameters (the eventual output of the algorithm)\n        q_avg = restructure(averaged_params)\n\n        # Compute predictions using \n        μ_β = mean(q_avg.dist)[1:(end - 1)] # posterior mean of β\n        Σ_β = cov(q_avg.dist)[1:(end - 1), end - 1] # marginal posterior covariance of β\n        y_pred = logistic_prediction(X, μ_β, Σ_β) .> 0.5\n\n        # Prediction accuracy\n        acc = mean(y_pred .== model.y)\n\n        # Higher fidelity estimate of the ELBO on the averaged parameters\n        n_samples = 256\n        obj = AdvancedVI.RepGradELBO(n_samples; entropy=MonteCarloEntropy())\n        elbo_callback = estimate_objective(obj, q_avg, model)\n\n        (elbo_callback=elbo_callback, accuracy=acc, time_elapsed=time() - time_begin)\n    else\n        nothing\n    end\nend\n\ntime_begin = time()\n_, info_full, _ = AdvancedVI.optimize(\n    alg_full, max_iter, model_ad, q_transformed; show_progress=false, callback\n);\n\ntime_begin = time()\n_, info_sub, _ = AdvancedVI.optimize(\n    alg_sub, max_iter, model_ad, q_transformed; show_progress=false, callback\n);\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"Let's visualize the ELBO over time.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"using Plots\n\nt = 1:logging_interval:max_iter\nplot(\n    [i.iteration for i in info_full[t]],\n    [i.elbo_callback for i in info_full[t]];\n    xlabel=\"Iteration\",\n    ylabel=\"ELBO\",\n)\nplot!([i.iteration for i in info_sub[t]], [i.elbo_callback for i in info_sub[t]])\nsavefig(\"subsampling_example_iteration_elbo.svg\")\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"(Image: )","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"According to this plot, it might seem like subsampling has no effect. However, this is because we are plotting against the number of iterations. Subsampling generally converges slower (asymptotically) in terms of iterations. But in return, it reduces the time spent at each iteration. Therefore, we need to plot against the elapsed time:","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"plot(\n    [i.time_elapsed for i in info_full[t]],\n    [i.elbo_callback for i in info_full[t]];\n    xlabel=\"Wallclock Time (sec)\",\n    ylabel=\"ELBO\",\n)\nplot!([i.time_elapsed for i in info_sub[t]], [i.elbo_callback for i in info_sub[t]])\nsavefig(\"subsampling_example_time_elbo.svg\")\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"(Image: )","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"We can now see the dramatic effect of subsampling. The picture is similar if we visualize the prediction accuracy over time.","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"plot(\n    [i.time_elapsed for i in info_full[t]],\n    [i.accuracy for i in info_full[t]];\n    xlabel=\"Wallclock Time (sec)\",\n    ylabel=\"Prediction Accuracy\",\n)\nplot!([i.time_elapsed for i in info_sub[t]], [i.accuracy for i in info_sub[t]])\nsavefig(\"subsampling_example_time_accuracy.svg\")\nnothing","category":"page"},{"location":"tutorials/subsampling/","page":"Scaling to Large Datasets","title":"Scaling to Large Datasets","text":"(Image: )","category":"page"},{"location":"tutorials/flows/#Normalizing-Flows","page":"Normalizing Flows","title":"Normalizing Flows","text":"","category":"section"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"In this example, we will see how to use NormalizingFlows with AdvancedVI.","category":"page"},{"location":"tutorials/flows/#Problem-Setup","page":"Normalizing Flows","title":"Problem Setup","text":"","category":"section"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"For the problem, we will look into a toy problem where NormalizingFlows can be benficial. For a dataset of real valued data y_1 ldots y_n, consider the following generative model:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"beginaligned\nalpha sim textLogNormal(0 1) \nbeta sim textNormalleft(0 10right) \ny_i sim textNormalleft(alpha beta 1right)\nendaligned","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Notice that the mean is predicted as the product alpha beta of two unknown parameters. This results in multiplicative unidentifiability of alpha and beta. As such, the posterior exhibits a \"banana\"-shaped degeneracy. Multiplicative degeneracy is not entirely made up and do come up in some models used in practice. For example, in the 3-parameter (3-PL) item-response theory model and the N-mixture model used for estimating animal population.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using Bijectors: Bijectors\nusing Distributions\nusing LogDensityProblems: LogDensityProblems\n\nstruct MultDegen{Y}\n    y::Y\nend\n\nfunction LogDensityProblems.logdensity(model::MultDegen, θ)\n    α, β = θ[1], θ[2]\n\n    logprior_α = logpdf(LogNormal(0, 1), α)\n    logprior_β = logpdf(Normal(0, 10), β)\n\n    loglike_y = mapreduce(+, model.y) do yi\n        logpdf(Normal(α * β, 1.0), yi)\n    end\n    return logprior_α + logprior_β + loglike_y\nend\n\nfunction LogDensityProblems.dimension(model::MultDegen)\n    return 2\nend\n\nfunction LogDensityProblems.capabilities(::Type{<:MultDegen})\n    return LogDensityProblems.LogDensityOrder{0}()\nend\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Degenerate posteriors often indicate that there is not enough data to pin-point the right set of parameters. Therefore, for the purpose of illustration, we will use a single data point:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"model = MultDegen([3.0])\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"The banana-shaped degeneracy of the posterior can be readily visualized:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using Plots\n\ncontour(\n    range(0, 4; length=64),\n    range(-3, 25; length=64),\n    (x, y) -> LogDensityProblems.logdensity(model, [x, y]);\n    xlabel=\"α\",\n    ylabel=\"β\",\n    clims=(-8, Inf),\n)\n\nsavefig(\"flow_example_posterior.svg\")\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"(Image: )","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Notice that the two ends of the \"banana\" run deep both horizontally and vertically. This sort of nonlinear correlation structure is difficult to model using only location-scale distributions.","category":"page"},{"location":"tutorials/flows/#Gaussian-Variational-Family","page":"Normalizing Flows","title":"Gaussian Variational Family","text":"","category":"section"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"As usual, let's try to fit a multivariate Gaussian to this posterior.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using ADTypes: ADTypes\nusing ReverseDiff: ReverseDiff\nusing DifferentiationInterface: DifferentiationInterface\nusing LogDensityProblemsAD: LogDensityProblemsAD\n\nmodel_ad = LogDensityProblemsAD.ADgradient(\n    ADTypes.AutoReverseDiff(; compile=true), model; x=[1.0, 1.0]\n)\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Since alpha is constrained to the positive real half-space, we have to employ bijectors. For this, we use Bijectors:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using Bijectors: Bijectors\n\nfunction Bijectors.bijector(model::MultDegen)\n    return Bijectors.Stacked(\n        Bijectors.bijector.([LogNormal(0, 1), Normal(0, 10)]), [1:1, 2:2]\n    )\nend","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"For the algorithm, we will use the KLMinRepGradProxDescent objective.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using AdvancedVI\nusing LinearAlgebra\n\nd = LogDensityProblems.dimension(model_ad)\nq = FullRankGaussian(zeros(d), LowerTriangular(Matrix{Float64}(I, d, d)))\n\nbinv = Bijectors.inverse(Bijectors.bijector(model))\nq_trans = Bijectors.TransformedDistribution(q, binv)\n\nmax_iter = 3*10^3\nalg = KLMinRepGradProxDescent(ADTypes.AutoReverseDiff(; compile=true))\nq_out, info, _ = AdvancedVI.optimize(alg, max_iter, model_ad, q_trans; show_progress=false)\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"The resulting variational posterior can be visualized as follows:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"samples = rand(q_out, 10000)\nhistogram2d(\n    samples[1, :],\n    samples[2, :];\n    normalize=:pdf,\n    nbins=32,\n    xlabel=\"α\",\n    ylabel=\"β\",\n    xlims=(0, 4),\n    ylims=(-3, 25),\n)\nsavefig(\"flow_example_locationscale.svg\")\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"(Image: )","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"We can see that the mode is closely matched, but the tails don't go as deep as the true posterior. For this, we will need a more \"expressive\" variational family that is capable of representing nonlinear correlations.","category":"page"},{"location":"tutorials/flows/#Normalizing-Flow-Variational-Family","page":"Normalizing Flows","title":"Normalizing Flow Variational Family","text":"","category":"section"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Now, let's try to optimize over a variational family formed by normalizing flows. Normalizing flows, or flow for short, is a class of parametric models leveraging neural networks for density estimation. (For a detailed tutorial on flows, refer to the review by Papamakarios et al.[PNRML2021]) Within the Julia ecosystem, the package NormalizingFlows provides a collection of popular flow models. In this example, we will use the popular RealNVP flow model[DSB2017]. We will use a standard Gaussian base distribution with three layers, each with 16 hidden units.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[PNRML2021]: Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., & Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. Journal of Machine Learning Research, 22(57), 1-64.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[DSB2017]: Dinh, L., Sohl-Dickstein, J., & Bengio, S. (2016). Density estimation using real nvp. In Proceedings of the International Conference on Learning Representations.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using NormalizingFlows\nusing Functors\n\n@leaf MvNormal\n\nn_layers = 3\nhidden_dim = fill(16, n_layers - 1)\nq_flow = realnvp(MvNormal(zeros(d), I), hidden_dim, n_layers; paramtype=Float64)\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Recall that out posterior is constrained. In most cases, flows assume an unconstrained support. Therefore, just as with the Gaussian variational family, we can incorporate Bijectors to match the supports:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"q_flow_trans = Bijectors.TransformedDistribution(q_flow, binv)\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"For the variational inference algorithms, we will similarly minimize the KL divergence with stochastic gradient descent as originally proposed by Rezende and Mohamed[RM2015]. For this, however, we need to be mindful of the requirements of the variational algorithm. The default objective of KLMinRepGradDescent essentially assumes a MvLocationScale family is being used:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"entropy=RepGradELBO(): The default entropy gradient estimator  is ClosedFormEntropy(), which assumes that the entropy of the variational family entropy(q) is available. For flows, the entropy is (usually) not available.\noperator=ClipScale(): The operator applied after a gradient descent step is ClipScale by default. This operator only works on MvLocationScale and MvLocationScaleLowRank. Therefore, we have to customize the two keyword arguments above to make it work with flows.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"In particular, for the operator, we will use IdentityOperator(), which is a no-op. For entropy, we can use any gradient estimator that only relies on the log-density of the variational family logpdf(q), StickingTheLandingEntropy() or MonteCarloEntropy(). Here, we will use StickingTheLandingEntropy()[RWD2017]. When the variational family is \"expressive,\" this gradient estimator has a variance reduction effect, resulting in faster convergence[ASD2020]. Furthermore, Agrawal et al.[AD2025] claim that using a larger number of Monte Carlo samples n_samples is beneficial.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[RM2015]: Rezende, D., & Mohamed, S. (2015, June). Variational inference with normalizing flows. In Proceedings of the International conference on machine learning. PMLR.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[RWD2017]: Roeder, G., Wu, Y., & Duvenaud, D. K. (2017). Sticking the landing: Simple, lower-variance gradient estimators for variational inference. In Advances in Neural Information Processing Systems, 30.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[ASD2020]: Agrawal, A., Sheldon, D. R., & Domke, J. (2020). Advances in black-box VI: Normalizing flows, importance weighting, and optimization. In Advances in Neural Information Processing Systems, 33, 17358-17369.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"[AD2025]: Agrawal, A., & Domke, J. (2024). Disentangling impact of capacity, objective, batchsize, estimators, and step-size on flow VI. In Proceedings of the International Conference on Artificial Intelligence and Statistics.","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"alg_flow = KLMinRepGradDescent(\n    ADTypes.AutoReverseDiff(; compile=true);\n    n_samples=8,\n    operator=IdentityOperator(),\n    entropy=StickingTheLandingEntropy(),\n)","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Without further due, let's now run VI:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"q_flow_out, info_flow, _ = AdvancedVI.optimize(\n    alg_flow, max_iter, model_ad, q_flow_trans; show_progress=false\n)\nnothing","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"We can do a quick visual diagnostic of whether the optimization went smoothly:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"plot([i.elbo for i in info_flow]; xlabel=\"Iteration\", ylabel=\"ELBO\", ylims=(-30, Inf))\nsavefig(\"flow_example_flow_elbo.svg\")","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"(Image: )","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Finally, let's visualize the variational posterior:","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"samples = rand(q_flow_out, 10000)\nhistogram2d(\n    samples[1, :],\n    samples[2, :];\n    normalize=:pdf,\n    nbins=64,\n    xlabel=\"α\",\n    ylabel=\"β\",\n    xlims=(0, 4),\n    ylims=(-3, 25),\n)\nsavefig(\"flow_example_flow.svg\")","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"(Image: )","category":"page"},{"location":"tutorials/flows/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Compared to the Gaussian approximation, we can see that the tails go much deeper into vertical direction. This shows that, for this example with extreme nonlinear correlations, normalizing flows enable more accurate approximation.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/#klminscoregraddescent","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"","category":"section"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"This is a convenience constructor for ParamSpaceSGD with the ScoreGradELBO objective. This is similar to the algorithm that was originally referred to as black-box variational inference (BBVI; [RGB2014][WW2013]). (The term BBVI has also recently been used to refer to the more general setup of maximizing the ELBO in parameter space. We are using the more narrow definition, which restricts to the use of the score gradient.) However, instead of using the vanilla score gradient estimator, we differentiate the \"VarGrad\" objective[RBNRA2020], which results in the score gradient variance-reduced by the leave-one-out control variate[SK2014][KvHW2019].","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[RGB2014]: Ranganath, R., Gerrish, S., & Blei, D. (2014, April). Black box variational inference. In Artificial Intelligence and Statistics (pp. 814-822). PMLR.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[WW2013]: Wingate, D., & Weber, T. (2013). Automated variational inference in probabilistic programming. arXiv preprint arXiv:1301.1299.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[RBNRA2020]: Richter, L., Boustati, A., Nüsken, N., Ruiz, F., & Akyildiz, O. D. (2020). Vargrad: a low-variance gradient estimator for variational inference. Advances in Neural Information Processing Systems, 33, 13481-13492.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[SK2014]: Salimans, T., & Knowles, D. A. (2014). On using control variates with stochastic approximation for variational bayes and its connection to stochastic linear regression. arXiv preprint arXiv:1401.1022.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/","page":"KLMinScoreGradDescent","title":"KLMinScoreGradDescent","text":"[KvHW2019]: Kool, W., van Hoof, H., & Welling, M. (2019). Buy 4 reinforce samples, get a baseline for free!.","category":"page"},{"location":"paramspacesgd/klminscoregraddescent/#AdvancedVI.KLMinScoreGradDescent","page":"KLMinScoreGradDescent","title":"AdvancedVI.KLMinScoreGradDescent","text":"KLMinScoreGradDescent(adtype; optimizer, n_samples, averager, operator)\n\nKL divergence minimization by running stochastic gradient descent with the score gradient in the Euclidean space of variational parameters.\n\nArguments\n\nadtype: Automatic differentiation backend. \n\nKeyword Arguments\n\noptimizer::Optimisers.AbstractRule: Optimization algorithm to be used. Only DoG, DoWG and Optimisers.Descent are supported. (default: DoWG())\nn_samples::Int: Number of Monte Carlo samples to be used for estimating each gradient.\naverager::AbstractAverager: Parameter averaging strategy. (default: PolynomialAveraging())\noperator::Union{<:IdentityOperator, <:ClipScale}: Operator to be applied after each gradient descent step. (default: IdentityOperator())\nsubsampling::Union{<:Nothing,<:AbstractSubsampling}: Data point subsampling strategy. If nothing, subsampling is not used. (default: nothing)\n\nRequirements\n\nThe trainable parameters in the variational approximation are expected to be extractable through Optimisers.destructure. This requires the variational approximation to be marked as a functor through Functors.@functor.\nThe variational approximation q_lambda implements rand.\nThe variational approximation q_lambda implements logpdf(q, x), which should also be differentiable with respect to x.\nThe target distribution and the variational approximation have the same support.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/basic/#basic","page":"Basic Example","title":"Basic Example","text":"","category":"section"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"In this tutorial, we will demonstrate the basic usage of AdvancedVI with LogDensityProblem interface.","category":"page"},{"location":"tutorials/basic/#Problem-Setup","page":"Basic Example","title":"Problem Setup","text":"","category":"section"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Let's consider a basic logistic regression example with a hierarchical prior. For a dataset (X y) with the design matrix X in mathbbR^n times d and the response variables y in 0 1^n, we assume the following data generating process:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"beginaligned\nsigma sim textLogNormal(0 3) \nbeta sim textNormalleft(0_d sigma^2 mathrmI_dright) \ny sim mathrmBernoulliLogitleft(X betaright)\nendaligned","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"The LogDensityProblem corresponding to this model can be constructed as","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using LogDensityProblems: LogDensityProblems\nusing Distributions\nusing FillArrays\n\nstruct LogReg{XType,YType}\n    X::XType\n    y::YType\nend\n\nfunction LogDensityProblems.logdensity(model::LogReg, θ)\n    (; X, y) = model\n    d = size(X, 2)\n    β, σ = θ[1:d], θ[end]\n\n    logprior_β = logpdf(MvNormal(Zeros(d), σ), β)\n    logprior_σ = logpdf(LogNormal(0, 3), σ)\n\n    logit = X*β\n    loglike_y = mapreduce((li, yi) -> logpdf(BernoulliLogit(li), yi), +, logit, y)\n    return loglike_y + logprior_β + logprior_σ\nend\n\nfunction LogDensityProblems.dimension(model::LogReg)\n    return size(model.X, 2) + 1\nend\n\nfunction LogDensityProblems.capabilities(::Type{<:LogReg})\n    return LogDensityProblems.LogDensityOrder{0}()\nend\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Since the support of σ is constrained to be positive and most VI algorithms assume an unconstrained Euclidean support, we need to use a bijector to transform θ. We will use Bijectors for this purpose. This corresponds to the automatic differentiation variational inference (ADVI) formulation[KTRGB2017].","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"[KTRGB2017]: Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of machine learning research. The bijector can be constructed as follows:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using Bijectors: Bijectors\n\nfunction Bijectors.bijector(model::LogReg)\n    d = size(model.X, 2)\n    return Bijectors.Stacked(\n        Bijectors.bijector.([MvNormal(Zeros(d), 1.0), LogNormal(0, 3)]),\n        [1:d, (d + 1):(d + 1)],\n    )\nend\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"For the dataset, we will use the popular sonar classification dataset from the UCI repository. This can be automatically downloaded using OpenML. The sonar dataset corresponds to the dataset id 40.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using OpenML: OpenML\nusing DataFrames: DataFrames\ndata = Array(DataFrames.DataFrame(OpenML.load(40)))\nX = Matrix{Float64}(data[:, 1:(end - 1)])\ny = Vector{Bool}(data[:, end] .== \"Mine\")\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Let's apply some basic pre-processing and add an intercept column:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"X = (X .- mean(X; dims=2)) ./ std(X; dims=2)\nX = hcat(X, ones(size(X, 1)))\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"The model can now be instantiated as follows:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"model = LogReg(X, y)\nnothing","category":"page"},{"location":"tutorials/basic/#Basic-Usage","page":"Basic Example","title":"Basic Usage","text":"","category":"section"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"For the VI algorithm, we will use KLMinRepGradDescent:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using ADTypes, ReverseDiff\nusing AdvancedVI\n\nalg = KLMinRepGradDescent(ADTypes.AutoReverseDiff())\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"This algorithm minimizes the exclusive/reverse KL divergence via stochastic gradient descent in the (Euclidean) space of the parameters of the variational approximation with the reparametrization gradient[TL2014][RMW2014][KW2014]. This is also commonly referred as automatic differentiation VI, black-box VI, stochastic gradient VI, and so on. KLMinRepGradDescent, in particular, assumes that the target LogDensityProblem is differentiable. If the LogDensityProblem has a differentiation capability of at least first-order, we can take advantage of this.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"For this example, we will use LogDensityProblemsAD to equip our problem with a first-order capability:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"[TL2014]: Titsias, M., & Lázaro-Gredilla, M. (2014, June). Doubly stochastic variational Bayes for non-conjugate inference. In International Conference on Machine Learning. PMLR.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"[RMW2014]: Rezende, D. J., Mohamed, S., & Wierstra, D. (2014, June). Stochastic backpropagation and approximate inference in deep generative models. In International Conference on Machine Learning. PMLR.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"[KW2014]: Kingma, D. P., & Welling, M. (2014). Auto-encoding variational bayes. In International Conference on Learning Representations.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using DifferentiationInterface: DifferentiationInterface\nusing LogDensityProblemsAD: LogDensityProblemsAD\n\nmodel_ad = LogDensityProblemsAD.ADgradient(ADTypes.AutoReverseDiff(), model)\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"For the variational family, we will consider a FullRankGaussian approximation:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using LinearAlgebra\n\nd = LogDensityProblems.dimension(model_ad)\nq = FullRankGaussian(zeros(d), LowerTriangular(Matrix{Float64}(I, d, d)))\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"The bijector can now be applied to q to match the support of the target problem.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"b = Bijectors.bijector(model)\nbinv = Bijectors.inverse(b)\nq_transformed = Bijectors.TransformedDistribution(q, binv)\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"We can now run VI:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"max_iter = 10^4\nq_out, info, _ = AdvancedVI.optimize(\n    alg, max_iter, model_ad, q_transformed; show_progress=false\n)\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Let's verify that the optimization procedure converged. For this, we will visually inspect that the maximization objective of KLMinRepGradDescent, the \"evidence lower bound\" (ELBO) increased. Since KLMinRepGradDescent stores the ELBO estimate at each iteration in info, we can visualize this as follows:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using Plots\n\nplot(\n    [i.iteration for i in info],\n    [i.elbo for i in info];\n    xlabel=\"Iteration\",\n    ylabel=\"ELBO\",\n    label=nothing,\n    ylims=(-1000, Inf),\n)\nsavefig(\"basic_example_elbo.svg\")\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"(Image: )","category":"page"},{"location":"tutorials/basic/#Custom-Callback","page":"Basic Example","title":"Custom Callback","text":"","category":"section"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"The ELBO estimates above however, use only a handful of Monte Carlo samples. Furthermore, the ELBO is evaluated on the iterates of the optimization procedure, which may not coincide with the actual output of the algorithm. (For instance, if parameter averaging is used.) Therefore, we may want to occasionally estimate higher resolution ELBO estimates. Also, depending on the problem, we may want to monitor some problem-specific diagnostics for monitoring the progress.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"For both use cases above, defining a custom callback function can be useful. In this example, we will compute a more accurate estimate of the ELBO and the classification accuracy every logging_interval = 10 iterations.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"using StatsFuns: StatsFuns\n\n\"\"\"\n    logistic_prediction(X, μ_β, Σ_β)\n    \nApproximate the posterior predictive probability for a logistic link function using Mackay's approximation (Bishop p. 220).\n\"\"\"\nfunction logistic_prediction(X, μ_β, Σ_β)\n    xtΣx = sum((model.X*Σ_β) .* model.X; dims=2)[:, 1]\n    κ = @. 1/sqrt(1 + π/8*xtΣx)\n    return StatsFuns.logistic.(κ .* X*μ_β)\nend\n\nlogging_interval = 100\nfunction callback(; iteration, averaged_params, restructure, kwargs...)\n    if mod(iteration, logging_interval) == 1\n\n        # Use the averaged parameters (the eventual output of the algorithm)\n        q_avg = restructure(averaged_params)\n\n        # Compute predictions\n        μ_β = mean(q_avg.dist)[1:(end - 1)] # posterior mean of β\n        Σ_β = cov(q_avg.dist)[1:(end - 1), end - 1] # marginal posterior covariance of β\n        y_pred = logistic_prediction(X, μ_β, Σ_β) .> 0.5\n\n        # Prediction accuracy\n        acc = mean(y_pred .== model.y)\n\n        # Higher fidelity estimate of the ELBO on the averaged parameters\n        n_samples = 256\n        obj = AdvancedVI.RepGradELBO(n_samples)\n        elbo_callback = estimate_objective(obj, q_avg, model)\n\n        (elbo_callback=elbo_callback, accuracy=acc)\n    else\n        nothing\n    end\nend\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Note that the interface for the callback function will depend on the VI algorithm being used. Therefore, please refer to the documentation of each VI algorithm.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"The callback can be supplied to optimize:","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"max_iter = 10^4\nq_out, info, _ = AdvancedVI.optimize(\n    alg, max_iter, model_ad, q_transformed; show_progress=false, callback=callback\n)\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"First, let's compare the default estimate of the ELBO, which uses a small number of samples and is evaluated in the current iterate, versus the ELBO computed in the callback, which uses a large number of samples and is evaluated on the averaged iterate.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"t = 1:max_iter\nelbo = [i.elbo for i in info[t]]\n\nt_callback = 1:logging_interval:max_iter\nelbo_callback = [i.elbo_callback for i in info[t_callback]]\n\nplot(t, elbo; xlabel=\"Iteration\", ylabel=\"ELBO\", label=\"Default\")\nplot!(t_callback, elbo_callback; label=\"Callback\", ylims=(-1000, Inf), linewidth=2)\n\nsavefig(\"basic_example_elbo_callback.svg\")\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"(Image: )","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"We can see that the default ELBO estimates are noisy compared to the higher fidelity estimates from the callback. After a few thousands of iterations, it is difficult to judge if we are still making progress or not. In contrast, the estimates from callback show that the objective is increasing smoothly.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Similarly, we can monitor the evolution of the prediction accuracy.","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"acc_callback = [i.accuracy for i in info[t_callback]]\nplot(\n    t_callback,\n    acc_callback;\n    xlabel=\"Iteration\",\n    ylabel=\"Prediction Accuracy\",\n    label=nothing,\n)\nsavefig(\"basic_example_acc.svg\")\nnothing","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"(Image: )","category":"page"},{"location":"tutorials/basic/","page":"Basic Example","title":"Basic Example","text":"Clearly, the accuracy is improving over time.","category":"page"},{"location":"paramspacesgd/objectives/#Overview-of-Algorithms","page":"Overview","title":"Overview of Algorithms","text":"","category":"section"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"This section will provide an overview of the algorithm form by each objectives provided by AdvancedVI.","category":"page"},{"location":"paramspacesgd/objectives/#Evidence-Lower-Bound-Maximization","page":"Overview","title":"Evidence Lower Bound Maximization","text":"","category":"section"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"Evidence lower bound (ELBO) maximization[JGJS1999] is a general family of algorithms that minimize the exclusive (or reverse) Kullback-Leibler (KL) divergence between the target distribution pi and a variational approximation q_lambda. More generally, it aims to solve the problem","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmminimize_q in mathcalQquad mathrmKLleft(q piright)  ","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"where mathcalQ is some family of distributions, often called the variational family. Since we usually only have access to the unnormalized densities of the target distribution pi, we don't have direct access to the KL divergence. Instead, the ELBO maximization strategy maximizes a surrogate objective, the ELBO:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmELBOleft(qright) triangleq mathbbE_theta sim q log pileft(thetaright) + mathbbHleft(qright)","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"which is equivalent to the KL up to an additive constant (the evidence). The ELBO and its gradient can be readily estimated through various strategies. Overall, ELBO maximization algorithms aim to solve the problem:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"  mathrmminimize_q in mathcalQquad -mathrmELBOleft(qright)","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"Multiple ways to solve this problem exist, each leading to a different variational inference algorithm. AdvancedVI provides the following objectives:","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"RepGradELBO: Implements the reparameterization gradient estimator of the ELBO gradient.\nScoreGradELBO: Implements the score gradient estimator of the ELBO gradient.","category":"page"},{"location":"paramspacesgd/objectives/","page":"Overview","title":"Overview","text":"[JGJS1999]: Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., & Saul, L. K. (1999). An introduction to variational methods for graphical models. Machine learning, 37, 183-233.","category":"page"},{"location":"paramspacesgd/scoregradelbo/#scoregradelbo","page":"ScoreGradELBO","title":"Score Gradient Estimator","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/#Overview","page":"ScoreGradELBO","title":"Overview","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"The ScoreGradELBO implements the score gradient estimator[G1990][KR1996][RSU1996][W1992] of the ELBO gradient, also known as the score function method and the REINFORCE gradient. For variational inference, the use of the score gradient was proposed in [WW2013][RGB2014]. Unlike the reparameterization gradient, the score gradient does not require the target log density to be differentiable, and does not differentiate through the sampling process of the variational approximation q. Instead, it only requires gradients of the log density log q. For this reason, the score gradient is the standard method to deal with discrete variables and targets with discrete support.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[G1990]: Glynn, P. W. (1990). Likelihood ratio gradient estimation for stochastic systems. Communications of the ACM, 33(10), 75-84.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[KR1996]: Kleijnen, J. P., & Rubinstein, R. Y. (1996). Optimization and sensitivity analysis of computer simulation models by the score function method. European Journal of Operational Research, 88(3), 413-427.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RSU1996]: Rubinstein, R. Y., Shapiro, A., & Uryasev, S. (1996). The score function method. Encyclopedia of Management Sciences, 1363-1366.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[W1992]: Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8, 229-256.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[WW2013]: Wingate, D., & Weber, T. (2013). Automated variational inference in probabilistic programming. arXiv preprint arXiv:1301.1299.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RGB2014]: Ranganath, R., Gerrish, S., & Blei, D. (2014). Black box variational inference. In Artificial intelligence and statistics (pp. 814-822). PMLR. In more detail, the score gradient uses the Fisher log-derivative identity: For any regular f,","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"nabla_lambda mathbbE_z sim q_lambda f\n=\nmathbbE_z sim q_lambdaleft f(z) log q_lambda(z) right  ","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"The ELBO corresponds to the case where f = log pi  log q, where log pi is the target log density.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"Instead of implementing the canonical score gradient, ScoreGradELBO uses the \"VarGrad\" objective[RBNRA2020]:","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"widehatmathrmVarGrad(lambda) \n=\nmathrmVarleft( log q_lambda(z_i) - log pileft(z_iright) right)  ","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"where the variance is computed over the samples z_1 ldots z_m sim q_lambda. Differentiating the VarGrad objective corresponds to the canonical score gradient combined with the \"leave-one-out\" control variate[SK2014][KvHW2019].","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[RBNRA2020]: Richter, L., Boustati, A., Nüsken, N., Ruiz, F., & Akyildiz, O. D. (2020). Vargrad: a low-variance gradient estimator for variational inference. Advances in Neural Information Processing Systems, 33, 13481-13492.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[SK2014]: Salimans, T., & Knowles, D. A. (2014). On using control variates with stochastic approximation for variational bayes and its connection to stochastic linear regression. arXiv preprint arXiv:1401.1022.","category":"page"},{"location":"paramspacesgd/scoregradelbo/","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"[KvHW2019]: Kool, W., van Hoof, H., & Welling, M. (2019). Buy 4 reinforce samples, get a baseline for free!. Since the expectation of the VarGrad objective (not its gradient) is not exactly the ELBO, we separately obtain an unbiased estimate of the ELBO to be returned by estimate_objective.","category":"page"},{"location":"paramspacesgd/scoregradelbo/#ScoreGradELBO","page":"ScoreGradELBO","title":"ScoreGradELBO","text":"","category":"section"},{"location":"paramspacesgd/scoregradelbo/#AdvancedVI.ScoreGradELBO","page":"ScoreGradELBO","title":"AdvancedVI.ScoreGradELBO","text":"ScoreGradELBO(n_samples; kwargs...)\n\nEvidence lower-bound objective computed with score function gradient with the VarGrad objective, also known as the leave-one-out control variate.\n\nArguments\n\nn_samples::Int: Number of Monte Carlo samples used to estimate the VarGrad objective.\n\nRequirements\n\nThe variational approximation q_lambda implements rand and logpdf.\nlogpdf(q, x) must be differentiable with respect to q by the selected AD backend.\nThe target distribution and the variational approximation have the same support.\n\n\n\n\n\n","category":"type"},{"location":"general/#general","page":"General Usage","title":"General Usage","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"AdvancedVI provides multiple variational inference (VI) algorithms. Each algorithm defines its subtype of AdvancedVI.AbstractAlgorithm with some corresponding methods (see this section). Then the algorithm can be executed by invoking optimize. (See this section).","category":"page"},{"location":"general/#optimize","page":"General Usage","title":"Optimize","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Given a subtype of AbstractAlgorithm associated with each algorithm, it suffices to call the function optimize:","category":"page"},{"location":"general/#AdvancedVI.optimize","page":"General Usage","title":"AdvancedVI.optimize","text":"optimize(\n    [rng::Random.AbstractRNG = Random.default_rng(),]\n    algorithm::AbstractAlgorithm,\n    max_iter::Int,\n    prob,\n    q_init,\n    args...;\n    kwargs...\n)\n\nRun variational inference algorithm on the problem implementing the LogDensityProblems interface. For more details on the usage, refer to the documentation corresponding to algorithm.\n\nArguments\n\nrng: Random number generator.\nalgorithm: Variational inference algorithm.\nmax_iter::Int: Maximum number of iterations.\nprob: Target LogDensityProblem \nq_init: Initial variational distribution.\nargs...: Arguments to be passed to algorithm.\n\nKeyword Arguments\n\nshow_progress::Bool: Whether to show the progress bar. (Default: true.)\nstate::Union{<:Any,Nothing}: Initial value for the internal state of optimization. Used to warm-start from the state of a previous run. (See the returned values below.)\ncallback: Callback function called after every iteration. See further information below. (Default: nothing.)\nprogress::ProgressMeter.AbstractProgress: Progress bar configuration. (Default: ProgressMeter.Progress(n_max_iter; desc=\"Optimizing\", barlen=31, showspeed=true, enabled=prog).)\nkwargs...: Keyword arguments to be passed to algorithm.\n\nReturns\n\noutput: The output of the variational inference algorithm.\ninfo: Array of NamedTuples, where each NamedTuple contains information generated at each iteration.\nstate: Collection of the final internal states of optimization. This can used later to warm-start from the last iteration of the corresponding run.\n\nCallback\n\nThe signature of the callback function depends on the algorithm in use. Thus, see the documentation for each algorithm. However, a callback should return either a nothing or a NamedTuple containing information generated during the current iteration. The content of the NamedTuple will be concatenated into the corresponding entry in the info array returns in the end of the call to optimize and will be displayed on the progress meter.\n\n\n\n\n\n","category":"function"},{"location":"general/","page":"General Usage","title":"General Usage","text":"Each algorithm may interact differently with the arguments of optimize. Therefore, please refer to the documentation of each different algorithm for a detailed description on their behavior and their requirements.","category":"page"},{"location":"general/#algorithm","page":"General Usage","title":"Algorithm Interface","text":"","category":"section"},{"location":"general/","page":"General Usage","title":"General Usage","text":"A variational inference algorithm supported by AdvancedVI should define its own subtype of AbstractAlgorithm:","category":"page"},{"location":"general/#AdvancedVI.AbstractAlgorithm","page":"General Usage","title":"AdvancedVI.AbstractAlgorithm","text":"AbstractAlgorithm\n\nAbstract type for a variational inference algorithm.\n\n\n\n\n\n","category":"type"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The functionality of each algorithm is then implemented through the following methods:","category":"page"},{"location":"general/#AdvancedVI.init-Tuple{AbstractRNG, AdvancedVI.AbstractAlgorithm, Any, Any}","page":"General Usage","title":"AdvancedVI.init","text":"init(rng, alg, q_init, prob)\n\nInitialize alg given the initial variational approximation q_init and the target prob.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nalg::AbstractAlgorithm: Variational inference algorithm.\nq_init: Initial variational approximation.\nprob: Target problem.\n\nReturns\n\nstate: Initial state of the algorithm.\n\n\n\n\n\n","category":"method"},{"location":"general/#AdvancedVI.step","page":"General Usage","title":"AdvancedVI.step","text":"step(rng, alg, state, callback, objargs...; kwargs...)\n\nPerform a single step of alg given the previous state.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nalg::AbstractAlgorithm: Variational inference algorithm.\nstate: Previous state of the algorithm.\ncallback: Callback function to be called during the step.\n\nReturns\n\nstate: New state generated by performing the step.\nterminate::Bool: Whether to terminate the algorithm after the step.\ninfo::NamedTuple: Information generated during the step. \n\n\n\n\n\n","category":"function"},{"location":"general/#AdvancedVI.output","page":"General Usage","title":"AdvancedVI.output","text":"output(alg, state)\n\nOutput a variational approximation from the last state of alg.\n\nArguments\n\nalg::AbstractAlgorithm: Variational inference algorithm used to compute the state.\nstate: The last state generated by the algorithm.\n\nReturns\n\nout: The output of the algorithm. \n\n\n\n\n\n","category":"function"},{"location":"general/","page":"General Usage","title":"General Usage","text":"The role of each method should be self-explanatory and should be clear once we take a look at how optimize interacts with each algorithm. The operation of optimize can be simplified as follows:","category":"page"},{"location":"general/","page":"General Usage","title":"General Usage","text":"function optimize([rng,] algorithm, max_iter, q_init, objargs; kwargs...)\n    info_total = NamedTuple[]\n    state = init(rng, algorithm, q_init, prob)\n    for t in 1:max_iter\n        info = (iteration=t,)\n        state, terminate, info′ = step(\n            rng, algorithm, state, callback, objargs...; kwargs...\n        )\n        info = merge(info′, info)\n\n        if terminate\n            break\n        end\n\n        push!(info_total, info)\n    end\n    out = output(algorithm, state)\n    return out, info_total, state\nend","category":"page"},{"location":"#AdvancedVI","page":"AdvancedVI","title":"AdvancedVI","text":"","category":"section"},{"location":"","page":"AdvancedVI","title":"AdvancedVI","text":"AdvancedVI provides implementations of variational Bayesian inference (VI) algorithms. VI algorithms perform scalable and computationally efficient Bayesian inference at the cost of asymptotic exactness. AdvancedVI is part of the Turing probabilistic programming ecosystem.","category":"page"},{"location":"#List-of-Algorithms","page":"AdvancedVI","title":"List of Algorithms","text":"","category":"section"},{"location":"","page":"AdvancedVI","title":"AdvancedVI","text":"ParamSpaceSGD\nKLMinRepGradDescent (alias of ADVI)\nKLMinRepGradProxDescent\nKLMinScoreGradDescent  (alias of BBVI)","category":"page"}]
}
