<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>General Usage · AdvancedVI.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AdvancedVI.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">AdvancedVI</a></li><li class="is-active"><a class="tocitem" href>General Usage</a><ul class="internal"><li><a class="tocitem" href="#Optimizing-a-Variational-Objective"><span>Optimizing a Variational Objective</span></a></li><li><a class="tocitem" href="#Estimating-the-Objective"><span>Estimating the Objective</span></a></li><li><a class="tocitem" href="#Advanced-Usage"><span>Advanced Usage</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><span class="tocitem">ELBO Maximization</span><ul><li><a class="tocitem" href="../elbo/overview/">Overview</a></li><li><a class="tocitem" href="../elbo/repgradelbo/">Reparameterization Gradient Estimator</a></li></ul></li><li><a class="tocitem" href="../families/">Variational Families</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>General Usage</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>General Usage</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TuringLang/AdvancedVI.jl/blob/master/docs/src/general.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="general"><a class="docs-heading-anchor" href="#general">General Usage</a><a id="general-1"></a><a class="docs-heading-anchor-permalink" href="#general" title="Permalink"></a></h1><p>Each VI algorithm provides the followings:</p><ol><li>Variational families supported by each VI algorithm.</li><li>A variational objective corresponding to the VI algorithm. Note that each variational family is subject to its own constraints. Thus, please refer to the documentation of the variational inference algorithm of interest.</li></ol><h2 id="Optimizing-a-Variational-Objective"><a class="docs-heading-anchor" href="#Optimizing-a-Variational-Objective">Optimizing a Variational Objective</a><a id="Optimizing-a-Variational-Objective-1"></a><a class="docs-heading-anchor-permalink" href="#Optimizing-a-Variational-Objective" title="Permalink"></a></h2><p>After constructing a <em>variational objective</em> <code>objective</code> and initializing a <em>variational approximation</em>, one can optimize <code>objective</code> by calling <code>optimize</code>:</p><article class="docstring"><header><a class="docstring-binding" id="AdvancedVI.optimize" href="#AdvancedVI.optimize"><code>AdvancedVI.optimize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">optimize(problem, objective, q_init, max_iter, objargs...; kwargs...)</code></pre><p>Optimize the variational objective <code>objective</code> targeting the problem <code>problem</code> by estimating (stochastic) gradients.</p><p>The trainable parameters in the variational approximation are expected to be extractable through <code>Optimisers.destructure</code>. This requires the variational approximation to be marked as a functor through <code>Functors.@functor</code>.</p><p><strong>Arguments</strong></p><ul><li><code>objective::AbstractVariationalObjective</code>: Variational Objective.</li><li><code>q_init</code>: Initial variational distribution. The variational parameters must be extractable through <code>Optimisers.destructure</code>.</li><li><code>max_iter::Int</code>: Maximum number of iterations.</li><li><code>objargs...</code>: Arguments to be passed to <code>objective</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>adtype::ADtypes.AbstractADType</code>: Automatic differentiation backend. </li><li><code>optimizer::Optimisers.AbstractRule</code>: Optimizer used for inference. (Default: <code>Adam</code>.)</li><li><code>averager::AbstractAverager</code> : Parameter averaging strategy. (Default: <code>NoAveraging()</code>)</li><li><code>rng::AbstractRNG</code>: Random number generator. (Default: <code>Random.default_rng()</code>.)</li><li><code>show_progress::Bool</code>: Whether to show the progress bar. (Default: <code>true</code>.)</li><li><code>callback</code>: Callback function called after every iteration. See further information below. (Default: <code>nothing</code>.)</li><li><code>prog</code>: Progress bar configuration. (Default: <code>ProgressMeter.Progress(n_max_iter; desc=&quot;Optimizing&quot;, barlen=31, showspeed=true, enabled=prog)</code>.)</li><li><code>state::NamedTuple</code>: Initial value for the internal state of optimization. Used to warm-start from the state of a previous run. (See the returned values below.)</li></ul><p><strong>Returns</strong></p><ul><li><code>averaged_params</code>: Variational parameters generated by the algorithm averaged according to <code>averager</code>.</li><li><code>params</code>: Last variational parameters generated by the algorithm.</li><li><code>stats</code>: Statistics gathered during optimization.</li><li><code>state</code>: Collection of the final internal states of optimization. This can used later to warm-start from the last iteration of the corresponding run.</li></ul><p><strong>Callback</strong></p><p>The callback function <code>callback</code> has a signature of</p><pre><code class="nohighlight hljs">callback(; stat, state, params, averaged_params, restructure, gradient)</code></pre><p>The arguments are as follows:</p><ul><li><code>stat</code>: Statistics gathered during the current iteration. The content will vary depending on <code>objective</code>.</li><li><code>state</code>: Collection of the internal states used for optimization.</li><li><code>params</code>: Variational parameters.</li><li><code>averaged_params</code>: Variational parameters averaged according to the averaging strategy.</li><li><code>restructure</code>: Function that restructures the variational approximation from the variational parameters. Calling <code>restructure(param)</code> reconstructs the variational approximation. </li><li><code>gradient</code>: The estimated (possibly stochastic) gradient.</li></ul><p><code>callback</code> can return a <code>NamedTuple</code> containing some additional information computed within <code>cb</code>. This will be appended to the statistic of the current corresponding iteration. Otherwise, just return <code>nothing</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/optimize.jl#L2-L49">source</a></section></article><h2 id="Estimating-the-Objective"><a class="docs-heading-anchor" href="#Estimating-the-Objective">Estimating the Objective</a><a id="Estimating-the-Objective-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-the-Objective" title="Permalink"></a></h2><p>In some cases, it is useful to directly estimate the objective value. This can be done by the following funciton:</p><article class="docstring"><header><a class="docstring-binding" id="AdvancedVI.estimate_objective" href="#AdvancedVI.estimate_objective"><code>AdvancedVI.estimate_objective</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_objective([rng,] obj, q, prob; kwargs...)</code></pre><p>Estimate the variational objective <code>obj</code> targeting <code>prob</code> with respect to the variational approximation <code>q</code>.</p><p><strong>Arguments</strong></p><ul><li><code>rng::Random.AbstractRNG</code>: Random number generator.</li><li><code>obj::AbstractVariationalObjective</code>: Variational objective.</li><li><code>prob</code>: The target log-joint likelihood implementing the <code>LogDensityProblem</code> interface.</li><li><code>q</code>: Variational approximation.</li></ul><p><strong>Keyword Arguments</strong></p><p>Depending on the objective, additional keyword arguments may apply. Please refer to the respective documentation of each variational objective for more info.</p><p><strong>Returns</strong></p><ul><li><code>obj_est</code>: Estimate of the objective value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/AdvancedVI.jl#L119-L136">source</a></section></article><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Note that <code>estimate_objective</code> is not expected to be differentiated through, and may not result in optimal statistical performance.</p></div></div><h2 id="Advanced-Usage"><a class="docs-heading-anchor" href="#Advanced-Usage">Advanced Usage</a><a id="Advanced-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Usage" title="Permalink"></a></h2><p>Each variational objective is a subtype of the following abstract type:</p><article class="docstring"><header><a class="docstring-binding" id="AdvancedVI.AbstractVariationalObjective" href="#AdvancedVI.AbstractVariationalObjective"><code>AdvancedVI.AbstractVariationalObjective</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractVariationalObjective</code></pre><p>Abstract type for the VI algorithms supported by <code>AdvancedVI</code>.</p><p><strong>Implementations</strong></p><p>To be supported by <code>AdvancedVI</code>, a VI algorithm must implement <code>AbstractVariationalObjective</code> and <code>estimate_objective</code>. Also, it should provide gradients by implementing the function <code>estimate_gradient!</code>. If the estimator is stateful, it can implement <code>init</code> to initialize the state.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/AdvancedVI.jl#L93-L102">source</a></section></article><p>Furthermore, <code>AdvancedVI</code> only interacts with each variational objective by querying gradient estimates. Therefore, to create a new custom objective to be optimized through <code>AdvancedVI</code>, it suffices to implement the following function:</p><article class="docstring"><header><a class="docstring-binding" id="AdvancedVI.estimate_gradient!" href="#AdvancedVI.estimate_gradient!"><code>AdvancedVI.estimate_gradient!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_gradient!(rng, obj, adtype, out, prob, params, restructure, obj_state)</code></pre><p>Estimate (possibly stochastic) gradients of the variational objective <code>obj</code> targeting <code>prob</code> with respect to the variational parameters <code>λ</code></p><p><strong>Arguments</strong></p><ul><li><code>rng::Random.AbstractRNG</code>: Random number generator.</li><li><code>obj::AbstractVariationalObjective</code>: Variational objective.</li><li><code>adtype::ADTypes.AbstractADType</code>: Automatic differentiation backend. </li><li><code>out::DiffResults.MutableDiffResult</code>: Buffer containing the objective value and gradient estimates. </li><li><code>prob</code>: The target log-joint likelihood implementing the <code>LogDensityProblem</code> interface.</li><li><code>params</code>: Variational parameters to evaluate the gradient on.</li><li><code>restructure</code>: Function that reconstructs the variational approximation from <code>λ</code>.</li><li><code>obj_state</code>: Previous state of the objective.</li></ul><p><strong>Returns</strong></p><ul><li><code>out::MutableDiffResult</code>: Buffer containing the objective value and gradient estimates.</li><li><code>obj_state</code>: The updated state of the objective.</li><li><code>stat::NamedTuple</code>: Statistics and logs generated during estimation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/AdvancedVI.jl#L141-L160">source</a></section></article><p>If an objective needs to be stateful, one can implement the following function to inialize the state.</p><article class="docstring"><header><a class="docstring-binding" id="AdvancedVI.init" href="#AdvancedVI.init"><code>AdvancedVI.init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">init(rng, obj, prob, params, restructure)</code></pre><p>Initialize a state of the variational objective <code>obj</code> given the initial variational parameters <code>λ</code>. This function needs to be implemented only if <code>obj</code> is stateful.</p><p><strong>Arguments</strong></p><ul><li><code>rng::Random.AbstractRNG</code>: Random number generator.</li><li><code>obj::AbstractVariationalObjective</code>: Variational objective.</li><li><code>params</code>: Initial variational parameters.</li><li><code>restructure</code>: Function that reconstructs the variational approximation from <code>λ</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/AdvancedVI.jl#L105-L116">source</a></section><section><div><pre><code class="nohighlight hljs">init(avg, params)</code></pre><p>Initialize the state of the averaging strategy <code>avg</code> with the initial parameters <code>params</code>.</p><p><strong>Arguments</strong></p><ul><li><code>avg::AbstractAverager</code>: Averaging strategy.</li><li><code>params</code>: Initial variational parameters.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/AdvancedVI.jl/blob/9cc1de24287f17204b9569b4c0a5c0859d7f46e0/src/AdvancedVI.jl#L207-L215">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« AdvancedVI</a><a class="docs-footer-nextpage" href="../examples/">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 4 October 2024 19:28">Friday 4 October 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
