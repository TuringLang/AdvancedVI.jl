
struct ADVI{TlogÏ€} <: AbstractGradientEstimator
    â„“Ï€::TlogÏ€
    n_samples::Int
end

function ADVI(â„“Ï€, n_samples; kwargs...)
    # ADVI requires gradients of log-likelihood
    cap = LogDensityProblems.capabilities(â„“Ï€)
    if cap === nothing
        throw(
            ArgumentError(
                "The log density function does not support the LogDensityProblems.jl interface",
            ),
        )
    end
    ADVI(Base.Fix1(LogDensityProblems.logdensity, â„“Ï€), n_samples)
end

objective(::ADVI) = "ELBO"

function estimate_gradient!(
    rng::Random.AbstractRNG,
    estimator::ADVI,
    Î»::Vector{<:Real},
    rebuild::Function,
    out::DiffResults.MutableDiffResult)

    n_samples = estimator.n_samples

    grad!(ADBackend(), Î», out) do Î»â€²
        q = rebuild(Î»â€²)
        zs, âˆ‘logdetjac = rand_and_logjac(rng, q, estimator.n_samples)

        ğ”¼logÏ€ = mapreduce(+, eachcol(zs)) do záµ¢
            estimator.â„“Ï€(záµ¢) / n_samples
        end
        ğ”¼logdetjac = âˆ‘logdetjac/n_samples

        elbo = ğ”¼logÏ€ + ğ”¼logdetjac + entropy(q)
        -elbo
    end
    nelbo = DiffResults.value(out)
    (elbo=-nelbo,)
end

