
"""
    ADVI(prob, n_samples; kwargs...)

Automatic differentiation variational inference (ADVI; Kucukelbir *et al.* 2017) objective.

# Arguments
- `prob`: An object that implements the order `K == 0` `LogDensityProblems` interface.
- `n_samples`: Number of Monte Carlo samples used to estimate the ELBO. (Type `<: Int`.)

# Keyword Arguments
- `entropy`: The estimator for the entropy term. (Type `<: AbstractEntropyEstimator`; Default: ClosedFormEntropy())
- `cv`: A control variate.
- `b`: A bijector mapping the support of the base distribution to that of `prob`. (Default: `Bijectors.identity`.)

# Requirements
- ``q_{\\lambda}`` implements `rand`.
- `logdensity(prob)` must be differentiable by the selected AD backend.

Depending on the options, additional requirements on ``q_{\\lambda}`` may apply.
"""
struct ADVI{TlogÏ€, B,
            EntropyEst <: AbstractEntropyEstimator,
            ControlVar <: Union{<: AbstractControlVariate, Nothing}} <: AbstractVariationalObjective
    â„“Ï€::TlogÏ€
    b::B
    entropy::EntropyEst
    cv::ControlVar
    n_samples::Int

    function ADVI(prob, n_samples::Int;
                  entropy::AbstractEntropyEstimator = ClosedFormEntropy(),
                  cv::Union{<:AbstractControlVariate, Nothing} = nothing,
                  b = Bijectors.identity)
        cap = LogDensityProblems.capabilities(prob)
        if cap === nothing
            throw(
                ArgumentError(
                    "The log density function does not support the LogDensityProblems.jl interface",
                ),
            )
        end
        â„“Ï€ = Base.Fix1(LogDensityProblems.logdensity, prob)
        new{typeof(â„“Ï€), typeof(b), typeof(entropy), typeof(cv)}(â„“Ï€, b, entropy, cv, n_samples)
    end
end

Base.show(io::IO, advi::ADVI) =
    print(io, "ADVI(entropy=$(advi.entropy), cv=$(advi.cv), n_samples=$(advi.n_samples))")

init(advi::ADVI) = init(advi.cv)

function (advi::ADVI)(
    rng::AbstractRNG,
    q_Î·::ContinuousMultivariateDistribution,
    Î·s ::AbstractMatrix
)
    n_samples = size(Î·s, 2)
    ð”¼â„“ = mapreduce(+, eachcol(Î·s)) do Î·áµ¢
        záµ¢, logdetjacáµ¢ = Bijectors.with_logabsdet_jacobian(advi.b, Î·áµ¢)
        (advi.â„“Ï€(záµ¢) + logdetjacáµ¢) / n_samples
    end
    â„  = advi.entropy(q_Î·, Î·s)
    ð”¼â„“ + â„
end

"""
    (advi::ADVI)(
        q_Î·::ContinuousMultivariateDistribution;
        rng::AbstractRNG = Random.default_rng(),
        n_samples::Int = advi.n_samples
    )

Evaluate the ELBO using the ADVI formulation.

# Arguments
- `q_Î·`: Variational approximation before applying a bijector (unconstrained support).
- `n_samples`: Number of Monte Carlo samples used to estimate the ELBO.

"""
function (advi::ADVI)(
    q_Î·::ContinuousMultivariateDistribution;
    rng::AbstractRNG = default_rng(),
    n_samples::Int = advi.n_samples
)
    Î·s = rand(rng, q_Î·, n_samples)
    advi(rng, q_Î·, Î·s)
end

function estimate_advi_gradient_maybe_stl!(
    rng::AbstractRNG,
    adbackend::AbstractADType,
    advi::ADVI{P, B, StickingTheLandingEntropy, CV},
    Î»::Vector{<:Real},
    restructure,
    out::DiffResults.MutableDiffResult
) where {P, B, CV}
    q_Î·_stop = restructure(Î»)
    f(Î»â€²) = begin
        q_Î· = restructure(Î»â€²)
        Î·s  = rand(rng, q_Î·, advi.n_samples)
        -advi(rng, q_Î·_stop, Î·s)
    end
    value_and_gradient!(adbackend, f, Î», out)
end

function estimate_advi_gradient_maybe_stl!(
    rng::AbstractRNG,
    adbackend::AbstractADType,
    advi::ADVI{P, B, <:Union{ClosedFormEntropy, FullMonteCarloEntropy}, CV},
    Î»::Vector{<:Real},
    restructure,
    out::DiffResults.MutableDiffResult
) where {P, B, CV}
    f(Î»â€²) = begin
        q_Î· = restructure(Î»â€²)
        Î·s  = rand(rng, q_Î·, advi.n_samples)
        -advi(rng, q_Î·, Î·s)
    end
    value_and_gradient!(adbackend, f, Î», out)
end

function estimate_gradient(
    rng::AbstractRNG,
    adbackend::AbstractADType,
    advi::ADVI,
    est_state,
    Î»::Vector{<:Real},
    restructure,
    out::DiffResults.MutableDiffResult
)
    estimate_advi_gradient_maybe_stl!(
        rng, adbackend, advi, Î», restructure, out)
    nelbo = DiffResults.value(out)
    stat  = (elbo=-nelbo,)

    est_state, statâ€² = update(advi.cv, est_state)
    stat = !isnothing(statâ€²) ? merge(statâ€², stat) : stat 

    out, est_state, stat
end
