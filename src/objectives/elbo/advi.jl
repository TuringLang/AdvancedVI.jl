
"""
    ADVI

Automatic differentiation variational inference (ADVI; Kucukelbir *et al.* 2017) objective.

# Requirements
- ``q_{\\lambda}`` implements `rand`.
- ``\\pi`` must be differentiable

Depending on the options, additional requirements on ``q_{\\lambda}`` may apply.
"""
struct ADVI{TlogÏ€, B,
            EntropyEst <: AbstractEntropyEstimator,
            ControlVar <: Union{<: AbstractControlVariate, Nothing}} <: AbstractVariationalObjective
    â„“Ï€::TlogÏ€
    b::B
    entropy::EntropyEst
    cv::ControlVar
    n_samples::Int

    function ADVI(prob, n_samples::Int;
                  entropy::AbstractEntropyEstimator = ClosedFormEntropy(),
                  cv::Union{<:AbstractControlVariate, Nothing} = nothing,
                  b = Bijectors.identity)
        cap = LogDensityProblems.capabilities(prob)
        if cap === nothing
            throw(
                ArgumentError(
                    "The log density function does not support the LogDensityProblems.jl interface",
                ),
            )
        end
        â„“Ï€ = Base.Fix1(LogDensityProblems.logdensity, prob)
        new{typeof(â„“Ï€), typeof(b), typeof(entropy), typeof(cv)}(â„“Ï€, b, entropy, cv, n_samples)
    end
end

Base.show(io::IO, advi::ADVI) =
    print(io, "ADVI(entropy=$(advi.entropy), cv=$(advi.cv), n_samples=$(advi.n_samples))")

skip_entropy_gradient(advi::ADVI) = skip_entropy_gradient(advi.entropy)

init(advi::ADVI) = init(advi.cv)

function (advi::ADVI)(q_Î·::ContinuousMultivariateDistribution;
                      rng       ::AbstractRNG    = default_rng(),
                      n_samples ::Int            = advi.n_samples,
                      Î·s        ::AbstractMatrix = rand(rng, q_Î·, n_samples),
                      q_Î·_entropy::ContinuousMultivariateDistribution = q_Î·)
    ð”¼â„“ = mapreduce(+, eachcol(Î·s)) do Î·áµ¢
        záµ¢, logdetjacáµ¢ = Bijectors.with_logabsdet_jacobian(advi.b, Î·áµ¢)
        (advi.â„“Ï€(záµ¢) + logdetjacáµ¢) / n_samples
    end
    â„  = advi.entropy(q_Î·_entropy, Î·s)
    ð”¼â„“ + â„
end

function estimate_gradient(
    rng::AbstractRNG,
    adbackend::AbstractADType,
    advi::ADVI,
    est_state,
    Î»::Vector{<:Real},
    restructure,
    out::DiffResults.MutableDiffResult)

    # Gradient-stopping for computing the sticking-the-landing control variate
    q_Î·_stop = skip_entropy_gradient(advi.entropy) ? restructure(Î») : nothing

    grad!(adbackend, Î», out) do Î»â€²
        q_Î· = restructure(Î»â€²)
        q_Î·_entropy = skip_entropy_gradient(advi.entropy) ? q_Î·_stop : q_Î·
        -advi(q_Î·; rng, q_Î·_entropy)
    end
    nelbo = DiffResults.value(out)
    stat  = (elbo=-nelbo,)

    est_state, statâ€² = update(advi.cv, est_state)
    stat = !isnothing(statâ€²) ? merge(statâ€², stat) : stat 

    out, est_state, stat
end
